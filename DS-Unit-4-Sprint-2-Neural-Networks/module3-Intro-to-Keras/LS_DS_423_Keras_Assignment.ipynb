{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Boston Housing dataset using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data\n",
    "\n",
    "Neural networks are able to converge with data that hasn't been normalized. But, normalizing the data can cause the model to converge more quickly. Normalization is more important for traditional statistical models, and very important for distance-based clustering algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = (X_train / np.amax(X_train, axis=0)).astype('float32')\n",
    "X_test = (X_test / np.amax(X_test, axis=0)).astype('float32')\n",
    "\n",
    "y_train = (y_train / np.amax(y_train, axis=0)).astype('float32')\n",
    "y_test = (y_test / np.amax(y_train, axis=0)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the type of model and layers that you will need from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate a model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Input layer + hidden layer\n",
    "model.add(Dense(10, input_dim=13, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "# Output layer (no activation for output layer in regression problems)\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 261\n",
      "Trainable params: 261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='sgd',\n",
    "              metrics=['mean_squared_error', 'accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit your model and report its accuracy in terms of Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 316us/sample - loss: 594.9763 - mean_squared_error: 594.9763 - acc: 0.0000e+00\n",
      "mean_squared_error: 594.976318359375\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(f'{model.metrics_names[1]}: {scores[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph the model's loss or train/validation accuracies by epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas is needed for altair to read the history data\n",
    "import altair.vegalite.v2 as alt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>acc</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.449899</td>\n",
       "      <td>0.449899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061148</td>\n",
       "      <td>0.061148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036428</td>\n",
       "      <td>0.036428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034205</td>\n",
       "      <td>0.034205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  mean_squared_error  acc  epoch\n",
       "0  0.449899            0.449899  0.0      0\n",
       "1  0.061148            0.061148  0.0      1\n",
       "2  0.036428            0.036428  0.0      2\n",
       "3  0.034205            0.034205  0.0      3\n",
       "4  0.033974            0.033974  0.0      4"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df['epoch'] = history.epoch\n",
    "history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>acc</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.036053</td>\n",
       "      <td>0.036053</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>49.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.041932</td>\n",
       "      <td>0.041932</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>29.011492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.029281</td>\n",
       "      <td>0.029281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.030363</td>\n",
       "      <td>0.030363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.031479</td>\n",
       "      <td>0.031479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.032788</td>\n",
       "      <td>0.032788</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>74.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.449899</td>\n",
       "      <td>0.449899</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss  mean_squared_error         acc       epoch\n",
       "count  100.000000          100.000000  100.000000  100.000000\n",
       "mean     0.036053            0.036053    0.000965   49.500000\n",
       "std      0.041932            0.041932    0.001213   29.011492\n",
       "min      0.029281            0.029281    0.000000    0.000000\n",
       "25%      0.030363            0.030363    0.000000   24.750000\n",
       "50%      0.031479            0.031479    0.000000   49.500000\n",
       "75%      0.032788            0.032788    0.002475   74.250000\n",
       "max      0.449899            0.449899    0.002475   99.000000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v2+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v2.6.0.json",
       "config": {
        "view": {
         "height": 300,
         "width": 400
        }
       },
       "data": {
        "name": "data-f0857b13d3e0fd7b55b1293337f757cb"
       },
       "datasets": {
        "data-f0857b13d3e0fd7b55b1293337f757cb": [
         {
          "acc": 0,
          "epoch": 0,
          "loss": 0.4498986417409217,
          "mean_squared_error": 0.4498986601829529
         },
         {
          "acc": 0,
          "epoch": 1,
          "loss": 0.06114793047401132,
          "mean_squared_error": 0.06114793196320534
         },
         {
          "acc": 0,
          "epoch": 2,
          "loss": 0.0364278245090258,
          "mean_squared_error": 0.036427829414606094
         },
         {
          "acc": 0,
          "epoch": 3,
          "loss": 0.03420475612182428,
          "mean_squared_error": 0.03420475870370865
         },
         {
          "acc": 0,
          "epoch": 4,
          "loss": 0.033974194124636085,
          "mean_squared_error": 0.03397419676184654
         },
         {
          "acc": 0,
          "epoch": 5,
          "loss": 0.03401322391732495,
          "mean_squared_error": 0.03401322662830353
         },
         {
          "acc": 0,
          "epoch": 6,
          "loss": 0.03390081680499681,
          "mean_squared_error": 0.03390081971883774
         },
         {
          "acc": 0,
          "epoch": 7,
          "loss": 0.03385929711679421,
          "mean_squared_error": 0.03385929390788078
         },
         {
          "acc": 0,
          "epoch": 8,
          "loss": 0.033745671189067385,
          "mean_squared_error": 0.033745668828487396
         },
         {
          "acc": 0,
          "epoch": 9,
          "loss": 0.03376702949552253,
          "mean_squared_error": 0.03376702964305878
         },
         {
          "acc": 0,
          "epoch": 10,
          "loss": 0.033637874012831415,
          "mean_squared_error": 0.0336378738284111
         },
         {
          "acc": 0,
          "epoch": 11,
          "loss": 0.03358127750308797,
          "mean_squared_error": 0.03358127549290657
         },
         {
          "acc": 0,
          "epoch": 12,
          "loss": 0.033533947745172106,
          "mean_squared_error": 0.03353394195437431
         },
         {
          "acc": 0,
          "epoch": 13,
          "loss": 0.033459225282220555,
          "mean_squared_error": 0.03345922753214836
         },
         {
          "acc": 0,
          "epoch": 14,
          "loss": 0.033441911220993145,
          "mean_squared_error": 0.03344191238284111
         },
         {
          "acc": 0,
          "epoch": 15,
          "loss": 0.033347540175413144,
          "mean_squared_error": 0.033347539603710175
         },
         {
          "acc": 0,
          "epoch": 16,
          "loss": 0.03334823062661851,
          "mean_squared_error": 0.03334823250770569
         },
         {
          "acc": 0,
          "epoch": 17,
          "loss": 0.03327284849221163,
          "mean_squared_error": 0.03327284753322601
         },
         {
          "acc": 0,
          "epoch": 18,
          "loss": 0.0332534838246532,
          "mean_squared_error": 0.03325348719954491
         },
         {
          "acc": 0,
          "epoch": 19,
          "loss": 0.03309644873041918,
          "mean_squared_error": 0.033096447587013245
         },
         {
          "acc": 0,
          "epoch": 20,
          "loss": 0.03304118618811711,
          "mean_squared_error": 0.03304118663072586
         },
         {
          "acc": 0,
          "epoch": 21,
          "loss": 0.03298136785552643,
          "mean_squared_error": 0.03298136591911316
         },
         {
          "acc": 0,
          "epoch": 22,
          "loss": 0.032968707843729766,
          "mean_squared_error": 0.032968707382678986
         },
         {
          "acc": 0,
          "epoch": 23,
          "loss": 0.03288138255772024,
          "mean_squared_error": 0.03288138657808304
         },
         {
          "acc": 0,
          "epoch": 24,
          "loss": 0.032821801325103435,
          "mean_squared_error": 0.03282180055975914
         },
         {
          "acc": 0,
          "epoch": 25,
          "loss": 0.03277663768518089,
          "mean_squared_error": 0.032776638865470886
         },
         {
          "acc": 0,
          "epoch": 26,
          "loss": 0.03275256780999722,
          "mean_squared_error": 0.032752569764852524
         },
         {
          "acc": 0,
          "epoch": 27,
          "loss": 0.03263400406530588,
          "mean_squared_error": 0.032634004950523376
         },
         {
          "acc": 0,
          "epoch": 28,
          "loss": 0.03261877109508703,
          "mean_squared_error": 0.032618772238492966
         },
         {
          "acc": 0,
          "epoch": 29,
          "loss": 0.032582548861899,
          "mean_squared_error": 0.03258255124092102
         },
         {
          "acc": 0,
          "epoch": 30,
          "loss": 0.03250134562944422,
          "mean_squared_error": 0.03250134363770485
         },
         {
          "acc": 0,
          "epoch": 31,
          "loss": 0.032435495793671894,
          "mean_squared_error": 0.032435499131679535
         },
         {
          "acc": 0,
          "epoch": 32,
          "loss": 0.03242294040351811,
          "mean_squared_error": 0.03242293745279312
         },
         {
          "acc": 0,
          "epoch": 33,
          "loss": 0.03236598200579681,
          "mean_squared_error": 0.03236598148941994
         },
         {
          "acc": 0,
          "epoch": 34,
          "loss": 0.032292150329835345,
          "mean_squared_error": 0.03229214996099472
         },
         {
          "acc": 0,
          "epoch": 35,
          "loss": 0.03227277889405147,
          "mean_squared_error": 0.03227277845144272
         },
         {
          "acc": 0,
          "epoch": 36,
          "loss": 0.03215507351525939,
          "mean_squared_error": 0.032155074179172516
         },
         {
          "acc": 0,
          "epoch": 37,
          "loss": 0.032170031413362166,
          "mean_squared_error": 0.03217003494501114
         },
         {
          "acc": 0,
          "epoch": 38,
          "loss": 0.03215584856006178,
          "mean_squared_error": 0.0321558453142643
         },
         {
          "acc": 0,
          "epoch": 39,
          "loss": 0.03208873581399422,
          "mean_squared_error": 0.032088737934827805
         },
         {
          "acc": 0,
          "epoch": 40,
          "loss": 0.031948480312481965,
          "mean_squared_error": 0.031948480755090714
         },
         {
          "acc": 0,
          "epoch": 41,
          "loss": 0.031887163343553494,
          "mean_squared_error": 0.03188716247677803
         },
         {
          "acc": 0,
          "epoch": 42,
          "loss": 0.03187574164960349,
          "mean_squared_error": 0.031875740736722946
         },
         {
          "acc": 0,
          "epoch": 43,
          "loss": 0.03182434452937381,
          "mean_squared_error": 0.03182434290647507
         },
         {
          "acc": 0,
          "epoch": 44,
          "loss": 0.031741872356079594,
          "mean_squared_error": 0.03174187242984772
         },
         {
          "acc": 0,
          "epoch": 45,
          "loss": 0.03175268862580899,
          "mean_squared_error": 0.03175269067287445
         },
         {
          "acc": 0,
          "epoch": 46,
          "loss": 0.03164118631641463,
          "mean_squared_error": 0.03164118900895119
         },
         {
          "acc": 0,
          "epoch": 47,
          "loss": 0.031610363190717035,
          "mean_squared_error": 0.031610362231731415
         },
         {
          "acc": 0,
          "epoch": 48,
          "loss": 0.03155932332029437,
          "mean_squared_error": 0.03155932202935219
         },
         {
          "acc": 0,
          "epoch": 49,
          "loss": 0.0314948439303011,
          "mean_squared_error": 0.03149484470486641
         },
         {
          "acc": 0,
          "epoch": 50,
          "loss": 0.031463458617724996,
          "mean_squared_error": 0.03146345913410187
         },
         {
          "acc": 0,
          "epoch": 51,
          "loss": 0.03145819183180828,
          "mean_squared_error": 0.03145819157361984
         },
         {
          "acc": 0,
          "epoch": 52,
          "loss": 0.03133017988414458,
          "mean_squared_error": 0.031330179423093796
         },
         {
          "acc": 0,
          "epoch": 53,
          "loss": 0.031316836724186885,
          "mean_squared_error": 0.03131683170795441
         },
         {
          "acc": 0,
          "epoch": 54,
          "loss": 0.03130169168557271,
          "mean_squared_error": 0.03130168840289116
         },
         {
          "acc": 0,
          "epoch": 55,
          "loss": 0.031243670916203226,
          "mean_squared_error": 0.031243668869137764
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 56,
          "loss": 0.031191627762400278,
          "mean_squared_error": 0.0311916284263134
         },
         {
          "acc": 0,
          "epoch": 57,
          "loss": 0.031141551783179292,
          "mean_squared_error": 0.031141553074121475
         },
         {
          "acc": 0,
          "epoch": 58,
          "loss": 0.031114175288689018,
          "mean_squared_error": 0.03111417405307293
         },
         {
          "acc": 0,
          "epoch": 59,
          "loss": 0.03108880290816916,
          "mean_squared_error": 0.031088802963495255
         },
         {
          "acc": 0,
          "epoch": 60,
          "loss": 0.03105402782116786,
          "mean_squared_error": 0.031054027378559113
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 61,
          "loss": 0.0309105416999595,
          "mean_squared_error": 0.030910542234778404
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 62,
          "loss": 0.030883914394543903,
          "mean_squared_error": 0.030883915722370148
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 63,
          "loss": 0.030827199450076215,
          "mean_squared_error": 0.030827201902866364
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 64,
          "loss": 0.03088259663764793,
          "mean_squared_error": 0.030882595106959343
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 65,
          "loss": 0.03079715559240615,
          "mean_squared_error": 0.03079715557396412
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 66,
          "loss": 0.030680516458088808,
          "mean_squared_error": 0.030680516734719276
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 67,
          "loss": 0.03065123925409695,
          "mean_squared_error": 0.030651239678263664
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 68,
          "loss": 0.03065525338348776,
          "mean_squared_error": 0.030655253678560257
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 69,
          "loss": 0.030605212241263672,
          "mean_squared_error": 0.030605211853981018
         },
         {
          "acc": 0,
          "epoch": 70,
          "loss": 0.03054570705436244,
          "mean_squared_error": 0.030545709654688835
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 71,
          "loss": 0.030508034779588775,
          "mean_squared_error": 0.03050803393125534
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 72,
          "loss": 0.030457480580057247,
          "mean_squared_error": 0.030457479879260063
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 73,
          "loss": 0.03038386163292545,
          "mean_squared_error": 0.03038386069238186
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 74,
          "loss": 0.030408914191740574,
          "mean_squared_error": 0.030408911406993866
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 75,
          "loss": 0.030301479567395578,
          "mean_squared_error": 0.03030148148536682
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 76,
          "loss": 0.03023195015912009,
          "mean_squared_error": 0.03023195080459118
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 77,
          "loss": 0.030251941210267568,
          "mean_squared_error": 0.030251942574977875
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 78,
          "loss": 0.030215765985817013,
          "mean_squared_error": 0.030215764418244362
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 79,
          "loss": 0.030145906686487766,
          "mean_squared_error": 0.030145909637212753
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 80,
          "loss": 0.03004818330380586,
          "mean_squared_error": 0.030048182234168053
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 81,
          "loss": 0.03006077583621044,
          "mean_squared_error": 0.030060773715376854
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 82,
          "loss": 0.03004488964924718,
          "mean_squared_error": 0.030044889077544212
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 83,
          "loss": 0.02996386985967655,
          "mean_squared_error": 0.029963871464133263
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 84,
          "loss": 0.029880246405701825,
          "mean_squared_error": 0.02988024801015854
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 85,
          "loss": 0.029855040962448214,
          "mean_squared_error": 0.029855040833353996
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 86,
          "loss": 0.029895103324462872,
          "mean_squared_error": 0.029895102605223656
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 87,
          "loss": 0.029828595200387557,
          "mean_squared_error": 0.029828593134880066
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 88,
          "loss": 0.02974405829416643,
          "mean_squared_error": 0.02974405698478222
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 89,
          "loss": 0.029714516004418382,
          "mean_squared_error": 0.029714519158005714
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 90,
          "loss": 0.029686745956982716,
          "mean_squared_error": 0.02968674898147583
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 91,
          "loss": 0.029655270518200234,
          "mean_squared_error": 0.029655268415808678
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 92,
          "loss": 0.029676489421341677,
          "mean_squared_error": 0.029676489531993866
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 93,
          "loss": 0.02953866948511931,
          "mean_squared_error": 0.029538672417402267
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 94,
          "loss": 0.029599862007221374,
          "mean_squared_error": 0.029599860310554504
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 95,
          "loss": 0.029460002105719973,
          "mean_squared_error": 0.0294599998742342
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 96,
          "loss": 0.0294485659993226,
          "mean_squared_error": 0.02944856882095337
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 97,
          "loss": 0.02937041147436836,
          "mean_squared_error": 0.029370412230491638
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 98,
          "loss": 0.029371580422514736,
          "mean_squared_error": 0.029371580109000206
         },
         {
          "acc": 0.002475247485563159,
          "epoch": 99,
          "loss": 0.029281474908094594,
          "mean_squared_error": 0.02928147464990616
         }
        ]
       },
       "encoding": {
        "x": {
         "field": "epoch",
         "type": "quantitative"
        },
        "y": {
         "field": "mean_squared_error",
         "type": "quantitative"
        }
       },
       "mark": {
        "opacity": 0.3,
        "type": "area"
       }
      },
      "image/png": "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",
      "text/plain": [
       "<VegaLite 2 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(history_df).mark_area(opacity=0.3).encode(\n",
    "    x='epoch',\n",
    "    y='mean_squared_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "\n",
    "Since this is not a classification task, the accuracy metric cannot be used for this estimator. Instead, a metric such as `'neg_mean_squared_error'` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "reg = LinearRegression(normalize=True, n_jobs=-1)\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network MSE:  594.9763\n",
      "OLS/Linear regression MSE:  21.814922904968263\n"
     ]
    }
   ],
   "source": [
    "reg_neg_mae = abs(cross_val_score(reg, X_test, y_test, cv=5, scoring='neg_mean_squared_error'))\n",
    "reg_mae = reg_neg_mae.mean()\n",
    "print(\"Neural network MSE: \", scores[1])\n",
    "print(\"OLS/Linear regression MSE: \", reg_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform feature engineering and see how that affects your neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 13), (506, 1))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "boston_df = pd.concat([pd.DataFrame(X_train), pd.DataFrame(X_test)])\n",
    "boston_y = pd.concat([pd.DataFrame(y_train), pd.DataFrame(y_test)])\n",
    "boston_df.shape, boston_y.shape\n",
    "#boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df.corr()\n",
    "#Create interaction terms for these pairs w/ high corr. coefs:\n",
    "# 17, 24, 27, 47, 46, 67, 89\n",
    "boston_df[17] = boston_df[1] * boston_df[7]\n",
    "boston_df[24] = boston_df[2] * boston_df[4]\n",
    "boston_df[27] = boston_df[2] * boston_df[7]\n",
    "boston_df[47] = boston_df[4] * boston_df[7]\n",
    "boston_df[46] = boston_df[4] * boston_df[6]\n",
    "boston_df[67] = boston_df[6] * boston_df[7]\n",
    "boston_df[89] = boston_df[8] * boston_df[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 20)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston_df, boston_y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 350us/sample - loss: 91.5482 - mean_squared_error: 91.5482 - acc: 0.0000e+00\n",
      "mean_squared_error: 91.54815673828125\n"
     ]
    }
   ],
   "source": [
    "# Reinitialize model with new input dimensions\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer + hidden layer\n",
    "model.add(Dense(10, input_dim=20, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "# Output layer (no activation for output layer in regression problems)\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Recompile the model\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='sgd',\n",
    "              metrics=['mean_squared_error', 'accuracy'])\n",
    "\n",
    "# Fit and score model\n",
    "history = model.fit(X_train, y_train, epochs=100, verbose=0)\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(f'{model.metrics_names[1]}: {scores[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
