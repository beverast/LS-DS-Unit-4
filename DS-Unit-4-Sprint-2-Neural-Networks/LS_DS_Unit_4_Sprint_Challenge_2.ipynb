{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Perceptron on XOR Gates](#Q2)\n",
    "3. [Multilayer Perceptron](#Q3)\n",
    "4. [Keras MMP](#Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:** A neuron takes each of the input values, multiplies each of them by a weight, sums the products, and then passes the sum through an activation function which produces the final value.\n",
    "- **Input Layer:** The input layer receives input from the dataset(s). The input layer is also called the \"visible layer\" because its the only part that is exposed to and interacts with the data directly. \n",
    "- **Hidden Layer:** They're hidden in the sense that we don't know what their current state is, and their values are neither input nor output data. They're intermediate states of NN computation.\n",
    "- **Output Layer:** Output layers return a vector of values in a suitable format for the problem domain. Typically output values are modified by an activation function to transform it to said suitable format. \n",
    "- **Activation:** The activation function determines if a neuron \"fires\" or not. The activation function, more accurately, determines how much of the signal to pass along from one layer to the next.\n",
    "- **Backpropagation:** Backpropagation is an algorithm for updating the weights of a neural network starting at the output layer and working backwards using various calculus methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptron on AND Gates <a id=\"Q3=2\"></a>\n",
    "\n",
    "Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
    "\n",
    "|x1\t|x2|x3|\ty|\n",
    "|---|---|---|---|\n",
    "1|\t1|\t1|\t1|\n",
    "1|\t0|\t1|\t0|\n",
    "0|\t1|\t1|\t0|\n",
    "0|\t0|\t1|\t0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Perceptron on AND Gates\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[-0.25091976],\n",
      "       [ 0.90142861],\n",
      "       [ 0.46398788]])\n"
     ]
    }
   ],
   "source": [
    "# Initialize inputs and weights. Add bias to X too.\n",
    "np.random.seed(42)\n",
    "\n",
    "X = np.array([\n",
    "    [1,1,1],\n",
    "    [1,0,1],\n",
    "    [0,1,1],\n",
    "    [0,0,1]])\n",
    "y = [[1], [0], [0], [0]]\n",
    "\n",
    "weights = 2 * np.random.random((3,1)) - 1\n",
    "pprint(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define activation function and the derivative \"update\" function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1-sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.75296649],\n",
      "       [0.55306642],\n",
      "       [0.79663861],\n",
      "       [0.61395979]])\n"
     ]
    }
   ],
   "source": [
    "# Calculate weighted sum\n",
    "weighted_sum = np.dot(X, weights)\n",
    "\n",
    "# Calculate activation values for epoch #1\n",
    "activated_output = sigmoid(weighted_sum)\n",
    "pprint(activated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[-0.32535954],\n",
      "       [ 0.78457259],\n",
      "       [ 0.07903399]])\n"
     ]
    }
   ],
   "source": [
    "# Calculate error and update weights\n",
    "error = y - activated_output\n",
    "\n",
    "adjustments = error * sigmoid_derivative(activated_output)\n",
    "weights += np.dot(X.T, adjustments)\n",
    "pprint(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions/Activated Output for 10,000 epochs\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# 10,000 epochs\n",
    "for _ in range(10_000):\n",
    "    # Same procedure as above\n",
    "    weighted_sum = np.dot(X, weights)\n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    error = y - activated_output\n",
    "    adjustments = error * sigmoid_derivative(activated_output)\n",
    "    \n",
    "    # Update weights\n",
    "    weights += np.dot(X.T, adjustments)\n",
    "\n",
    "print(\"Predictions/Activated Output for 10,000 epochs\")\n",
    "print(np.round(activated_output, decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights.\n",
    "Your network must have one hidden layer.\n",
    "You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
    "Train your model on the Heart Disease dataset from UCI:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Imports for Multilayer Perceptron\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13) <class 'numpy.ndarray'>\n",
      "(303, 1) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Split data into X,y and normalize X.\n",
    "X = df.drop(columns='target').values\n",
    "y = np.array(df['target'].values).reshape(-1,1)\n",
    "\n",
    "print(X.shape, type(X))\n",
    "print(y.shape, type(y))\n",
    "\n",
    "X = X / np.amax(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP implementation with Feedforward and Backpropagation\n",
    "class MultilayerPerceptron:\n",
    "    def __init__(self):\n",
    "        # Architecture\n",
    "        self.inputs = 13  # 13 features\n",
    "        self.hidden_nodes = 303\n",
    "        self.output_nodes = 1\n",
    "        \n",
    "        # Initial weights\n",
    "        # 13x303 matrix for first layer\n",
    "        self.weights1 = np.random.randn(self.inputs, self.hidden_nodes)\n",
    "        # 303x1 matrix array for hidden to output\n",
    "        self.weights2 = np.random.randn(self.hidden_nodes, self.output_nodes)\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        # Activation function\n",
    "        return 1 / (1+np.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1-s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        #Weighted sume of inputs and hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.weights1)\n",
    "        \n",
    "        #Acivations of weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # Weight sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
    "        \n",
    "        #Final activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    # HERE LIVES A BUG\n",
    "    def backward(self, X, y, o):\n",
    "        # Calculate error, apply sigmoid derivative\n",
    "        self.o_error = y - o\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
    "        \n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T)\n",
    "        # print(self.z2_error)\n",
    "        \n",
    "        self.z2_delta = self.z2_error*self.sigmoidPrime(self.activated_hidden)\n",
    "        # print(self.z2_delta)\n",
    "        \n",
    "        self.weights1 += X.T.dot(self.z2_delta)\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta) \n",
    "        \n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X, y, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 1---------+\n",
      "Loss: \n",
      " 0.27969423483476347\n",
      "+---------EPOCH 2---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 3---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 4---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 5---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 50---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 100---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 150---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 200---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 250---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 300---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 350---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 400---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 450---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 500---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 550---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 600---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 650---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 700---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 750---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 800---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 850---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 900---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 950---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n",
      "+---------EPOCH 1000---------+\n",
      "Loss: \n",
      " 0.5445544554455446\n"
     ]
    }
   ],
   "source": [
    "nn = MultilayerPerceptron()\n",
    "\n",
    "for i in range(1000):\n",
    "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 50 ==0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
    "        # print('Input: \\n', X)\n",
    "        # print('Actual Output: \\n', y)\n",
    "        # print('Predicted Output: \\n', str(nn.feed_forward(X)))\n",
    "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(X)))))\n",
    "    nn.train(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Keras MMP <a id=\"Q4\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Imports for Keras MLP\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((303, 13), (303, 1))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset already loaded and normalized\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 203 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.6975 - acc: 0.5911 - val_loss: 2.7147 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "203/203 [==============================] - 0s 184us/step - loss: 0.5042 - acc: 0.8128 - val_loss: 1.4931 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "203/203 [==============================] - 0s 189us/step - loss: 0.4671 - acc: 0.8128 - val_loss: 1.6616 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "203/203 [==============================] - 0s 188us/step - loss: 0.4624 - acc: 0.8128 - val_loss: 1.7266 - val_acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "203/203 [==============================] - 0s 183us/step - loss: 0.4638 - acc: 0.8128 - val_loss: 1.6536 - val_acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "203/203 [==============================] - 0s 180us/step - loss: 0.4583 - acc: 0.8128 - val_loss: 1.6590 - val_acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "203/203 [==============================] - 0s 185us/step - loss: 0.4500 - acc: 0.8128 - val_loss: 1.5723 - val_acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "203/203 [==============================] - 0s 179us/step - loss: 0.4446 - acc: 0.8128 - val_loss: 1.8985 - val_acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "203/203 [==============================] - 0s 176us/step - loss: 0.4453 - acc: 0.8128 - val_loss: 1.7340 - val_acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "203/203 [==============================] - 0s 173us/step - loss: 0.4284 - acc: 0.8128 - val_loss: 1.5679 - val_acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "203/203 [==============================] - 0s 172us/step - loss: 0.4232 - acc: 0.8128 - val_loss: 1.6055 - val_acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "203/203 [==============================] - 0s 174us/step - loss: 0.4116 - acc: 0.8128 - val_loss: 1.5032 - val_acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "203/203 [==============================] - 0s 177us/step - loss: 0.4028 - acc: 0.8128 - val_loss: 1.6049 - val_acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "203/203 [==============================] - 0s 175us/step - loss: 0.3996 - acc: 0.8128 - val_loss: 1.8127 - val_acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "203/203 [==============================] - 0s 173us/step - loss: 0.3813 - acc: 0.8128 - val_loss: 1.5729 - val_acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "203/203 [==============================] - 0s 177us/step - loss: 0.3908 - acc: 0.8128 - val_loss: 1.2264 - val_acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "203/203 [==============================] - 0s 170us/step - loss: 0.3665 - acc: 0.8128 - val_loss: 1.1653 - val_acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "203/203 [==============================] - 0s 172us/step - loss: 0.3667 - acc: 0.8227 - val_loss: 2.1486 - val_acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "203/203 [==============================] - 0s 174us/step - loss: 0.4871 - acc: 0.8128 - val_loss: 1.3800 - val_acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "203/203 [==============================] - 0s 175us/step - loss: 0.3471 - acc: 0.8177 - val_loss: 0.8629 - val_acc: 0.3300\n",
      "Epoch 21/50\n",
      "203/203 [==============================] - 0s 175us/step - loss: 0.3631 - acc: 0.8522 - val_loss: 2.0528 - val_acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "203/203 [==============================] - 0s 174us/step - loss: 0.3350 - acc: 0.8177 - val_loss: 0.9214 - val_acc: 0.3100\n",
      "Epoch 23/50\n",
      "203/203 [==============================] - 0s 174us/step - loss: 0.3530 - acc: 0.8522 - val_loss: 2.0828 - val_acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "203/203 [==============================] - 0s 172us/step - loss: 0.3879 - acc: 0.8177 - val_loss: 1.1448 - val_acc: 0.1700\n",
      "Epoch 25/50\n",
      "203/203 [==============================] - 0s 172us/step - loss: 0.3156 - acc: 0.8571 - val_loss: 1.6180 - val_acc: 0.0700\n",
      "Epoch 26/50\n",
      "203/203 [==============================] - 0s 174us/step - loss: 0.3707 - acc: 0.8621 - val_loss: 1.8190 - val_acc: 0.0700\n",
      "Epoch 27/50\n",
      "203/203 [==============================] - 0s 171us/step - loss: 0.4322 - acc: 0.8424 - val_loss: 1.4723 - val_acc: 0.2100\n",
      "Epoch 28/50\n",
      "203/203 [==============================] - 0s 174us/step - loss: 0.3423 - acc: 0.8522 - val_loss: 0.4430 - val_acc: 0.8500\n",
      "Epoch 29/50\n",
      "203/203 [==============================] - 0s 181us/step - loss: 0.4173 - acc: 0.8621 - val_loss: 1.6923 - val_acc: 0.1600\n",
      "Epoch 30/50\n",
      "203/203 [==============================] - 0s 180us/step - loss: 0.4364 - acc: 0.8374 - val_loss: 1.3225 - val_acc: 0.2600\n",
      "Epoch 31/50\n",
      "203/203 [==============================] - 0s 171us/step - loss: 0.3049 - acc: 0.8670 - val_loss: 1.0321 - val_acc: 0.3500\n",
      "Epoch 32/50\n",
      "203/203 [==============================] - 0s 176us/step - loss: 0.3036 - acc: 0.8719 - val_loss: 1.8317 - val_acc: 0.2000\n",
      "Epoch 33/50\n",
      "203/203 [==============================] - 0s 171us/step - loss: 0.4162 - acc: 0.8571 - val_loss: 1.7010 - val_acc: 0.2300\n",
      "Epoch 34/50\n",
      "203/203 [==============================] - 0s 168us/step - loss: 0.4148 - acc: 0.8670 - val_loss: 1.5926 - val_acc: 0.3000\n",
      "Epoch 35/50\n",
      "203/203 [==============================] - 0s 174us/step - loss: 0.4108 - acc: 0.8621 - val_loss: 2.0564 - val_acc: 0.2600\n",
      "Epoch 36/50\n",
      "203/203 [==============================] - 0s 173us/step - loss: 0.3709 - acc: 0.8719 - val_loss: 0.5530 - val_acc: 0.7100\n",
      "Epoch 37/50\n",
      "203/203 [==============================] - 0s 176us/step - loss: 0.3616 - acc: 0.8670 - val_loss: 2.0045 - val_acc: 0.3100\n",
      "Epoch 38/50\n",
      "203/203 [==============================] - 0s 173us/step - loss: 0.4142 - acc: 0.8571 - val_loss: 1.5743 - val_acc: 0.3700\n",
      "Epoch 39/50\n",
      "203/203 [==============================] - 0s 174us/step - loss: 0.3444 - acc: 0.8867 - val_loss: 1.3294 - val_acc: 0.4100\n",
      "Epoch 40/50\n",
      "203/203 [==============================] - 0s 174us/step - loss: 0.3953 - acc: 0.8670 - val_loss: 2.3027 - val_acc: 0.3300\n",
      "Epoch 41/50\n",
      "203/203 [==============================] - 0s 172us/step - loss: 0.3631 - acc: 0.8916 - val_loss: 1.2463 - val_acc: 0.4400\n",
      "Epoch 42/50\n",
      "203/203 [==============================] - 0s 177us/step - loss: 0.3946 - acc: 0.8768 - val_loss: 2.2573 - val_acc: 0.3700\n",
      "Epoch 43/50\n",
      "203/203 [==============================] - 0s 173us/step - loss: 0.3917 - acc: 0.8670 - val_loss: 1.9147 - val_acc: 0.4100\n",
      "Epoch 44/50\n",
      "203/203 [==============================] - 0s 173us/step - loss: 0.3353 - acc: 0.8916 - val_loss: 1.0425 - val_acc: 0.5800\n",
      "Epoch 45/50\n",
      "203/203 [==============================] - 0s 175us/step - loss: 0.3884 - acc: 0.8867 - val_loss: 0.7583 - val_acc: 0.5800\n",
      "Epoch 46/50\n",
      "203/203 [==============================] - 0s 170us/step - loss: 0.4140 - acc: 0.8719 - val_loss: 2.2801 - val_acc: 0.3700\n",
      "Epoch 47/50\n",
      "203/203 [==============================] - 0s 175us/step - loss: 0.3329 - acc: 0.8916 - val_loss: 1.1425 - val_acc: 0.5000\n",
      "Epoch 48/50\n",
      "203/203 [==============================] - 0s 175us/step - loss: 0.3958 - acc: 0.8916 - val_loss: 2.3407 - val_acc: 0.3800\n",
      "Epoch 49/50\n",
      "203/203 [==============================] - 0s 176us/step - loss: 0.3852 - acc: 0.8768 - val_loss: 2.0084 - val_acc: 0.4200\n",
      "Epoch 50/50\n",
      "203/203 [==============================] - 0s 175us/step - loss: 0.3851 - acc: 0.8670 - val_loss: 1.9952 - val_acc: 0.4200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a6c5e32b0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train & Baseline accuracy\n",
    "inputs = X.shape[1]\n",
    "epochs = 50\n",
    "batch_size = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='sigmoid', input_shape=(inputs,)))\n",
    "model.add(Dense(60, activation='sigmoid'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, validation_split=0.33, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a3f8cde48>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.callbacks.History()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tune batch size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "303/303 [==============================] - 1s 2ms/step - loss: 0.6773 - acc: 0.5545\n",
      "Epoch 2/20\n",
      "303/303 [==============================] - 0s 272us/step - loss: 0.6583 - acc: 0.6106\n",
      "Epoch 3/20\n",
      "303/303 [==============================] - 0s 271us/step - loss: 0.6421 - acc: 0.6766\n",
      "Epoch 4/20\n",
      "303/303 [==============================] - 0s 266us/step - loss: 0.6252 - acc: 0.7789\n",
      "Epoch 5/20\n",
      "303/303 [==============================] - 0s 263us/step - loss: 0.6106 - acc: 0.7855\n",
      "Epoch 6/20\n",
      "303/303 [==============================] - 0s 268us/step - loss: 0.5953 - acc: 0.7690\n",
      "Epoch 7/20\n",
      "303/303 [==============================] - 0s 265us/step - loss: 0.5805 - acc: 0.7954\n",
      "Epoch 8/20\n",
      "303/303 [==============================] - 0s 267us/step - loss: 0.5646 - acc: 0.8086\n",
      "Epoch 9/20\n",
      "303/303 [==============================] - 0s 257us/step - loss: 0.5500 - acc: 0.7987\n",
      "Epoch 10/20\n",
      "303/303 [==============================] - 0s 258us/step - loss: 0.5369 - acc: 0.8086\n",
      "Epoch 11/20\n",
      "303/303 [==============================] - 0s 265us/step - loss: 0.5227 - acc: 0.8119\n",
      "Epoch 12/20\n",
      "303/303 [==============================] - 0s 262us/step - loss: 0.5120 - acc: 0.8119\n",
      "Epoch 13/20\n",
      "303/303 [==============================] - 0s 259us/step - loss: 0.4999 - acc: 0.8218\n",
      "Epoch 14/20\n",
      "303/303 [==============================] - 0s 267us/step - loss: 0.4886 - acc: 0.8185\n",
      "Epoch 15/20\n",
      "303/303 [==============================] - 0s 256us/step - loss: 0.4803 - acc: 0.8284\n",
      "Epoch 16/20\n",
      "303/303 [==============================] - 0s 261us/step - loss: 0.4708 - acc: 0.8086\n",
      "Epoch 17/20\n",
      "303/303 [==============================] - 0s 258us/step - loss: 0.4625 - acc: 0.8185\n",
      "Epoch 18/20\n",
      "303/303 [==============================] - 0s 259us/step - loss: 0.4552 - acc: 0.8185\n",
      "Epoch 19/20\n",
      "303/303 [==============================] - 0s 258us/step - loss: 0.4507 - acc: 0.8119\n",
      "Epoch 20/20\n",
      "303/303 [==============================] - 0s 257us/step - loss: 0.4425 - acc: 0.8152\n",
      "Best: 0.33663366833339037 using {'batch_size': 5, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "# Required for KerasClassifier\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=13, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Make output verbose for grading\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "param_grid = {'batch_size': [5, 10, 20, 40, 60, 80],\n",
    "              'epochs': [20]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tune epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [5, 10, 20],\n",
    "              'epochs': [20, 40, 60, 80, 100]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.6633663478955971 using {'batch_size': 5, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "202/202 [==============================] - 3s 13ms/step - loss: 0.6813 - acc: 0.5792\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.6155 - acc: 0.6832\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.5952 - acc: 0.6832\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.5847 - acc: 0.6832\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.5770 - acc: 0.6832\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.5687 - acc: 0.6832\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.5609 - acc: 0.6832\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.5523 - acc: 0.6832\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.5441 - acc: 0.6832\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.5367 - acc: 0.6832\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.5286 - acc: 0.6832\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.5205 - acc: 0.6881\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.5104 - acc: 0.7030\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.5029 - acc: 0.7129\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 374us/step - loss: 0.4931 - acc: 0.7624\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.4866 - acc: 0.7772\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 375us/step - loss: 0.4768 - acc: 0.7871\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.4697 - acc: 0.7921\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.4612 - acc: 0.8020\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 373us/step - loss: 0.4536 - acc: 0.8020\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 374us/step - loss: 0.4467 - acc: 0.8020\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.4388 - acc: 0.8020\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 374us/step - loss: 0.4326 - acc: 0.7970\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.4270 - acc: 0.8119\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 376us/step - loss: 0.4219 - acc: 0.8119\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.4169 - acc: 0.8267\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.4098 - acc: 0.8168\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.4067 - acc: 0.8267\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.4020 - acc: 0.8119\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 374us/step - loss: 0.3967 - acc: 0.8168\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3935 - acc: 0.8218\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3918 - acc: 0.8317\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.3857 - acc: 0.8267\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3836 - acc: 0.8267\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3808 - acc: 0.8218\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 377us/step - loss: 0.3779 - acc: 0.8317\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 373us/step - loss: 0.3747 - acc: 0.8317\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 372us/step - loss: 0.3742 - acc: 0.8317\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3705 - acc: 0.8267\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3691 - acc: 0.8218\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3684 - acc: 0.8218\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.3643 - acc: 0.8267\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 408us/step - loss: 0.3641 - acc: 0.8366\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 0s 376us/step - loss: 0.3621 - acc: 0.8267\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.3623 - acc: 0.8218\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3587 - acc: 0.8267\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3577 - acc: 0.8317\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.3557 - acc: 0.8366\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3558 - acc: 0.8317\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.3543 - acc: 0.8317\n",
      "101/101 [==============================] - 1s 10ms/step\n",
      "202/202 [==============================] - 0s 222us/step\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 3s 13ms/step - loss: 0.7579 - acc: 0.5000\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.6943 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.6758 - acc: 0.5248\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.6639 - acc: 0.6683\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 377us/step - loss: 0.6567 - acc: 0.6881\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.6474 - acc: 0.7030\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.6366 - acc: 0.7327\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 373us/step - loss: 0.6286 - acc: 0.7574\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.6200 - acc: 0.7723\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 368us/step - loss: 0.6117 - acc: 0.7871\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 373us/step - loss: 0.6014 - acc: 0.8020\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 376us/step - loss: 0.5924 - acc: 0.8020\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 372us/step - loss: 0.5836 - acc: 0.8119\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.5757 - acc: 0.7970\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 374us/step - loss: 0.5679 - acc: 0.8020\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 377us/step - loss: 0.5570 - acc: 0.8267\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 368us/step - loss: 0.5473 - acc: 0.8168\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.5382 - acc: 0.8168\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.5309 - acc: 0.8267\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 375us/step - loss: 0.5214 - acc: 0.8069\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 377us/step - loss: 0.5143 - acc: 0.8317\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 0s 375us/step - loss: 0.5069 - acc: 0.8119\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 377us/step - loss: 0.4987 - acc: 0.8218\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.4916 - acc: 0.8168\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 377us/step - loss: 0.4870 - acc: 0.8119\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.4789 - acc: 0.8218\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 375us/step - loss: 0.4730 - acc: 0.8267\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 376us/step - loss: 0.4680 - acc: 0.8168\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 371us/step - loss: 0.4638 - acc: 0.8218\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 373us/step - loss: 0.4574 - acc: 0.8119\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.4530 - acc: 0.8119\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 379us/step - loss: 0.4483 - acc: 0.8119\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 379us/step - loss: 0.4451 - acc: 0.8069\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 373us/step - loss: 0.4399 - acc: 0.8267\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.4367 - acc: 0.8119\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 371us/step - loss: 0.4335 - acc: 0.8218\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 374us/step - loss: 0.4304 - acc: 0.8069\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.4274 - acc: 0.8069\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 371us/step - loss: 0.4274 - acc: 0.8218\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 376us/step - loss: 0.4230 - acc: 0.8119\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 371us/step - loss: 0.4185 - acc: 0.8218\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.4164 - acc: 0.8267\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 374us/step - loss: 0.4140 - acc: 0.8317\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 0s 371us/step - loss: 0.4121 - acc: 0.8267\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.4101 - acc: 0.8366\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.4082 - acc: 0.8366\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.4063 - acc: 0.8366\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.4047 - acc: 0.8317\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 374us/step - loss: 0.4027 - acc: 0.8317\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 375us/step - loss: 0.4010 - acc: 0.8366\n",
      "101/101 [==============================] - 1s 10ms/step\n",
      "202/202 [==============================] - 0s 218us/step\n",
      "Epoch 1/50\n",
      "202/202 [==============================] - 3s 13ms/step - loss: 0.5045 - acc: 0.8168\n",
      "Epoch 2/50\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.4763 - acc: 0.8168\n",
      "Epoch 3/50\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.4650 - acc: 0.8168\n",
      "Epoch 4/50\n",
      "202/202 [==============================] - 0s 429us/step - loss: 0.4570 - acc: 0.8168\n",
      "Epoch 5/50\n",
      "202/202 [==============================] - 0s 377us/step - loss: 0.4505 - acc: 0.8168\n",
      "Epoch 6/50\n",
      "202/202 [==============================] - 0s 379us/step - loss: 0.4441 - acc: 0.8168\n",
      "Epoch 7/50\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.4385 - acc: 0.8168\n",
      "Epoch 8/50\n",
      "202/202 [==============================] - 0s 375us/step - loss: 0.4333 - acc: 0.8168\n",
      "Epoch 9/50\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.4265 - acc: 0.8168\n",
      "Epoch 10/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.4203 - acc: 0.8168\n",
      "Epoch 11/50\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.4146 - acc: 0.8168\n",
      "Epoch 12/50\n",
      "202/202 [==============================] - 0s 375us/step - loss: 0.4073 - acc: 0.8168\n",
      "Epoch 13/50\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.4013 - acc: 0.8168\n",
      "Epoch 14/50\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3951 - acc: 0.8168\n",
      "Epoch 15/50\n",
      "202/202 [==============================] - 0s 372us/step - loss: 0.3901 - acc: 0.8168\n",
      "Epoch 16/50\n",
      "202/202 [==============================] - 0s 373us/step - loss: 0.3835 - acc: 0.8168\n",
      "Epoch 17/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3777 - acc: 0.8168\n",
      "Epoch 18/50\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.3714 - acc: 0.8168\n",
      "Epoch 19/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3663 - acc: 0.8168\n",
      "Epoch 20/50\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.3601 - acc: 0.8267\n",
      "Epoch 21/50\n",
      "202/202 [==============================] - 0s 369us/step - loss: 0.3578 - acc: 0.8465\n",
      "Epoch 22/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3503 - acc: 0.8416\n",
      "Epoch 23/50\n",
      "202/202 [==============================] - 0s 377us/step - loss: 0.3469 - acc: 0.8416\n",
      "Epoch 24/50\n",
      "202/202 [==============================] - 0s 372us/step - loss: 0.3408 - acc: 0.8564\n",
      "Epoch 25/50\n",
      "202/202 [==============================] - 0s 379us/step - loss: 0.3353 - acc: 0.8614\n",
      "Epoch 26/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3317 - acc: 0.8663\n",
      "Epoch 27/50\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.3276 - acc: 0.8713\n",
      "Epoch 28/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3233 - acc: 0.8713\n",
      "Epoch 29/50\n",
      "202/202 [==============================] - 0s 375us/step - loss: 0.3190 - acc: 0.8713\n",
      "Epoch 30/50\n",
      "202/202 [==============================] - 0s 374us/step - loss: 0.3157 - acc: 0.8713\n",
      "Epoch 31/50\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.3123 - acc: 0.8713\n",
      "Epoch 32/50\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3086 - acc: 0.8762\n",
      "Epoch 33/50\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3059 - acc: 0.8762\n",
      "Epoch 34/50\n",
      "202/202 [==============================] - 0s 375us/step - loss: 0.3028 - acc: 0.8812\n",
      "Epoch 35/50\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.3008 - acc: 0.8812\n",
      "Epoch 36/50\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.2968 - acc: 0.8812\n",
      "Epoch 37/50\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.2948 - acc: 0.8812\n",
      "Epoch 38/50\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.2931 - acc: 0.8861\n",
      "Epoch 39/50\n",
      "202/202 [==============================] - 0s 377us/step - loss: 0.2899 - acc: 0.8861\n",
      "Epoch 40/50\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.2871 - acc: 0.8861\n",
      "Epoch 41/50\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2857 - acc: 0.8812\n",
      "Epoch 42/50\n",
      "202/202 [==============================] - 0s 371us/step - loss: 0.2831 - acc: 0.8861\n",
      "Epoch 43/50\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.2819 - acc: 0.8960\n",
      "Epoch 44/50\n",
      "202/202 [==============================] - 0s 372us/step - loss: 0.2799 - acc: 0.8861\n",
      "Epoch 45/50\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2778 - acc: 0.8911\n",
      "Epoch 46/50\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.2769 - acc: 0.9010\n",
      "Epoch 47/50\n",
      "202/202 [==============================] - 0s 379us/step - loss: 0.2742 - acc: 0.9010\n",
      "Epoch 48/50\n",
      "202/202 [==============================] - 0s 375us/step - loss: 0.2732 - acc: 0.9010\n",
      "Epoch 49/50\n",
      "202/202 [==============================] - 0s 376us/step - loss: 0.2718 - acc: 0.9010\n",
      "Epoch 50/50\n",
      "202/202 [==============================] - 0s 368us/step - loss: 0.2704 - acc: 0.9059\n",
      "101/101 [==============================] - 1s 11ms/step\n",
      "202/202 [==============================] - 0s 227us/step\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 3s 14ms/step - loss: 0.6370 - acc: 0.6832\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 0s 407us/step - loss: 0.6180 - acc: 0.6832\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.6064 - acc: 0.6832\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 0s 407us/step - loss: 0.5965 - acc: 0.6832\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.5872 - acc: 0.6832\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.5775 - acc: 0.6832\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.5672 - acc: 0.6832\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.5583 - acc: 0.6832\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.5496 - acc: 0.6832\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.5401 - acc: 0.6832\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.5308 - acc: 0.6832\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.5223 - acc: 0.6931\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.5122 - acc: 0.6980\n",
      "Epoch 14/100\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.5052 - acc: 0.6980\n",
      "Epoch 15/100\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.4947 - acc: 0.7624\n",
      "Epoch 16/100\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.4881 - acc: 0.7723\n",
      "Epoch 17/100\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.4780 - acc: 0.7822\n",
      "Epoch 18/100\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.4718 - acc: 0.7871\n",
      "Epoch 19/100\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.4624 - acc: 0.8020\n",
      "Epoch 20/100\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.4552 - acc: 0.8069\n",
      "Epoch 21/100\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.4481 - acc: 0.8020\n",
      "Epoch 22/100\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.4424 - acc: 0.8020\n",
      "Epoch 23/100\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.4354 - acc: 0.8020\n",
      "Epoch 24/100\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.4289 - acc: 0.8267\n",
      "Epoch 25/100\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.4234 - acc: 0.8317\n",
      "Epoch 26/100\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.4178 - acc: 0.8218\n",
      "Epoch 27/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.4147 - acc: 0.8267\n",
      "Epoch 28/100\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.4098 - acc: 0.8119\n",
      "Epoch 29/100\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.4036 - acc: 0.8218\n",
      "Epoch 30/100\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3996 - acc: 0.8218\n",
      "Epoch 31/100\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3968 - acc: 0.8218\n",
      "Epoch 32/100\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3919 - acc: 0.8168\n",
      "Epoch 33/100\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3905 - acc: 0.8218\n",
      "Epoch 34/100\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3864 - acc: 0.8366\n",
      "Epoch 35/100\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3826 - acc: 0.8267\n",
      "Epoch 36/100\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3805 - acc: 0.8267\n",
      "Epoch 37/100\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3770 - acc: 0.8218\n",
      "Epoch 38/100\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3747 - acc: 0.8218\n",
      "Epoch 39/100\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3722 - acc: 0.8267\n",
      "Epoch 40/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3714 - acc: 0.8317\n",
      "Epoch 41/100\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.3677 - acc: 0.8317\n",
      "Epoch 42/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3669 - acc: 0.8317\n",
      "Epoch 43/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3653 - acc: 0.8317\n",
      "Epoch 44/100\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3631 - acc: 0.8366\n",
      "Epoch 45/100\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3613 - acc: 0.8317\n",
      "Epoch 46/100\n",
      "202/202 [==============================] - 0s 379us/step - loss: 0.3617 - acc: 0.8267\n",
      "Epoch 47/100\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.3597 - acc: 0.8218\n",
      "Epoch 48/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3572 - acc: 0.8317\n",
      "Epoch 49/100\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.3563 - acc: 0.8366\n",
      "Epoch 50/100\n",
      "202/202 [==============================] - 0s 402us/step - loss: 0.3554 - acc: 0.8267\n",
      "Epoch 51/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3556 - acc: 0.8267\n",
      "Epoch 52/100\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3528 - acc: 0.8366\n",
      "Epoch 53/100\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3526 - acc: 0.8267\n",
      "Epoch 54/100\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3513 - acc: 0.8366\n",
      "Epoch 55/100\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.3507 - acc: 0.8317\n",
      "Epoch 56/100\n",
      "202/202 [==============================] - 0s 405us/step - loss: 0.3493 - acc: 0.8366\n",
      "Epoch 57/100\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3486 - acc: 0.8366\n",
      "Epoch 58/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3476 - acc: 0.8366\n",
      "Epoch 59/100\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3475 - acc: 0.8366\n",
      "Epoch 60/100\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3467 - acc: 0.8416\n",
      "Epoch 61/100\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3460 - acc: 0.8416\n",
      "Epoch 62/100\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.3448 - acc: 0.8366\n",
      "Epoch 63/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3459 - acc: 0.8366\n",
      "Epoch 64/100\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3443 - acc: 0.8366\n",
      "Epoch 65/100\n",
      "202/202 [==============================] - 0s 425us/step - loss: 0.3454 - acc: 0.8267\n",
      "Epoch 66/100\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.3434 - acc: 0.8416\n",
      "Epoch 67/100\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3429 - acc: 0.8416\n",
      "Epoch 68/100\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3432 - acc: 0.8267\n",
      "Epoch 69/100\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3426 - acc: 0.8416\n",
      "Epoch 70/100\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3410 - acc: 0.8416\n",
      "Epoch 71/100\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3416 - acc: 0.8416\n",
      "Epoch 72/100\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.3412 - acc: 0.8416\n",
      "Epoch 73/100\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3408 - acc: 0.8416\n",
      "Epoch 74/100\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3407 - acc: 0.8416\n",
      "Epoch 75/100\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.3401 - acc: 0.8416\n",
      "Epoch 76/100\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.3390 - acc: 0.8416\n",
      "Epoch 77/100\n",
      "202/202 [==============================] - 0s 407us/step - loss: 0.3399 - acc: 0.8416\n",
      "Epoch 78/100\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.3381 - acc: 0.8416\n",
      "Epoch 79/100\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3390 - acc: 0.8416\n",
      "Epoch 80/100\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.3382 - acc: 0.8416\n",
      "Epoch 81/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3383 - acc: 0.8416\n",
      "Epoch 82/100\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.3380 - acc: 0.8416\n",
      "Epoch 83/100\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3376 - acc: 0.8416\n",
      "Epoch 84/100\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3404 - acc: 0.8416\n",
      "Epoch 85/100\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.3370 - acc: 0.8416\n",
      "Epoch 86/100\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.3376 - acc: 0.8416\n",
      "Epoch 87/100\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3387 - acc: 0.8416\n",
      "Epoch 88/100\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.3366 - acc: 0.8416\n",
      "Epoch 89/100\n",
      "202/202 [==============================] - 0s 410us/step - loss: 0.3358 - acc: 0.8416\n",
      "Epoch 90/100\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.3366 - acc: 0.8317\n",
      "Epoch 91/100\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.3354 - acc: 0.8416\n",
      "Epoch 92/100\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3357 - acc: 0.8416\n",
      "Epoch 93/100\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3352 - acc: 0.8416\n",
      "Epoch 94/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3369 - acc: 0.8416\n",
      "Epoch 95/100\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.3353 - acc: 0.8366\n",
      "Epoch 96/100\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3347 - acc: 0.8416\n",
      "Epoch 97/100\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3353 - acc: 0.8416\n",
      "Epoch 98/100\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3349 - acc: 0.8366\n",
      "Epoch 99/100\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3359 - acc: 0.8416\n",
      "Epoch 100/100\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3337 - acc: 0.8416\n",
      "101/101 [==============================] - 1s 11ms/step\n",
      "202/202 [==============================] - 0s 231us/step\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 3s 14ms/step - loss: 0.7216 - acc: 0.4851\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 0s 404us/step - loss: 0.7053 - acc: 0.4158\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.6944 - acc: 0.4901\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.6839 - acc: 0.5743\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 0s 409us/step - loss: 0.6756 - acc: 0.6733\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.6659 - acc: 0.6436\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.6549 - acc: 0.7277\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.6463 - acc: 0.7277\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.6364 - acc: 0.7376\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.6272 - acc: 0.7475\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.6185 - acc: 0.8020\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.6103 - acc: 0.7723\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.5997 - acc: 0.7871\n",
      "Epoch 14/100\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.5911 - acc: 0.7970\n",
      "Epoch 15/100\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.5820 - acc: 0.7723\n",
      "Epoch 16/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.5748 - acc: 0.7723\n",
      "Epoch 17/100\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.5644 - acc: 0.7871\n",
      "Epoch 18/100\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.5581 - acc: 0.7822\n",
      "Epoch 19/100\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.5484 - acc: 0.8020\n",
      "Epoch 20/100\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.5390 - acc: 0.8020\n",
      "Epoch 21/100\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.5331 - acc: 0.8069\n",
      "Epoch 22/100\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.5244 - acc: 0.8020\n",
      "Epoch 23/100\n",
      "202/202 [==============================] - 0s 406us/step - loss: 0.5160 - acc: 0.8069\n",
      "Epoch 24/100\n",
      "202/202 [==============================] - 0s 416us/step - loss: 0.5092 - acc: 0.7970\n",
      "Epoch 25/100\n",
      "202/202 [==============================] - 0s 421us/step - loss: 0.5020 - acc: 0.8069\n",
      "Epoch 26/100\n",
      "202/202 [==============================] - 0s 429us/step - loss: 0.4953 - acc: 0.8020\n",
      "Epoch 27/100\n",
      "202/202 [==============================] - 0s 438us/step - loss: 0.4885 - acc: 0.8069\n",
      "Epoch 28/100\n",
      "202/202 [==============================] - 0s 419us/step - loss: 0.4836 - acc: 0.8020\n",
      "Epoch 29/100\n",
      "202/202 [==============================] - 0s 418us/step - loss: 0.4774 - acc: 0.8020\n",
      "Epoch 30/100\n",
      "202/202 [==============================] - 0s 409us/step - loss: 0.4751 - acc: 0.8119\n",
      "Epoch 31/100\n",
      "202/202 [==============================] - 0s 410us/step - loss: 0.4672 - acc: 0.8020\n",
      "Epoch 32/100\n",
      "202/202 [==============================] - 0s 411us/step - loss: 0.4635 - acc: 0.8069\n",
      "Epoch 33/100\n",
      "202/202 [==============================] - 0s 416us/step - loss: 0.4589 - acc: 0.8119\n",
      "Epoch 34/100\n",
      "202/202 [==============================] - 0s 422us/step - loss: 0.4567 - acc: 0.8119\n",
      "Epoch 35/100\n",
      "202/202 [==============================] - 0s 428us/step - loss: 0.4495 - acc: 0.8069\n",
      "Epoch 36/100\n",
      "202/202 [==============================] - 0s 411us/step - loss: 0.4459 - acc: 0.8119\n",
      "Epoch 37/100\n",
      "202/202 [==============================] - 0s 439us/step - loss: 0.4426 - acc: 0.8119\n",
      "Epoch 38/100\n",
      "202/202 [==============================] - 0s 402us/step - loss: 0.4405 - acc: 0.8119\n",
      "Epoch 39/100\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.4354 - acc: 0.8119\n",
      "Epoch 40/100\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.4332 - acc: 0.8119\n",
      "Epoch 41/100\n",
      "202/202 [==============================] - 0s 379us/step - loss: 0.4299 - acc: 0.8168\n",
      "Epoch 42/100\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.4278 - acc: 0.8168\n",
      "Epoch 43/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.4240 - acc: 0.8168\n",
      "Epoch 44/100\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.4220 - acc: 0.8218\n",
      "Epoch 45/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.4196 - acc: 0.8218\n",
      "Epoch 46/100\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.4176 - acc: 0.8218\n",
      "Epoch 47/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.4162 - acc: 0.8218\n",
      "Epoch 48/100\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.4156 - acc: 0.8366\n",
      "Epoch 49/100\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.4123 - acc: 0.8218\n",
      "Epoch 50/100\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.4101 - acc: 0.8119\n",
      "Epoch 51/100\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.4089 - acc: 0.8366\n",
      "Epoch 52/100\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.4063 - acc: 0.8317\n",
      "Epoch 53/100\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.4042 - acc: 0.8317\n",
      "Epoch 54/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.4029 - acc: 0.8317\n",
      "Epoch 55/100\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.4017 - acc: 0.8317\n",
      "Epoch 56/100\n",
      "202/202 [==============================] - 0s 402us/step - loss: 0.4009 - acc: 0.8267\n",
      "Epoch 57/100\n",
      "202/202 [==============================] - 0s 402us/step - loss: 0.3990 - acc: 0.8317\n",
      "Epoch 58/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3980 - acc: 0.8168\n",
      "Epoch 59/100\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.3967 - acc: 0.8416\n",
      "Epoch 60/100\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3973 - acc: 0.8416\n",
      "Epoch 61/100\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.3943 - acc: 0.8416\n",
      "Epoch 62/100\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3954 - acc: 0.8366\n",
      "Epoch 63/100\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3931 - acc: 0.8416\n",
      "Epoch 64/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3917 - acc: 0.8267\n",
      "Epoch 65/100\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3903 - acc: 0.8416\n",
      "Epoch 66/100\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3888 - acc: 0.8416\n",
      "Epoch 67/100\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3882 - acc: 0.8416\n",
      "Epoch 68/100\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3879 - acc: 0.8416\n",
      "Epoch 69/100\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3867 - acc: 0.8416\n",
      "Epoch 70/100\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3861 - acc: 0.8366\n",
      "Epoch 71/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3851 - acc: 0.8366\n",
      "Epoch 72/100\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.3846 - acc: 0.8465\n",
      "Epoch 73/100\n",
      "202/202 [==============================] - 0s 402us/step - loss: 0.3844 - acc: 0.8366\n",
      "Epoch 74/100\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3837 - acc: 0.8416\n",
      "Epoch 75/100\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3826 - acc: 0.8366\n",
      "Epoch 76/100\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3833 - acc: 0.8416\n",
      "Epoch 77/100\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.3808 - acc: 0.8465\n",
      "Epoch 78/100\n",
      "202/202 [==============================] - 0s 405us/step - loss: 0.3810 - acc: 0.8416\n",
      "Epoch 79/100\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.3815 - acc: 0.8416\n",
      "Epoch 80/100\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.3802 - acc: 0.8515\n",
      "Epoch 81/100\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3789 - acc: 0.8416\n",
      "Epoch 82/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3777 - acc: 0.8465\n",
      "Epoch 83/100\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3780 - acc: 0.8465\n",
      "Epoch 84/100\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3769 - acc: 0.8465\n",
      "Epoch 85/100\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.3765 - acc: 0.8515\n",
      "Epoch 86/100\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.3761 - acc: 0.8515\n",
      "Epoch 87/100\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3760 - acc: 0.8515\n",
      "Epoch 88/100\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3763 - acc: 0.8515\n",
      "Epoch 89/100\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.3743 - acc: 0.8515\n",
      "Epoch 90/100\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3750 - acc: 0.8465\n",
      "Epoch 91/100\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3747 - acc: 0.8416\n",
      "Epoch 92/100\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3749 - acc: 0.8515\n",
      "Epoch 93/100\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3738 - acc: 0.8465\n",
      "Epoch 94/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3731 - acc: 0.8465\n",
      "Epoch 95/100\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.3726 - acc: 0.8465\n",
      "Epoch 96/100\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.3727 - acc: 0.8465\n",
      "Epoch 97/100\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.3717 - acc: 0.8515\n",
      "Epoch 98/100\n",
      "202/202 [==============================] - 0s 410us/step - loss: 0.3726 - acc: 0.8515\n",
      "Epoch 99/100\n",
      "202/202 [==============================] - 0s 410us/step - loss: 0.3732 - acc: 0.8416\n",
      "Epoch 100/100\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.3720 - acc: 0.8465\n",
      "101/101 [==============================] - 1s 11ms/step\n",
      "202/202 [==============================] - 0s 223us/step\n",
      "Epoch 1/100\n",
      "202/202 [==============================] - 3s 14ms/step - loss: 0.6636 - acc: 0.6386\n",
      "Epoch 2/100\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.5376 - acc: 0.8168\n",
      "Epoch 3/100\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.4886 - acc: 0.8168\n",
      "Epoch 4/100\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.4702 - acc: 0.8168\n",
      "Epoch 5/100\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.4618 - acc: 0.8168\n",
      "Epoch 6/100\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.4566 - acc: 0.8168\n",
      "Epoch 7/100\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.4518 - acc: 0.8168\n",
      "Epoch 8/100\n",
      "202/202 [==============================] - 0s 408us/step - loss: 0.4460 - acc: 0.8168\n",
      "Epoch 9/100\n",
      "202/202 [==============================] - 0s 408us/step - loss: 0.4428 - acc: 0.8168\n",
      "Epoch 10/100\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.4378 - acc: 0.8168\n",
      "Epoch 11/100\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.4302 - acc: 0.8168\n",
      "Epoch 12/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.4252 - acc: 0.8168\n",
      "Epoch 13/100\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.4205 - acc: 0.8168\n",
      "Epoch 14/100\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.4162 - acc: 0.8168\n",
      "Epoch 15/100\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.4104 - acc: 0.8168\n",
      "Epoch 16/100\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.4051 - acc: 0.8168\n",
      "Epoch 17/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.4000 - acc: 0.8168\n",
      "Epoch 18/100\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3948 - acc: 0.8168\n",
      "Epoch 19/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3897 - acc: 0.8168\n",
      "Epoch 20/100\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.3838 - acc: 0.8168\n",
      "Epoch 21/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3782 - acc: 0.8168\n",
      "Epoch 22/100\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.3740 - acc: 0.8168\n",
      "Epoch 23/100\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.3684 - acc: 0.8168\n",
      "Epoch 24/100\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3632 - acc: 0.8218\n",
      "Epoch 25/100\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.3591 - acc: 0.8416\n",
      "Epoch 26/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3538 - acc: 0.8465\n",
      "Epoch 27/100\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3493 - acc: 0.8515\n",
      "Epoch 28/100\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3451 - acc: 0.8614\n",
      "Epoch 29/100\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.3411 - acc: 0.8614\n",
      "Epoch 30/100\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.3361 - acc: 0.8713\n",
      "Epoch 31/100\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.3324 - acc: 0.8713\n",
      "Epoch 32/100\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.3298 - acc: 0.8663\n",
      "Epoch 33/100\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3250 - acc: 0.8713\n",
      "Epoch 34/100\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3223 - acc: 0.8762\n",
      "Epoch 35/100\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3177 - acc: 0.8762\n",
      "Epoch 36/100\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3146 - acc: 0.8762\n",
      "Epoch 37/100\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.3117 - acc: 0.8762\n",
      "Epoch 38/100\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.3091 - acc: 0.8762\n",
      "Epoch 39/100\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.3061 - acc: 0.8812\n",
      "Epoch 40/100\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3036 - acc: 0.8762\n",
      "Epoch 41/100\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3005 - acc: 0.8812\n",
      "Epoch 42/100\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.2979 - acc: 0.8861\n",
      "Epoch 43/100\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.2961 - acc: 0.8861\n",
      "Epoch 44/100\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.2932 - acc: 0.8861\n",
      "Epoch 45/100\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.2916 - acc: 0.8812\n",
      "Epoch 46/100\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.2892 - acc: 0.8812\n",
      "Epoch 47/100\n",
      "202/202 [==============================] - 0s 420us/step - loss: 0.2869 - acc: 0.8812\n",
      "Epoch 48/100\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.2856 - acc: 0.8861\n",
      "Epoch 49/100\n",
      "202/202 [==============================] - 0s 408us/step - loss: 0.2844 - acc: 0.8861\n",
      "Epoch 50/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.2814 - acc: 0.8911\n",
      "Epoch 51/100\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2804 - acc: 0.8861\n",
      "Epoch 52/100\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.2786 - acc: 0.8960\n",
      "Epoch 53/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.2773 - acc: 0.8960\n",
      "Epoch 54/100\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.2758 - acc: 0.8960\n",
      "Epoch 55/100\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.2743 - acc: 0.8960\n",
      "Epoch 56/100\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.2735 - acc: 0.8911\n",
      "Epoch 57/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.2711 - acc: 0.9010\n",
      "Epoch 58/100\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2704 - acc: 0.9059\n",
      "Epoch 59/100\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2710 - acc: 0.8960\n",
      "Epoch 60/100\n",
      "202/202 [==============================] - 0s 409us/step - loss: 0.2684 - acc: 0.9010\n",
      "Epoch 61/100\n",
      "202/202 [==============================] - 0s 402us/step - loss: 0.2660 - acc: 0.9059\n",
      "Epoch 62/100\n",
      "202/202 [==============================] - 0s 409us/step - loss: 0.2667 - acc: 0.8960\n",
      "Epoch 63/100\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.2656 - acc: 0.8960\n",
      "Epoch 64/100\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.2632 - acc: 0.9010\n",
      "Epoch 65/100\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.2627 - acc: 0.8960\n",
      "Epoch 66/100\n",
      "202/202 [==============================] - 0s 408us/step - loss: 0.2613 - acc: 0.9010\n",
      "Epoch 67/100\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.2605 - acc: 0.9010\n",
      "Epoch 68/100\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.2599 - acc: 0.9010\n",
      "Epoch 69/100\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.2594 - acc: 0.9010\n",
      "Epoch 70/100\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.2582 - acc: 0.9010\n",
      "Epoch 71/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.2571 - acc: 0.9010\n",
      "Epoch 72/100\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.2580 - acc: 0.8960\n",
      "Epoch 73/100\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.2555 - acc: 0.9010\n",
      "Epoch 74/100\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.2551 - acc: 0.9010\n",
      "Epoch 75/100\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2545 - acc: 0.8960\n",
      "Epoch 76/100\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.2541 - acc: 0.9010\n",
      "Epoch 77/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.2535 - acc: 0.9010\n",
      "Epoch 78/100\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2525 - acc: 0.9010\n",
      "Epoch 79/100\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.2526 - acc: 0.9010\n",
      "Epoch 80/100\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.2515 - acc: 0.9010\n",
      "Epoch 81/100\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.2513 - acc: 0.9010\n",
      "Epoch 82/100\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.2510 - acc: 0.9010\n",
      "Epoch 83/100\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.2496 - acc: 0.9059\n",
      "Epoch 84/100\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.2494 - acc: 0.9010\n",
      "Epoch 85/100\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.2492 - acc: 0.9059\n",
      "Epoch 86/100\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.2490 - acc: 0.9059\n",
      "Epoch 87/100\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.2490 - acc: 0.9059\n",
      "Epoch 88/100\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2490 - acc: 0.9059\n",
      "Epoch 89/100\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.2467 - acc: 0.9059\n",
      "Epoch 90/100\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.2478 - acc: 0.9109\n",
      "Epoch 91/100\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.2480 - acc: 0.9059\n",
      "Epoch 92/100\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.2464 - acc: 0.9109\n",
      "Epoch 93/100\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.2463 - acc: 0.9109\n",
      "Epoch 94/100\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.2455 - acc: 0.9109\n",
      "Epoch 95/100\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.2453 - acc: 0.9059\n",
      "Epoch 96/100\n",
      "202/202 [==============================] - 0s 416us/step - loss: 0.2453 - acc: 0.9109\n",
      "Epoch 97/100\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.2467 - acc: 0.8960\n",
      "Epoch 98/100\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.2441 - acc: 0.9109\n",
      "Epoch 99/100\n",
      "202/202 [==============================] - 0s 402us/step - loss: 0.2449 - acc: 0.9109\n",
      "Epoch 100/100\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.2446 - acc: 0.9158\n",
      "101/101 [==============================] - 1s 11ms/step\n",
      "202/202 [==============================] - 0s 234us/step\n",
      "Epoch 1/200\n",
      "202/202 [==============================] - 3s 14ms/step - loss: 0.9290 - acc: 0.3168\n",
      "Epoch 2/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.7530 - acc: 0.3168\n",
      "Epoch 3/200\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.6685 - acc: 0.6337\n",
      "Epoch 4/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.6285 - acc: 0.6832\n",
      "Epoch 5/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.6087 - acc: 0.6832\n",
      "Epoch 6/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.5987 - acc: 0.6832\n",
      "Epoch 7/200\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.5905 - acc: 0.6832\n",
      "Epoch 8/200\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.5832 - acc: 0.6832\n",
      "Epoch 9/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.5782 - acc: 0.6832\n",
      "Epoch 10/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.5699 - acc: 0.6832\n",
      "Epoch 11/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.5638 - acc: 0.6832\n",
      "Epoch 12/200\n",
      "202/202 [==============================] - 0s 421us/step - loss: 0.5565 - acc: 0.6832\n",
      "Epoch 13/200\n",
      "202/202 [==============================] - 0s 697us/step - loss: 0.5506 - acc: 0.6832\n",
      "Epoch 14/200\n",
      "202/202 [==============================] - 0s 415us/step - loss: 0.5414 - acc: 0.6832\n",
      "Epoch 15/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.5330 - acc: 0.6832\n",
      "Epoch 16/200\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.5250 - acc: 0.6881\n",
      "Epoch 17/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.5173 - acc: 0.6980\n",
      "Epoch 18/200\n",
      "202/202 [==============================] - 0s 371us/step - loss: 0.5086 - acc: 0.7228\n",
      "Epoch 19/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.5001 - acc: 0.7426\n",
      "Epoch 20/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.4925 - acc: 0.7426\n",
      "Epoch 21/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.4836 - acc: 0.7673\n",
      "Epoch 22/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.4752 - acc: 0.7772\n",
      "Epoch 23/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.4681 - acc: 0.7970\n",
      "Epoch 24/200\n",
      "202/202 [==============================] - 0s 373us/step - loss: 0.4597 - acc: 0.7970\n",
      "Epoch 25/200\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.4527 - acc: 0.7970\n",
      "Epoch 26/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.4451 - acc: 0.7921\n",
      "Epoch 27/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.4373 - acc: 0.7921\n",
      "Epoch 28/200\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.4313 - acc: 0.8168\n",
      "Epoch 29/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.4250 - acc: 0.8020\n",
      "Epoch 30/200\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.4198 - acc: 0.8168\n",
      "Epoch 31/200\n",
      "202/202 [==============================] - 0s 417us/step - loss: 0.4137 - acc: 0.8168\n",
      "Epoch 32/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.4093 - acc: 0.8168\n",
      "Epoch 33/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.4044 - acc: 0.8168\n",
      "Epoch 34/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.4012 - acc: 0.8168\n",
      "Epoch 35/200\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3960 - acc: 0.8168\n",
      "Epoch 36/200\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.3915 - acc: 0.8218\n",
      "Epoch 37/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.3883 - acc: 0.8168\n",
      "Epoch 38/200\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.3859 - acc: 0.8267\n",
      "Epoch 39/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.3815 - acc: 0.8218\n",
      "Epoch 40/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.3790 - acc: 0.8317\n",
      "Epoch 41/200\n",
      "202/202 [==============================] - 0s 407us/step - loss: 0.3768 - acc: 0.8366\n",
      "Epoch 42/200\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.3737 - acc: 0.8317\n",
      "Epoch 43/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3713 - acc: 0.8267\n",
      "Epoch 44/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3694 - acc: 0.8317\n",
      "Epoch 45/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3680 - acc: 0.8317\n",
      "Epoch 46/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3653 - acc: 0.8317\n",
      "Epoch 47/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3636 - acc: 0.8317\n",
      "Epoch 48/200\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.3620 - acc: 0.8317\n",
      "Epoch 49/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3613 - acc: 0.8317\n",
      "Epoch 50/200\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.3588 - acc: 0.8317\n",
      "Epoch 51/200\n",
      "202/202 [==============================] - 0s 406us/step - loss: 0.3586 - acc: 0.8366\n",
      "Epoch 52/200\n",
      "202/202 [==============================] - 0s 415us/step - loss: 0.3570 - acc: 0.8317\n",
      "Epoch 53/200\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.3552 - acc: 0.8267\n",
      "Epoch 54/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.3539 - acc: 0.8317\n",
      "Epoch 55/200\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.3535 - acc: 0.8267\n",
      "Epoch 56/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3538 - acc: 0.8267\n",
      "Epoch 57/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3516 - acc: 0.8317\n",
      "Epoch 58/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.3508 - acc: 0.8218\n",
      "Epoch 59/200\n",
      "202/202 [==============================] - 0s 379us/step - loss: 0.3498 - acc: 0.8317\n",
      "Epoch 60/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3494 - acc: 0.8317\n",
      "Epoch 61/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3485 - acc: 0.8317\n",
      "Epoch 62/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3475 - acc: 0.8267\n",
      "Epoch 63/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3470 - acc: 0.8366\n",
      "Epoch 64/200\n",
      "202/202 [==============================] - 0s 379us/step - loss: 0.3464 - acc: 0.8366\n",
      "Epoch 65/200\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.3453 - acc: 0.8416\n",
      "Epoch 66/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3443 - acc: 0.8366\n",
      "Epoch 67/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3447 - acc: 0.8366\n",
      "Epoch 68/200\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3435 - acc: 0.8317\n",
      "Epoch 69/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3440 - acc: 0.8366\n",
      "Epoch 70/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.3435 - acc: 0.8317\n",
      "Epoch 71/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3432 - acc: 0.8267\n",
      "Epoch 72/200\n",
      "202/202 [==============================] - 0s 408us/step - loss: 0.3415 - acc: 0.8366\n",
      "Epoch 73/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3417 - acc: 0.8416\n",
      "Epoch 74/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3422 - acc: 0.8416\n",
      "Epoch 75/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3412 - acc: 0.8366\n",
      "Epoch 76/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3404 - acc: 0.8366\n",
      "Epoch 77/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3405 - acc: 0.8416\n",
      "Epoch 78/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3409 - acc: 0.8366\n",
      "Epoch 79/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3401 - acc: 0.8366\n",
      "Epoch 80/200\n",
      "202/202 [==============================] - 0s 405us/step - loss: 0.3398 - acc: 0.8366\n",
      "Epoch 81/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3391 - acc: 0.8416\n",
      "Epoch 82/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3383 - acc: 0.8366\n",
      "Epoch 83/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3383 - acc: 0.8366\n",
      "Epoch 84/200\n",
      "202/202 [==============================] - 0s 408us/step - loss: 0.3386 - acc: 0.8366\n",
      "Epoch 85/200\n",
      "202/202 [==============================] - 0s 422us/step - loss: 0.3381 - acc: 0.8366\n",
      "Epoch 86/200\n",
      "202/202 [==============================] - 0s 406us/step - loss: 0.3392 - acc: 0.8366\n",
      "Epoch 87/200\n",
      "202/202 [==============================] - 0s 414us/step - loss: 0.3377 - acc: 0.8366\n",
      "Epoch 88/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.3380 - acc: 0.8366\n",
      "Epoch 89/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3368 - acc: 0.8366\n",
      "Epoch 90/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3370 - acc: 0.8366\n",
      "Epoch 91/200\n",
      "202/202 [==============================] - 0s 377us/step - loss: 0.3368 - acc: 0.8366\n",
      "Epoch 92/200\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.3370 - acc: 0.8416\n",
      "Epoch 93/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3363 - acc: 0.8416\n",
      "Epoch 94/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3361 - acc: 0.8366\n",
      "Epoch 95/200\n",
      "202/202 [==============================] - 0s 405us/step - loss: 0.3359 - acc: 0.8366\n",
      "Epoch 96/200\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3353 - acc: 0.8366\n",
      "Epoch 97/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.3349 - acc: 0.8416\n",
      "Epoch 98/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.3364 - acc: 0.8366\n",
      "Epoch 99/200\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.3359 - acc: 0.8416\n",
      "Epoch 100/200\n",
      "202/202 [==============================] - 0s 404us/step - loss: 0.3349 - acc: 0.8366\n",
      "Epoch 101/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3346 - acc: 0.8366\n",
      "Epoch 102/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3348 - acc: 0.8416\n",
      "Epoch 103/200\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.3338 - acc: 0.8366\n",
      "Epoch 104/200\n",
      "202/202 [==============================] - 0s 410us/step - loss: 0.3349 - acc: 0.8416\n",
      "Epoch 105/200\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.3336 - acc: 0.8366\n",
      "Epoch 106/200\n",
      "202/202 [==============================] - 0s 377us/step - loss: 0.3340 - acc: 0.8366\n",
      "Epoch 107/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3339 - acc: 0.8416\n",
      "Epoch 108/200\n",
      "202/202 [==============================] - 0s 373us/step - loss: 0.3332 - acc: 0.8416\n",
      "Epoch 109/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.3336 - acc: 0.8366\n",
      "Epoch 110/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3333 - acc: 0.8366\n",
      "Epoch 111/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3361 - acc: 0.8317\n",
      "Epoch 112/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.3331 - acc: 0.8366\n",
      "Epoch 113/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.3330 - acc: 0.8366\n",
      "Epoch 114/200\n",
      "202/202 [==============================] - 0s 405us/step - loss: 0.3330 - acc: 0.8416\n",
      "Epoch 115/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.3339 - acc: 0.8317\n",
      "Epoch 116/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3320 - acc: 0.8366\n",
      "Epoch 117/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3321 - acc: 0.8366\n",
      "Epoch 118/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3319 - acc: 0.8366\n",
      "Epoch 119/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3319 - acc: 0.8366\n",
      "Epoch 120/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3321 - acc: 0.8366\n",
      "Epoch 121/200\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.3331 - acc: 0.8416\n",
      "Epoch 122/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3319 - acc: 0.8366\n",
      "Epoch 123/200\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.3353 - acc: 0.8317\n",
      "Epoch 124/200\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.3339 - acc: 0.8416\n",
      "Epoch 125/200\n",
      "202/202 [==============================] - 0s 377us/step - loss: 0.3340 - acc: 0.8366\n",
      "Epoch 126/200\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.3340 - acc: 0.8416\n",
      "Epoch 127/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3309 - acc: 0.8366\n",
      "Epoch 128/200\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3323 - acc: 0.8366\n",
      "Epoch 129/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3322 - acc: 0.8366\n",
      "Epoch 130/200\n",
      "202/202 [==============================] - 0s 410us/step - loss: 0.3305 - acc: 0.8416\n",
      "Epoch 131/200\n",
      "202/202 [==============================] - 0s 409us/step - loss: 0.3314 - acc: 0.8366\n",
      "Epoch 132/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3331 - acc: 0.8366\n",
      "Epoch 133/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3306 - acc: 0.8366\n",
      "Epoch 134/200\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.3346 - acc: 0.8366\n",
      "Epoch 135/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.3292 - acc: 0.8366\n",
      "Epoch 136/200\n",
      "202/202 [==============================] - 0s 377us/step - loss: 0.3309 - acc: 0.8366\n",
      "Epoch 137/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.3301 - acc: 0.8366\n",
      "Epoch 138/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3300 - acc: 0.8366\n",
      "Epoch 139/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3297 - acc: 0.8366\n",
      "Epoch 140/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3294 - acc: 0.8366\n",
      "Epoch 141/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.3307 - acc: 0.8366\n",
      "Epoch 142/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.3292 - acc: 0.8366\n",
      "Epoch 143/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3316 - acc: 0.8317\n",
      "Epoch 144/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.3290 - acc: 0.8366\n",
      "Epoch 145/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3285 - acc: 0.8366\n",
      "Epoch 146/200\n",
      "202/202 [==============================] - 0s 377us/step - loss: 0.3291 - acc: 0.8366\n",
      "Epoch 147/200\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.3285 - acc: 0.8366\n",
      "Epoch 148/200\n",
      "202/202 [==============================] - 0s 375us/step - loss: 0.3313 - acc: 0.8416\n",
      "Epoch 149/200\n",
      "202/202 [==============================] - 0s 377us/step - loss: 0.3287 - acc: 0.8317\n",
      "Epoch 150/200\n",
      "202/202 [==============================] - 0s 377us/step - loss: 0.3284 - acc: 0.8366\n",
      "Epoch 151/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3279 - acc: 0.8366\n",
      "Epoch 152/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.3283 - acc: 0.8317\n",
      "Epoch 153/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3279 - acc: 0.8366\n",
      "Epoch 154/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3280 - acc: 0.8317\n",
      "Epoch 155/200\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.3287 - acc: 0.8317\n",
      "Epoch 156/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3285 - acc: 0.8317\n",
      "Epoch 157/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.3268 - acc: 0.8366\n",
      "Epoch 158/200\n",
      "202/202 [==============================] - 0s 379us/step - loss: 0.3277 - acc: 0.8366\n",
      "Epoch 159/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3290 - acc: 0.8465\n",
      "Epoch 160/200\n",
      "202/202 [==============================] - 0s 374us/step - loss: 0.3289 - acc: 0.8317\n",
      "Epoch 161/200\n",
      "202/202 [==============================] - 0s 402us/step - loss: 0.3290 - acc: 0.8366\n",
      "Epoch 162/200\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.3285 - acc: 0.8366\n",
      "Epoch 163/200\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.3296 - acc: 0.8416\n",
      "Epoch 164/200\n",
      "202/202 [==============================] - 0s 379us/step - loss: 0.3281 - acc: 0.8366\n",
      "Epoch 165/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3271 - acc: 0.8267\n",
      "Epoch 166/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3266 - acc: 0.8317\n",
      "Epoch 167/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3283 - acc: 0.8317\n",
      "Epoch 168/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3266 - acc: 0.8317\n",
      "Epoch 169/200\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.3271 - acc: 0.8317\n",
      "Epoch 170/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3266 - acc: 0.8267\n",
      "Epoch 171/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3282 - acc: 0.8317\n",
      "Epoch 172/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3264 - acc: 0.8267\n",
      "Epoch 173/200\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3267 - acc: 0.8317\n",
      "Epoch 174/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3267 - acc: 0.8317\n",
      "Epoch 175/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3259 - acc: 0.8317\n",
      "Epoch 176/200\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.3287 - acc: 0.8317\n",
      "Epoch 177/200\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.3262 - acc: 0.8366\n",
      "Epoch 178/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3265 - acc: 0.8267\n",
      "Epoch 179/200\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3255 - acc: 0.8317\n",
      "Epoch 180/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3256 - acc: 0.8317\n",
      "Epoch 181/200\n",
      "202/202 [==============================] - 0s 375us/step - loss: 0.3261 - acc: 0.8317\n",
      "Epoch 182/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.3253 - acc: 0.8267\n",
      "Epoch 183/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3265 - acc: 0.8317\n",
      "Epoch 184/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3256 - acc: 0.8416\n",
      "Epoch 185/200\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.3262 - acc: 0.8267\n",
      "Epoch 186/200\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.3262 - acc: 0.8317\n",
      "Epoch 187/200\n",
      "202/202 [==============================] - 0s 376us/step - loss: 0.3251 - acc: 0.8317\n",
      "Epoch 188/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3250 - acc: 0.8267\n",
      "Epoch 189/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3243 - acc: 0.8317\n",
      "Epoch 190/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3254 - acc: 0.8366\n",
      "Epoch 191/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3242 - acc: 0.8416\n",
      "Epoch 192/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.3254 - acc: 0.8366\n",
      "Epoch 193/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3271 - acc: 0.8267\n",
      "Epoch 194/200\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3254 - acc: 0.8465\n",
      "Epoch 195/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3242 - acc: 0.8317\n",
      "Epoch 196/200\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.3248 - acc: 0.8366\n",
      "Epoch 197/200\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.3243 - acc: 0.8267\n",
      "Epoch 198/200\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.3242 - acc: 0.8366\n",
      "Epoch 199/200\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3247 - acc: 0.8267\n",
      "Epoch 200/200\n",
      "202/202 [==============================] - 0s 413us/step - loss: 0.3233 - acc: 0.8317\n",
      "101/101 [==============================] - 1s 11ms/step\n",
      "202/202 [==============================] - 0s 231us/step\n",
      "Epoch 1/200\n",
      "202/202 [==============================] - 3s 15ms/step - loss: 0.7121 - acc: 0.5000\n",
      "Epoch 2/200\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.6781 - acc: 0.5099\n",
      "Epoch 3/200\n",
      "202/202 [==============================] - 0s 413us/step - loss: 0.6651 - acc: 0.6782\n",
      "Epoch 4/200\n",
      "202/202 [==============================] - 0s 409us/step - loss: 0.6550 - acc: 0.6188\n",
      "Epoch 5/200\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.6413 - acc: 0.7772\n",
      "Epoch 6/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.6324 - acc: 0.7525\n",
      "Epoch 7/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.6215 - acc: 0.7723\n",
      "Epoch 8/200\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.6105 - acc: 0.7871\n",
      "Epoch 9/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.6037 - acc: 0.7525\n",
      "Epoch 10/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.5907 - acc: 0.7970\n",
      "Epoch 11/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.5802 - acc: 0.8069\n",
      "Epoch 12/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.5717 - acc: 0.8020\n",
      "Epoch 13/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.5618 - acc: 0.8168\n",
      "Epoch 14/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.5520 - acc: 0.8069\n",
      "Epoch 15/200\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.5437 - acc: 0.8119\n",
      "Epoch 16/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.5341 - acc: 0.8168\n",
      "Epoch 17/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.5282 - acc: 0.8069\n",
      "Epoch 18/200\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.5181 - acc: 0.8020\n",
      "Epoch 19/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.5106 - acc: 0.8069\n",
      "Epoch 20/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.5039 - acc: 0.8119\n",
      "Epoch 21/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.4981 - acc: 0.8069\n",
      "Epoch 22/200\n",
      "202/202 [==============================] - 0s 402us/step - loss: 0.4892 - acc: 0.8119\n",
      "Epoch 23/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.4828 - acc: 0.8168\n",
      "Epoch 24/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.4772 - acc: 0.8069\n",
      "Epoch 25/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.4710 - acc: 0.8119\n",
      "Epoch 26/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.4659 - acc: 0.8168\n",
      "Epoch 27/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.4604 - acc: 0.8267\n",
      "Epoch 28/200\n",
      "202/202 [==============================] - 0s 402us/step - loss: 0.4556 - acc: 0.8218\n",
      "Epoch 29/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.4517 - acc: 0.8168\n",
      "Epoch 30/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.4480 - acc: 0.8069\n",
      "Epoch 31/200\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.4428 - acc: 0.8020\n",
      "Epoch 32/200\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.4396 - acc: 0.8168\n",
      "Epoch 33/200\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.4362 - acc: 0.8069\n",
      "Epoch 34/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.4334 - acc: 0.8020\n",
      "Epoch 35/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.4309 - acc: 0.8119\n",
      "Epoch 36/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.4269 - acc: 0.8119\n",
      "Epoch 37/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.4239 - acc: 0.8168\n",
      "Epoch 38/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.4210 - acc: 0.8267\n",
      "Epoch 39/200\n",
      "202/202 [==============================] - 0s 413us/step - loss: 0.4183 - acc: 0.8267\n",
      "Epoch 40/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.4177 - acc: 0.8168\n",
      "Epoch 41/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.4149 - acc: 0.8317\n",
      "Epoch 42/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.4127 - acc: 0.8317\n",
      "Epoch 43/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.4102 - acc: 0.8267\n",
      "Epoch 44/200\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.4087 - acc: 0.8317\n",
      "Epoch 45/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.4063 - acc: 0.8267\n",
      "Epoch 46/200\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.4062 - acc: 0.8317\n",
      "Epoch 47/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.4044 - acc: 0.8218\n",
      "Epoch 48/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.4023 - acc: 0.8168\n",
      "Epoch 49/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.4008 - acc: 0.8218\n",
      "Epoch 50/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3992 - acc: 0.8366\n",
      "Epoch 51/200\n",
      "202/202 [==============================] - 0s 407us/step - loss: 0.3981 - acc: 0.8317\n",
      "Epoch 52/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.3970 - acc: 0.8317\n",
      "Epoch 53/200\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.3948 - acc: 0.8317\n",
      "Epoch 54/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3948 - acc: 0.8267\n",
      "Epoch 55/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3927 - acc: 0.8317\n",
      "Epoch 56/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3928 - acc: 0.8317\n",
      "Epoch 57/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3934 - acc: 0.8317\n",
      "Epoch 58/200\n",
      "202/202 [==============================] - 0s 407us/step - loss: 0.3900 - acc: 0.8317\n",
      "Epoch 59/200\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.3889 - acc: 0.8366\n",
      "Epoch 60/200\n",
      "202/202 [==============================] - 0s 404us/step - loss: 0.3881 - acc: 0.8366\n",
      "Epoch 61/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.3888 - acc: 0.8317\n",
      "Epoch 62/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.3862 - acc: 0.8416\n",
      "Epoch 63/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3883 - acc: 0.8416\n",
      "Epoch 64/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3855 - acc: 0.8366\n",
      "Epoch 65/200\n",
      "202/202 [==============================] - 0s 402us/step - loss: 0.3836 - acc: 0.8366\n",
      "Epoch 66/200\n",
      "202/202 [==============================] - 0s 418us/step - loss: 0.3856 - acc: 0.8366\n",
      "Epoch 67/200\n",
      "202/202 [==============================] - 0s 404us/step - loss: 0.3828 - acc: 0.8317\n",
      "Epoch 68/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3828 - acc: 0.8416\n",
      "Epoch 69/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3840 - acc: 0.8515\n",
      "Epoch 70/200\n",
      "202/202 [==============================] - 0s 423us/step - loss: 0.3809 - acc: 0.8416\n",
      "Epoch 71/200\n",
      "202/202 [==============================] - 0s 406us/step - loss: 0.3802 - acc: 0.8465\n",
      "Epoch 72/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.3797 - acc: 0.8416\n",
      "Epoch 73/200\n",
      "202/202 [==============================] - 0s 404us/step - loss: 0.3781 - acc: 0.8465\n",
      "Epoch 74/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.3775 - acc: 0.8465\n",
      "Epoch 75/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3781 - acc: 0.8465\n",
      "Epoch 76/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3784 - acc: 0.8564\n",
      "Epoch 77/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3755 - acc: 0.8465\n",
      "Epoch 78/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3761 - acc: 0.8366\n",
      "Epoch 79/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3751 - acc: 0.8465\n",
      "Epoch 80/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3751 - acc: 0.8515\n",
      "Epoch 81/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3756 - acc: 0.8416\n",
      "Epoch 82/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3749 - acc: 0.8366\n",
      "Epoch 83/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.3731 - acc: 0.8564\n",
      "Epoch 84/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3738 - acc: 0.8416\n",
      "Epoch 85/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3725 - acc: 0.8465\n",
      "Epoch 86/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.3726 - acc: 0.8416\n",
      "Epoch 87/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.3724 - acc: 0.8416\n",
      "Epoch 88/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.3715 - acc: 0.8515\n",
      "Epoch 89/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3734 - acc: 0.8614\n",
      "Epoch 90/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3710 - acc: 0.8416\n",
      "Epoch 91/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3703 - acc: 0.8465\n",
      "Epoch 92/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3698 - acc: 0.8564\n",
      "Epoch 93/200\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.3690 - acc: 0.8366\n",
      "Epoch 94/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3721 - acc: 0.8465\n",
      "Epoch 95/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3686 - acc: 0.8416\n",
      "Epoch 96/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3683 - acc: 0.8515\n",
      "Epoch 97/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.3683 - acc: 0.8564\n",
      "Epoch 98/200\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.3691 - acc: 0.8515\n",
      "Epoch 99/200\n",
      "202/202 [==============================] - 0s 412us/step - loss: 0.3675 - acc: 0.8564\n",
      "Epoch 100/200\n",
      "202/202 [==============================] - 0s 404us/step - loss: 0.3679 - acc: 0.8366\n",
      "Epoch 101/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3670 - acc: 0.8416\n",
      "Epoch 102/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3676 - acc: 0.8614\n",
      "Epoch 103/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3683 - acc: 0.8416\n",
      "Epoch 104/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3666 - acc: 0.8515\n",
      "Epoch 105/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3658 - acc: 0.8564\n",
      "Epoch 106/200\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.3665 - acc: 0.8515\n",
      "Epoch 107/200\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.3655 - acc: 0.8515\n",
      "Epoch 108/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.3680 - acc: 0.8515\n",
      "Epoch 109/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3657 - acc: 0.8465\n",
      "Epoch 110/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3640 - acc: 0.8564\n",
      "Epoch 111/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3648 - acc: 0.8515\n",
      "Epoch 112/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3653 - acc: 0.8515\n",
      "Epoch 113/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3641 - acc: 0.8614\n",
      "Epoch 114/200\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.3647 - acc: 0.8515\n",
      "Epoch 115/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3641 - acc: 0.8564\n",
      "Epoch 116/200\n",
      "202/202 [==============================] - 0s 408us/step - loss: 0.3629 - acc: 0.8515\n",
      "Epoch 117/200\n",
      "202/202 [==============================] - 0s 417us/step - loss: 0.3631 - acc: 0.8564\n",
      "Epoch 118/200\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.3642 - acc: 0.8515\n",
      "Epoch 119/200\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.3631 - acc: 0.8564\n",
      "Epoch 120/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3638 - acc: 0.8564\n",
      "Epoch 121/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.3631 - acc: 0.8465\n",
      "Epoch 122/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3620 - acc: 0.8614\n",
      "Epoch 123/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.3619 - acc: 0.8564\n",
      "Epoch 124/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3608 - acc: 0.8564\n",
      "Epoch 125/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3613 - acc: 0.8614\n",
      "Epoch 126/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3622 - acc: 0.8515\n",
      "Epoch 127/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3605 - acc: 0.8614\n",
      "Epoch 128/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3611 - acc: 0.8614\n",
      "Epoch 129/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3612 - acc: 0.8564\n",
      "Epoch 130/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3608 - acc: 0.8564\n",
      "Epoch 131/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3606 - acc: 0.8614\n",
      "Epoch 132/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.3598 - acc: 0.8564\n",
      "Epoch 133/200\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.3596 - acc: 0.8614\n",
      "Epoch 134/200\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.3592 - acc: 0.8614\n",
      "Epoch 135/200\n",
      "202/202 [==============================] - 0s 408us/step - loss: 0.3594 - acc: 0.8614\n",
      "Epoch 136/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3588 - acc: 0.8614\n",
      "Epoch 137/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3595 - acc: 0.8564\n",
      "Epoch 138/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3580 - acc: 0.8564\n",
      "Epoch 139/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3585 - acc: 0.8564\n",
      "Epoch 140/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3579 - acc: 0.8614\n",
      "Epoch 141/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.3592 - acc: 0.8614\n",
      "Epoch 142/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3574 - acc: 0.8614\n",
      "Epoch 143/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3611 - acc: 0.8614\n",
      "Epoch 144/200\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.3573 - acc: 0.8614\n",
      "Epoch 145/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3580 - acc: 0.8515\n",
      "Epoch 146/200\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.3571 - acc: 0.8564\n",
      "Epoch 147/200\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.3565 - acc: 0.8614\n",
      "Epoch 148/200\n",
      "202/202 [==============================] - 0s 410us/step - loss: 0.3561 - acc: 0.8564\n",
      "Epoch 149/200\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.3561 - acc: 0.8614\n",
      "Epoch 150/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3571 - acc: 0.8515\n",
      "Epoch 151/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3559 - acc: 0.8564\n",
      "Epoch 152/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3561 - acc: 0.8515\n",
      "Epoch 153/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3558 - acc: 0.8564\n",
      "Epoch 154/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3552 - acc: 0.8515\n",
      "Epoch 155/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3548 - acc: 0.8515\n",
      "Epoch 156/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.3553 - acc: 0.8564\n",
      "Epoch 157/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3556 - acc: 0.8564\n",
      "Epoch 158/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.3549 - acc: 0.8564\n",
      "Epoch 159/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3539 - acc: 0.8564\n",
      "Epoch 160/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3550 - acc: 0.8564\n",
      "Epoch 161/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3541 - acc: 0.8564\n",
      "Epoch 162/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3551 - acc: 0.8614\n",
      "Epoch 163/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3552 - acc: 0.8515\n",
      "Epoch 164/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3542 - acc: 0.8515\n",
      "Epoch 165/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3538 - acc: 0.8564\n",
      "Epoch 166/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.3538 - acc: 0.8564\n",
      "Epoch 167/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3543 - acc: 0.8564\n",
      "Epoch 168/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3531 - acc: 0.8564\n",
      "Epoch 169/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3535 - acc: 0.8564\n",
      "Epoch 170/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.3524 - acc: 0.8564\n",
      "Epoch 171/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3524 - acc: 0.8515\n",
      "Epoch 172/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3519 - acc: 0.8564\n",
      "Epoch 173/200\n",
      "202/202 [==============================] - 0s 378us/step - loss: 0.3534 - acc: 0.8515\n",
      "Epoch 174/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3538 - acc: 0.8564\n",
      "Epoch 175/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3528 - acc: 0.8564\n",
      "Epoch 176/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3516 - acc: 0.8564\n",
      "Epoch 177/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3519 - acc: 0.8564\n",
      "Epoch 178/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3529 - acc: 0.8564\n",
      "Epoch 179/200\n",
      "202/202 [==============================] - 0s 407us/step - loss: 0.3517 - acc: 0.8564\n",
      "Epoch 180/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3508 - acc: 0.8564\n",
      "Epoch 181/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3510 - acc: 0.8564\n",
      "Epoch 182/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.3501 - acc: 0.8614\n",
      "Epoch 183/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3508 - acc: 0.8515\n",
      "Epoch 184/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.3504 - acc: 0.8515\n",
      "Epoch 185/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3522 - acc: 0.8564\n",
      "Epoch 186/200\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.3513 - acc: 0.8515\n",
      "Epoch 187/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3507 - acc: 0.8614\n",
      "Epoch 188/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3503 - acc: 0.8564\n",
      "Epoch 189/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3513 - acc: 0.8614\n",
      "Epoch 190/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.3497 - acc: 0.8564\n",
      "Epoch 191/200\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.3503 - acc: 0.8515\n",
      "Epoch 192/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3488 - acc: 0.8564\n",
      "Epoch 193/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.3485 - acc: 0.8564\n",
      "Epoch 194/200\n",
      "202/202 [==============================] - 0s 408us/step - loss: 0.3498 - acc: 0.8564\n",
      "Epoch 195/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.3481 - acc: 0.8564\n",
      "Epoch 196/200\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.3487 - acc: 0.8515\n",
      "Epoch 197/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.3482 - acc: 0.8564\n",
      "Epoch 198/200\n",
      "202/202 [==============================] - 0s 406us/step - loss: 0.3495 - acc: 0.8564\n",
      "Epoch 199/200\n",
      "202/202 [==============================] - 0s 445us/step - loss: 0.3476 - acc: 0.8564\n",
      "Epoch 200/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3478 - acc: 0.8564\n",
      "101/101 [==============================] - 1s 11ms/step\n",
      "202/202 [==============================] - 0s 219us/step\n",
      "Epoch 1/200\n",
      "202/202 [==============================] - 3s 15ms/step - loss: 0.5300 - acc: 0.8168\n",
      "Epoch 2/200\n",
      "202/202 [==============================] - 0s 414us/step - loss: 0.4817 - acc: 0.8168\n",
      "Epoch 3/200\n",
      "202/202 [==============================] - 0s 411us/step - loss: 0.4676 - acc: 0.8168\n",
      "Epoch 4/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.4605 - acc: 0.8168\n",
      "Epoch 5/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.4545 - acc: 0.8168\n",
      "Epoch 6/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.4496 - acc: 0.8168\n",
      "Epoch 7/200\n",
      "202/202 [==============================] - 0s 409us/step - loss: 0.4442 - acc: 0.8168\n",
      "Epoch 8/200\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.4385 - acc: 0.8168\n",
      "Epoch 9/200\n",
      "202/202 [==============================] - 0s 407us/step - loss: 0.4332 - acc: 0.8168\n",
      "Epoch 10/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.4286 - acc: 0.8168\n",
      "Epoch 11/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.4227 - acc: 0.8168\n",
      "Epoch 12/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.4166 - acc: 0.8168\n",
      "Epoch 13/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.4111 - acc: 0.8168\n",
      "Epoch 14/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.4053 - acc: 0.8168\n",
      "Epoch 15/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.4017 - acc: 0.8168\n",
      "Epoch 16/200\n",
      "202/202 [==============================] - 0s 405us/step - loss: 0.3948 - acc: 0.8168\n",
      "Epoch 17/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.3885 - acc: 0.8168\n",
      "Epoch 18/200\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.3831 - acc: 0.8168\n",
      "Epoch 19/200\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.3768 - acc: 0.8168\n",
      "Epoch 20/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3727 - acc: 0.8168\n",
      "Epoch 21/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.3657 - acc: 0.8218\n",
      "Epoch 22/200\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.3614 - acc: 0.8317\n",
      "Epoch 23/200\n",
      "202/202 [==============================] - 0s 411us/step - loss: 0.3557 - acc: 0.8465\n",
      "Epoch 24/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.3503 - acc: 0.8564\n",
      "Epoch 25/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.3468 - acc: 0.8515\n",
      "Epoch 26/200\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.3413 - acc: 0.8614\n",
      "Epoch 27/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3367 - acc: 0.8614\n",
      "Epoch 28/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.3321 - acc: 0.8663\n",
      "Epoch 29/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.3281 - acc: 0.8713\n",
      "Epoch 30/200\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.3249 - acc: 0.8713\n",
      "Epoch 31/200\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.3202 - acc: 0.8762\n",
      "Epoch 32/200\n",
      "202/202 [==============================] - 0s 410us/step - loss: 0.3168 - acc: 0.8762\n",
      "Epoch 33/200\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.3142 - acc: 0.8762\n",
      "Epoch 34/200\n",
      "202/202 [==============================] - 0s 402us/step - loss: 0.3102 - acc: 0.8762\n",
      "Epoch 35/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3067 - acc: 0.8762\n",
      "Epoch 36/200\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.3039 - acc: 0.8812\n",
      "Epoch 37/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.3010 - acc: 0.8861\n",
      "Epoch 38/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.2991 - acc: 0.8861\n",
      "Epoch 39/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.2957 - acc: 0.8861\n",
      "Epoch 40/200\n",
      "202/202 [==============================] - 0s 405us/step - loss: 0.2942 - acc: 0.8861\n",
      "Epoch 41/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.2911 - acc: 0.8861\n",
      "Epoch 42/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.2891 - acc: 0.8812\n",
      "Epoch 43/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.2874 - acc: 0.8861\n",
      "Epoch 44/200\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.2853 - acc: 0.8812\n",
      "Epoch 45/200\n",
      "202/202 [==============================] - 0s 402us/step - loss: 0.2834 - acc: 0.8861\n",
      "Epoch 46/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.2819 - acc: 0.8911\n",
      "Epoch 47/200\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.2790 - acc: 0.8960\n",
      "Epoch 48/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.2772 - acc: 0.8960\n",
      "Epoch 49/200\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.2772 - acc: 0.8911\n",
      "Epoch 50/200\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.2751 - acc: 0.9059\n",
      "Epoch 51/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.2730 - acc: 0.8960\n",
      "Epoch 52/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.2704 - acc: 0.9010\n",
      "Epoch 53/200\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.2712 - acc: 0.8960\n",
      "Epoch 54/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.2683 - acc: 0.9010\n",
      "Epoch 55/200\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.2699 - acc: 0.9010\n",
      "Epoch 56/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2664 - acc: 0.9059\n",
      "Epoch 57/200\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.2655 - acc: 0.9010\n",
      "Epoch 58/200\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.2643 - acc: 0.9059\n",
      "Epoch 59/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2626 - acc: 0.9010\n",
      "Epoch 60/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.2626 - acc: 0.9010\n",
      "Epoch 61/200\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.2610 - acc: 0.9010\n",
      "Epoch 62/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.2599 - acc: 0.9010\n",
      "Epoch 63/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.2588 - acc: 0.9010\n",
      "Epoch 64/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.2592 - acc: 0.8960\n",
      "Epoch 65/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2594 - acc: 0.9010\n",
      "Epoch 66/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.2566 - acc: 0.9010\n",
      "Epoch 67/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.2560 - acc: 0.9010\n",
      "Epoch 68/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2557 - acc: 0.9010\n",
      "Epoch 69/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.2547 - acc: 0.9010\n",
      "Epoch 70/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2546 - acc: 0.9010\n",
      "Epoch 71/200\n",
      "202/202 [==============================] - 0s 407us/step - loss: 0.2532 - acc: 0.9010\n",
      "Epoch 72/200\n",
      "202/202 [==============================] - 0s 410us/step - loss: 0.2538 - acc: 0.8960\n",
      "Epoch 73/200\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.2529 - acc: 0.9010\n",
      "Epoch 74/200\n",
      "202/202 [==============================] - 0s 404us/step - loss: 0.2515 - acc: 0.9010\n",
      "Epoch 75/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2515 - acc: 0.9010\n",
      "Epoch 76/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2512 - acc: 0.9010\n",
      "Epoch 77/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.2515 - acc: 0.9059\n",
      "Epoch 78/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.2497 - acc: 0.9010\n",
      "Epoch 79/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.2491 - acc: 0.9010\n",
      "Epoch 80/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2487 - acc: 0.9059\n",
      "Epoch 81/200\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.2480 - acc: 0.9059\n",
      "Epoch 82/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.2478 - acc: 0.9059\n",
      "Epoch 83/200\n",
      "202/202 [==============================] - 0s 402us/step - loss: 0.2471 - acc: 0.9059\n",
      "Epoch 84/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.2493 - acc: 0.9059\n",
      "Epoch 85/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.2469 - acc: 0.9059\n",
      "Epoch 86/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.2465 - acc: 0.9109\n",
      "Epoch 87/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2458 - acc: 0.9059\n",
      "Epoch 88/200\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.2456 - acc: 0.9059\n",
      "Epoch 89/200\n",
      "202/202 [==============================] - 0s 416us/step - loss: 0.2447 - acc: 0.9109\n",
      "Epoch 90/200\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.2454 - acc: 0.9158\n",
      "Epoch 91/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.2444 - acc: 0.9059\n",
      "Epoch 92/200\n",
      "202/202 [==============================] - 0s 407us/step - loss: 0.2444 - acc: 0.9158\n",
      "Epoch 93/200\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.2442 - acc: 0.9109\n",
      "Epoch 94/200\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.2440 - acc: 0.9059\n",
      "Epoch 95/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.2439 - acc: 0.9109\n",
      "Epoch 96/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.2438 - acc: 0.9158\n",
      "Epoch 97/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.2429 - acc: 0.9158\n",
      "Epoch 98/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.2435 - acc: 0.9158\n",
      "Epoch 99/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2424 - acc: 0.9158\n",
      "Epoch 100/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2438 - acc: 0.9109\n",
      "Epoch 101/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.2419 - acc: 0.9158\n",
      "Epoch 102/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.2417 - acc: 0.9158\n",
      "Epoch 103/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2411 - acc: 0.9158\n",
      "Epoch 104/200\n",
      "202/202 [==============================] - 0s 425us/step - loss: 0.2418 - acc: 0.9158\n",
      "Epoch 105/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2417 - acc: 0.9158\n",
      "Epoch 106/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.2433 - acc: 0.9109\n",
      "Epoch 107/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.2411 - acc: 0.9158\n",
      "Epoch 108/200\n",
      "202/202 [==============================] - 0s 382us/step - loss: 0.2406 - acc: 0.9208\n",
      "Epoch 109/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.2404 - acc: 0.9158\n",
      "Epoch 110/200\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.2400 - acc: 0.9109\n",
      "Epoch 111/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.2399 - acc: 0.9158\n",
      "Epoch 112/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.2406 - acc: 0.9109\n",
      "Epoch 113/200\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.2396 - acc: 0.9158\n",
      "Epoch 114/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.2412 - acc: 0.9158\n",
      "Epoch 115/200\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.2394 - acc: 0.9158\n",
      "Epoch 116/200\n",
      "202/202 [==============================] - 0s 402us/step - loss: 0.2393 - acc: 0.9158\n",
      "Epoch 117/200\n",
      "202/202 [==============================] - 0s 410us/step - loss: 0.2423 - acc: 0.9158\n",
      "Epoch 118/200\n",
      "202/202 [==============================] - 0s 402us/step - loss: 0.2404 - acc: 0.9109\n",
      "Epoch 119/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.2398 - acc: 0.9208\n",
      "Epoch 120/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2390 - acc: 0.9208\n",
      "Epoch 121/200\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.2400 - acc: 0.9158\n",
      "Epoch 122/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2385 - acc: 0.9158\n",
      "Epoch 123/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.2389 - acc: 0.9208\n",
      "Epoch 124/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.2391 - acc: 0.9158\n",
      "Epoch 125/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.2382 - acc: 0.9208\n",
      "Epoch 126/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.2390 - acc: 0.9109\n",
      "Epoch 127/200\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.2376 - acc: 0.9158\n",
      "Epoch 128/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2383 - acc: 0.9109\n",
      "Epoch 129/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.2385 - acc: 0.9208\n",
      "Epoch 130/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.2380 - acc: 0.9208\n",
      "Epoch 131/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2376 - acc: 0.9208\n",
      "Epoch 132/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2379 - acc: 0.9158\n",
      "Epoch 133/200\n",
      "202/202 [==============================] - 0s 420us/step - loss: 0.2387 - acc: 0.9158\n",
      "Epoch 134/200\n",
      "202/202 [==============================] - 0s 379us/step - loss: 0.2370 - acc: 0.9208\n",
      "Epoch 135/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.2391 - acc: 0.9208\n",
      "Epoch 136/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2390 - acc: 0.9158\n",
      "Epoch 137/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.2374 - acc: 0.9208\n",
      "Epoch 138/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2407 - acc: 0.9109\n",
      "Epoch 139/200\n",
      "202/202 [==============================] - 0s 404us/step - loss: 0.2373 - acc: 0.9208\n",
      "Epoch 140/200\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.2375 - acc: 0.9158\n",
      "Epoch 141/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.2389 - acc: 0.9158\n",
      "Epoch 142/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.2370 - acc: 0.9158\n",
      "Epoch 143/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.2369 - acc: 0.9208\n",
      "Epoch 144/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2370 - acc: 0.9109\n",
      "Epoch 145/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.2371 - acc: 0.9158\n",
      "Epoch 146/200\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.2381 - acc: 0.9010\n",
      "Epoch 147/200\n",
      "202/202 [==============================] - 0s 386us/step - loss: 0.2375 - acc: 0.9158\n",
      "Epoch 148/200\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.2366 - acc: 0.9158\n",
      "Epoch 149/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.2369 - acc: 0.9208\n",
      "Epoch 150/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.2359 - acc: 0.9158\n",
      "Epoch 151/200\n",
      "202/202 [==============================] - 0s 410us/step - loss: 0.2366 - acc: 0.9158\n",
      "Epoch 152/200\n",
      "202/202 [==============================] - 0s 403us/step - loss: 0.2371 - acc: 0.9158\n",
      "Epoch 153/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.2361 - acc: 0.9158\n",
      "Epoch 154/200\n",
      "202/202 [==============================] - 0s 391us/step - loss: 0.2367 - acc: 0.9158\n",
      "Epoch 155/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.2377 - acc: 0.9109\n",
      "Epoch 156/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.2358 - acc: 0.9158\n",
      "Epoch 157/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2365 - acc: 0.9158\n",
      "Epoch 158/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.2356 - acc: 0.9158\n",
      "Epoch 159/200\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.2360 - acc: 0.9158\n",
      "Epoch 160/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.2360 - acc: 0.9158\n",
      "Epoch 161/200\n",
      "202/202 [==============================] - 0s 401us/step - loss: 0.2360 - acc: 0.9158\n",
      "Epoch 162/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.2359 - acc: 0.9158\n",
      "Epoch 163/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2371 - acc: 0.9158\n",
      "Epoch 164/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.2367 - acc: 0.9109\n",
      "Epoch 165/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2377 - acc: 0.9109\n",
      "Epoch 166/200\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.2359 - acc: 0.9158\n",
      "Epoch 167/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.2354 - acc: 0.9158\n",
      "Epoch 168/200\n",
      "202/202 [==============================] - 0s 393us/step - loss: 0.2361 - acc: 0.9158\n",
      "Epoch 169/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.2358 - acc: 0.9158\n",
      "Epoch 170/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.2377 - acc: 0.9109\n",
      "Epoch 171/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.2360 - acc: 0.9158\n",
      "Epoch 172/200\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.2363 - acc: 0.9158\n",
      "Epoch 173/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.2357 - acc: 0.9158\n",
      "Epoch 174/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.2357 - acc: 0.9158\n",
      "Epoch 175/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2354 - acc: 0.9158\n",
      "Epoch 176/200\n",
      "202/202 [==============================] - 0s 395us/step - loss: 0.2358 - acc: 0.9158\n",
      "Epoch 177/200\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.2353 - acc: 0.9158\n",
      "Epoch 178/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.2362 - acc: 0.9158\n",
      "Epoch 179/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.2351 - acc: 0.9158\n",
      "Epoch 180/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.2354 - acc: 0.9158\n",
      "Epoch 181/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2361 - acc: 0.9109\n",
      "Epoch 182/200\n",
      "202/202 [==============================] - 0s 390us/step - loss: 0.2352 - acc: 0.9158\n",
      "Epoch 183/200\n",
      "202/202 [==============================] - 0s 396us/step - loss: 0.2349 - acc: 0.9158\n",
      "Epoch 184/200\n",
      "202/202 [==============================] - 0s 387us/step - loss: 0.2358 - acc: 0.9158\n",
      "Epoch 185/200\n",
      "202/202 [==============================] - 0s 381us/step - loss: 0.2354 - acc: 0.9109\n",
      "Epoch 186/200\n",
      "202/202 [==============================] - 0s 380us/step - loss: 0.2352 - acc: 0.9059\n",
      "Epoch 187/200\n",
      "202/202 [==============================] - 0s 388us/step - loss: 0.2387 - acc: 0.9109\n",
      "Epoch 188/200\n",
      "202/202 [==============================] - 0s 383us/step - loss: 0.2372 - acc: 0.9059\n",
      "Epoch 189/200\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.2348 - acc: 0.9158\n",
      "Epoch 190/200\n",
      "202/202 [==============================] - 0s 400us/step - loss: 0.2353 - acc: 0.9158\n",
      "Epoch 191/200\n",
      "202/202 [==============================] - 0s 397us/step - loss: 0.2353 - acc: 0.9158\n",
      "Epoch 192/200\n",
      "202/202 [==============================] - 0s 398us/step - loss: 0.2349 - acc: 0.9158\n",
      "Epoch 193/200\n",
      "202/202 [==============================] - 0s 392us/step - loss: 0.2350 - acc: 0.9158\n",
      "Epoch 194/200\n",
      "202/202 [==============================] - 0s 384us/step - loss: 0.2346 - acc: 0.9158\n",
      "Epoch 195/200\n",
      "202/202 [==============================] - 0s 385us/step - loss: 0.2346 - acc: 0.9158\n",
      "Epoch 196/200\n",
      "202/202 [==============================] - 0s 389us/step - loss: 0.2356 - acc: 0.9109\n",
      "Epoch 197/200\n",
      "202/202 [==============================] - 0s 394us/step - loss: 0.2344 - acc: 0.9158\n",
      "Epoch 198/200\n",
      "202/202 [==============================] - 0s 432us/step - loss: 0.2349 - acc: 0.9158\n",
      "Epoch 199/200\n",
      "202/202 [==============================] - 0s 410us/step - loss: 0.2366 - acc: 0.9158\n",
      "Epoch 200/200\n",
      "202/202 [==============================] - 0s 399us/step - loss: 0.2357 - acc: 0.9059\n",
      "101/101 [==============================] - 1s 12ms/step\n",
      "202/202 [==============================] - 0s 232us/step\n",
      "Epoch 1/200\n",
      "303/303 [==============================] - 3s 10ms/step - loss: 0.6883 - acc: 0.5347\n",
      "Epoch 2/200\n",
      "303/303 [==============================] - 0s 390us/step - loss: 0.6592 - acc: 0.7393\n",
      "Epoch 3/200\n",
      "303/303 [==============================] - 0s 393us/step - loss: 0.6436 - acc: 0.7492\n",
      "Epoch 4/200\n",
      "303/303 [==============================] - 0s 389us/step - loss: 0.6290 - acc: 0.7360\n",
      "Epoch 5/200\n",
      "303/303 [==============================] - 0s 399us/step - loss: 0.6160 - acc: 0.7789\n",
      "Epoch 6/200\n",
      "303/303 [==============================] - 0s 393us/step - loss: 0.6013 - acc: 0.7822\n",
      "Epoch 7/200\n",
      "303/303 [==============================] - 0s 385us/step - loss: 0.5876 - acc: 0.7789\n",
      "Epoch 8/200\n",
      "303/303 [==============================] - 0s 395us/step - loss: 0.5747 - acc: 0.7954\n",
      "Epoch 9/200\n",
      "303/303 [==============================] - 0s 392us/step - loss: 0.5621 - acc: 0.8020\n",
      "Epoch 10/200\n",
      "303/303 [==============================] - 0s 390us/step - loss: 0.5488 - acc: 0.7987\n",
      "Epoch 11/200\n",
      "303/303 [==============================] - 0s 406us/step - loss: 0.5372 - acc: 0.8020\n",
      "Epoch 12/200\n",
      "303/303 [==============================] - 0s 389us/step - loss: 0.5244 - acc: 0.8020\n",
      "Epoch 13/200\n",
      "303/303 [==============================] - 0s 390us/step - loss: 0.5127 - acc: 0.8086\n",
      "Epoch 14/200\n",
      "303/303 [==============================] - 0s 385us/step - loss: 0.5024 - acc: 0.8119\n",
      "Epoch 15/200\n",
      "303/303 [==============================] - 0s 382us/step - loss: 0.4923 - acc: 0.7987\n",
      "Epoch 16/200\n",
      "303/303 [==============================] - 0s 394us/step - loss: 0.4822 - acc: 0.8119\n",
      "Epoch 17/200\n",
      "303/303 [==============================] - 0s 380us/step - loss: 0.4741 - acc: 0.8086\n",
      "Epoch 18/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.4661 - acc: 0.8086\n",
      "Epoch 19/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.4591 - acc: 0.8185\n",
      "Epoch 20/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.4525 - acc: 0.8218\n",
      "Epoch 21/200\n",
      "303/303 [==============================] - 0s 390us/step - loss: 0.4458 - acc: 0.8086\n",
      "Epoch 22/200\n",
      "303/303 [==============================] - 0s 382us/step - loss: 0.4404 - acc: 0.8152\n",
      "Epoch 23/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.4354 - acc: 0.8119\n",
      "Epoch 24/200\n",
      "303/303 [==============================] - 0s 392us/step - loss: 0.4299 - acc: 0.8152\n",
      "Epoch 25/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.4260 - acc: 0.8185\n",
      "Epoch 26/200\n",
      "303/303 [==============================] - 0s 386us/step - loss: 0.4233 - acc: 0.8185\n",
      "Epoch 27/200\n",
      "303/303 [==============================] - 0s 380us/step - loss: 0.4181 - acc: 0.8185\n",
      "Epoch 28/200\n",
      "303/303 [==============================] - 0s 378us/step - loss: 0.4155 - acc: 0.8185\n",
      "Epoch 29/200\n",
      "303/303 [==============================] - 0s 374us/step - loss: 0.4125 - acc: 0.8218\n",
      "Epoch 30/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.4095 - acc: 0.8185\n",
      "Epoch 31/200\n",
      "303/303 [==============================] - 0s 382us/step - loss: 0.4065 - acc: 0.8218\n",
      "Epoch 32/200\n",
      "303/303 [==============================] - 0s 385us/step - loss: 0.4040 - acc: 0.8251\n",
      "Epoch 33/200\n",
      "303/303 [==============================] - 0s 381us/step - loss: 0.4010 - acc: 0.8251\n",
      "Epoch 34/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.4000 - acc: 0.8251\n",
      "Epoch 35/200\n",
      "303/303 [==============================] - 0s 385us/step - loss: 0.3987 - acc: 0.8251\n",
      "Epoch 36/200\n",
      "303/303 [==============================] - 0s 394us/step - loss: 0.3959 - acc: 0.8284\n",
      "Epoch 37/200\n",
      "303/303 [==============================] - 0s 383us/step - loss: 0.3936 - acc: 0.8317\n",
      "Epoch 38/200\n",
      "303/303 [==============================] - 0s 390us/step - loss: 0.3924 - acc: 0.8350\n",
      "Epoch 39/200\n",
      "303/303 [==============================] - 0s 387us/step - loss: 0.3925 - acc: 0.8317\n",
      "Epoch 40/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.3903 - acc: 0.8350\n",
      "Epoch 41/200\n",
      "303/303 [==============================] - 0s 389us/step - loss: 0.3891 - acc: 0.8350\n",
      "Epoch 42/200\n",
      "303/303 [==============================] - 0s 385us/step - loss: 0.3875 - acc: 0.8317\n",
      "Epoch 43/200\n",
      "303/303 [==============================] - 0s 378us/step - loss: 0.3862 - acc: 0.8284\n",
      "Epoch 44/200\n",
      "303/303 [==============================] - 0s 378us/step - loss: 0.3859 - acc: 0.8317\n",
      "Epoch 45/200\n",
      "303/303 [==============================] - 0s 380us/step - loss: 0.3852 - acc: 0.8416\n",
      "Epoch 46/200\n",
      "303/303 [==============================] - 0s 385us/step - loss: 0.3837 - acc: 0.8350\n",
      "Epoch 47/200\n",
      "303/303 [==============================] - 0s 378us/step - loss: 0.3820 - acc: 0.8416\n",
      "Epoch 48/200\n",
      "303/303 [==============================] - 0s 394us/step - loss: 0.3809 - acc: 0.8383\n",
      "Epoch 49/200\n",
      "303/303 [==============================] - 0s 387us/step - loss: 0.3806 - acc: 0.8416\n",
      "Epoch 50/200\n",
      "303/303 [==============================] - 0s 388us/step - loss: 0.3798 - acc: 0.8350\n",
      "Epoch 51/200\n",
      "303/303 [==============================] - 0s 383us/step - loss: 0.3801 - acc: 0.8383\n",
      "Epoch 52/200\n",
      "303/303 [==============================] - 0s 381us/step - loss: 0.3801 - acc: 0.8416\n",
      "Epoch 53/200\n",
      "303/303 [==============================] - 0s 387us/step - loss: 0.3776 - acc: 0.8416\n",
      "Epoch 54/200\n",
      "303/303 [==============================] - 0s 391us/step - loss: 0.3770 - acc: 0.8383\n",
      "Epoch 55/200\n",
      "303/303 [==============================] - 0s 394us/step - loss: 0.3780 - acc: 0.8350\n",
      "Epoch 56/200\n",
      "303/303 [==============================] - 0s 406us/step - loss: 0.3766 - acc: 0.8416\n",
      "Epoch 57/200\n",
      "303/303 [==============================] - 0s 381us/step - loss: 0.3766 - acc: 0.8416\n",
      "Epoch 58/200\n",
      "303/303 [==============================] - 0s 380us/step - loss: 0.3753 - acc: 0.8416\n",
      "Epoch 59/200\n",
      "303/303 [==============================] - 0s 381us/step - loss: 0.3757 - acc: 0.8416\n",
      "Epoch 60/200\n",
      "303/303 [==============================] - 0s 383us/step - loss: 0.3740 - acc: 0.8416\n",
      "Epoch 61/200\n",
      "303/303 [==============================] - 0s 393us/step - loss: 0.3743 - acc: 0.8449\n",
      "Epoch 62/200\n",
      "303/303 [==============================] - 0s 389us/step - loss: 0.3750 - acc: 0.8317\n",
      "Epoch 63/200\n",
      "303/303 [==============================] - 0s 381us/step - loss: 0.3736 - acc: 0.8482\n",
      "Epoch 64/200\n",
      "303/303 [==============================] - 0s 402us/step - loss: 0.3731 - acc: 0.8416\n",
      "Epoch 65/200\n",
      "303/303 [==============================] - 0s 409us/step - loss: 0.3728 - acc: 0.8416\n",
      "Epoch 66/200\n",
      "303/303 [==============================] - 0s 389us/step - loss: 0.3730 - acc: 0.8383\n",
      "Epoch 67/200\n",
      "303/303 [==============================] - 0s 387us/step - loss: 0.3745 - acc: 0.8416\n",
      "Epoch 68/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.3725 - acc: 0.8515\n",
      "Epoch 69/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.3725 - acc: 0.8383\n",
      "Epoch 70/200\n",
      "303/303 [==============================] - 0s 375us/step - loss: 0.3711 - acc: 0.8383\n",
      "Epoch 71/200\n",
      "303/303 [==============================] - 0s 388us/step - loss: 0.3712 - acc: 0.8482\n",
      "Epoch 72/200\n",
      "303/303 [==============================] - 0s 383us/step - loss: 0.3711 - acc: 0.8449\n",
      "Epoch 73/200\n",
      "303/303 [==============================] - 0s 376us/step - loss: 0.3714 - acc: 0.8482\n",
      "Epoch 74/200\n",
      "303/303 [==============================] - 0s 386us/step - loss: 0.3701 - acc: 0.8449\n",
      "Epoch 75/200\n",
      "303/303 [==============================] - 0s 385us/step - loss: 0.3713 - acc: 0.8482\n",
      "Epoch 76/200\n",
      "303/303 [==============================] - 0s 380us/step - loss: 0.3703 - acc: 0.8383\n",
      "Epoch 77/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.3699 - acc: 0.8449\n",
      "Epoch 78/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.3697 - acc: 0.8449\n",
      "Epoch 79/200\n",
      "303/303 [==============================] - 0s 395us/step - loss: 0.3708 - acc: 0.8515\n",
      "Epoch 80/200\n",
      "303/303 [==============================] - 0s 394us/step - loss: 0.3699 - acc: 0.8449\n",
      "Epoch 81/200\n",
      "303/303 [==============================] - 0s 394us/step - loss: 0.3708 - acc: 0.8416\n",
      "Epoch 82/200\n",
      "303/303 [==============================] - 0s 386us/step - loss: 0.3687 - acc: 0.8482\n",
      "Epoch 83/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.3688 - acc: 0.8449\n",
      "Epoch 84/200\n",
      "303/303 [==============================] - 0s 376us/step - loss: 0.3690 - acc: 0.8482\n",
      "Epoch 85/200\n",
      "303/303 [==============================] - 0s 383us/step - loss: 0.3681 - acc: 0.8449\n",
      "Epoch 86/200\n",
      "303/303 [==============================] - 0s 380us/step - loss: 0.3685 - acc: 0.8449\n",
      "Epoch 87/200\n",
      "303/303 [==============================] - 0s 380us/step - loss: 0.3680 - acc: 0.8449\n",
      "Epoch 88/200\n",
      "303/303 [==============================] - 0s 385us/step - loss: 0.3687 - acc: 0.8350\n",
      "Epoch 89/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.3710 - acc: 0.8416\n",
      "Epoch 90/200\n",
      "303/303 [==============================] - 0s 383us/step - loss: 0.3677 - acc: 0.8515\n",
      "Epoch 91/200\n",
      "303/303 [==============================] - 0s 389us/step - loss: 0.3677 - acc: 0.8449\n",
      "Epoch 92/200\n",
      "303/303 [==============================] - 0s 388us/step - loss: 0.3672 - acc: 0.8548\n",
      "Epoch 93/200\n",
      "303/303 [==============================] - 0s 390us/step - loss: 0.3679 - acc: 0.8449\n",
      "Epoch 94/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.3673 - acc: 0.8515\n",
      "Epoch 95/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.3673 - acc: 0.8482\n",
      "Epoch 96/200\n",
      "303/303 [==============================] - 0s 380us/step - loss: 0.3667 - acc: 0.8449\n",
      "Epoch 97/200\n",
      "303/303 [==============================] - 0s 385us/step - loss: 0.3674 - acc: 0.8515\n",
      "Epoch 98/200\n",
      "303/303 [==============================] - 0s 383us/step - loss: 0.3659 - acc: 0.8548\n",
      "Epoch 99/200\n",
      "303/303 [==============================] - 0s 391us/step - loss: 0.3658 - acc: 0.8449\n",
      "Epoch 100/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.3669 - acc: 0.8449\n",
      "Epoch 101/200\n",
      "303/303 [==============================] - 0s 394us/step - loss: 0.3668 - acc: 0.8449\n",
      "Epoch 102/200\n",
      "303/303 [==============================] - 0s 395us/step - loss: 0.3666 - acc: 0.8482\n",
      "Epoch 103/200\n",
      "303/303 [==============================] - 0s 382us/step - loss: 0.3664 - acc: 0.8350\n",
      "Epoch 104/200\n",
      "303/303 [==============================] - 0s 380us/step - loss: 0.3659 - acc: 0.8449\n",
      "Epoch 105/200\n",
      "303/303 [==============================] - 0s 390us/step - loss: 0.3659 - acc: 0.8416\n",
      "Epoch 106/200\n",
      "303/303 [==============================] - 0s 386us/step - loss: 0.3661 - acc: 0.8482\n",
      "Epoch 107/200\n",
      "303/303 [==============================] - 0s 378us/step - loss: 0.3656 - acc: 0.8515\n",
      "Epoch 108/200\n",
      "303/303 [==============================] - 0s 481us/step - loss: 0.3656 - acc: 0.8449\n",
      "Epoch 109/200\n",
      "303/303 [==============================] - 0s 388us/step - loss: 0.3655 - acc: 0.8449\n",
      "Epoch 110/200\n",
      "303/303 [==============================] - 0s 387us/step - loss: 0.3656 - acc: 0.8515\n",
      "Epoch 111/200\n",
      "303/303 [==============================] - 0s 404us/step - loss: 0.3657 - acc: 0.8515\n",
      "Epoch 112/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.3643 - acc: 0.8482\n",
      "Epoch 113/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.3650 - acc: 0.8548\n",
      "Epoch 114/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.3647 - acc: 0.8383\n",
      "Epoch 115/200\n",
      "303/303 [==============================] - 0s 382us/step - loss: 0.3642 - acc: 0.8383\n",
      "Epoch 116/200\n",
      "303/303 [==============================] - 0s 391us/step - loss: 0.3654 - acc: 0.8515\n",
      "Epoch 117/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.3642 - acc: 0.8416\n",
      "Epoch 118/200\n",
      "303/303 [==============================] - 0s 381us/step - loss: 0.3657 - acc: 0.8482\n",
      "Epoch 119/200\n",
      "303/303 [==============================] - 0s 382us/step - loss: 0.3676 - acc: 0.8449\n",
      "Epoch 120/200\n",
      "303/303 [==============================] - 0s 382us/step - loss: 0.3642 - acc: 0.8482\n",
      "Epoch 121/200\n",
      "303/303 [==============================] - 0s 381us/step - loss: 0.3642 - acc: 0.8383\n",
      "Epoch 122/200\n",
      "303/303 [==============================] - 0s 387us/step - loss: 0.3647 - acc: 0.8548\n",
      "Epoch 123/200\n",
      "303/303 [==============================] - 0s 424us/step - loss: 0.3648 - acc: 0.8383\n",
      "Epoch 124/200\n",
      "303/303 [==============================] - 0s 380us/step - loss: 0.3649 - acc: 0.8449\n",
      "Epoch 125/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.3654 - acc: 0.8548\n",
      "Epoch 126/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.3643 - acc: 0.8515\n",
      "Epoch 127/200\n",
      "303/303 [==============================] - 0s 380us/step - loss: 0.3634 - acc: 0.8416\n",
      "Epoch 128/200\n",
      "303/303 [==============================] - 0s 381us/step - loss: 0.3634 - acc: 0.8482\n",
      "Epoch 129/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.3646 - acc: 0.8449\n",
      "Epoch 130/200\n",
      "303/303 [==============================] - 0s 380us/step - loss: 0.3633 - acc: 0.8482\n",
      "Epoch 131/200\n",
      "303/303 [==============================] - 0s 378us/step - loss: 0.3660 - acc: 0.8482\n",
      "Epoch 132/200\n",
      "303/303 [==============================] - 0s 380us/step - loss: 0.3627 - acc: 0.8515\n",
      "Epoch 133/200\n",
      "303/303 [==============================] - 0s 406us/step - loss: 0.3625 - acc: 0.8416\n",
      "Epoch 134/200\n",
      "303/303 [==============================] - 0s 378us/step - loss: 0.3640 - acc: 0.8515\n",
      "Epoch 135/200\n",
      "303/303 [==============================] - 0s 400us/step - loss: 0.3637 - acc: 0.8383\n",
      "Epoch 136/200\n",
      "303/303 [==============================] - 0s 387us/step - loss: 0.3627 - acc: 0.8482\n",
      "Epoch 137/200\n",
      "303/303 [==============================] - 0s 385us/step - loss: 0.3627 - acc: 0.8449\n",
      "Epoch 138/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.3626 - acc: 0.8449\n",
      "Epoch 139/200\n",
      "303/303 [==============================] - 0s 385us/step - loss: 0.3620 - acc: 0.8482\n",
      "Epoch 140/200\n",
      "303/303 [==============================] - 0s 389us/step - loss: 0.3623 - acc: 0.8416\n",
      "Epoch 141/200\n",
      "303/303 [==============================] - 0s 385us/step - loss: 0.3615 - acc: 0.8515\n",
      "Epoch 142/200\n",
      "303/303 [==============================] - 0s 389us/step - loss: 0.3616 - acc: 0.8449\n",
      "Epoch 143/200\n",
      "303/303 [==============================] - 0s 390us/step - loss: 0.3624 - acc: 0.8449\n",
      "Epoch 144/200\n",
      "303/303 [==============================] - 0s 382us/step - loss: 0.3621 - acc: 0.8515\n",
      "Epoch 145/200\n",
      "303/303 [==============================] - 0s 381us/step - loss: 0.3618 - acc: 0.8482\n",
      "Epoch 146/200\n",
      "303/303 [==============================] - 0s 378us/step - loss: 0.3615 - acc: 0.8548\n",
      "Epoch 147/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.3613 - acc: 0.8482\n",
      "Epoch 148/200\n",
      "303/303 [==============================] - 0s 397us/step - loss: 0.3633 - acc: 0.8449\n",
      "Epoch 149/200\n",
      "303/303 [==============================] - 0s 403us/step - loss: 0.3622 - acc: 0.8449\n",
      "Epoch 150/200\n",
      "303/303 [==============================] - 0s 397us/step - loss: 0.3625 - acc: 0.8515\n",
      "Epoch 151/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.3615 - acc: 0.8515\n",
      "Epoch 152/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.3620 - acc: 0.8515\n",
      "Epoch 153/200\n",
      "303/303 [==============================] - 0s 381us/step - loss: 0.3606 - acc: 0.8515\n",
      "Epoch 154/200\n",
      "303/303 [==============================] - 0s 385us/step - loss: 0.3634 - acc: 0.8482\n",
      "Epoch 155/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.3609 - acc: 0.8482\n",
      "Epoch 156/200\n",
      "303/303 [==============================] - 0s 378us/step - loss: 0.3606 - acc: 0.8482\n",
      "Epoch 157/200\n",
      "303/303 [==============================] - 0s 396us/step - loss: 0.3605 - acc: 0.8482\n",
      "Epoch 158/200\n",
      "303/303 [==============================] - 0s 390us/step - loss: 0.3626 - acc: 0.8515\n",
      "Epoch 159/200\n",
      "303/303 [==============================] - 0s 395us/step - loss: 0.3601 - acc: 0.8515\n",
      "Epoch 160/200\n",
      "303/303 [==============================] - 0s 388us/step - loss: 0.3613 - acc: 0.8416\n",
      "Epoch 161/200\n",
      "303/303 [==============================] - 0s 378us/step - loss: 0.3620 - acc: 0.8482\n",
      "Epoch 162/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.3621 - acc: 0.8449\n",
      "Epoch 163/200\n",
      "303/303 [==============================] - 0s 383us/step - loss: 0.3619 - acc: 0.8482\n",
      "Epoch 164/200\n",
      "303/303 [==============================] - 0s 391us/step - loss: 0.3600 - acc: 0.8515\n",
      "Epoch 165/200\n",
      "303/303 [==============================] - 0s 389us/step - loss: 0.3604 - acc: 0.8482\n",
      "Epoch 166/200\n",
      "303/303 [==============================] - 0s 390us/step - loss: 0.3606 - acc: 0.8416\n",
      "Epoch 167/200\n",
      "303/303 [==============================] - 0s 390us/step - loss: 0.3604 - acc: 0.8515\n",
      "Epoch 168/200\n",
      "303/303 [==============================] - 0s 388us/step - loss: 0.3616 - acc: 0.8515\n",
      "Epoch 169/200\n",
      "303/303 [==============================] - 0s 393us/step - loss: 0.3594 - acc: 0.8482\n",
      "Epoch 170/200\n",
      "303/303 [==============================] - 0s 392us/step - loss: 0.3601 - acc: 0.8614\n",
      "Epoch 171/200\n",
      "303/303 [==============================] - 0s 387us/step - loss: 0.3624 - acc: 0.8515\n",
      "Epoch 172/200\n",
      "303/303 [==============================] - 0s 380us/step - loss: 0.3598 - acc: 0.8515\n",
      "Epoch 173/200\n",
      "303/303 [==============================] - 0s 382us/step - loss: 0.3597 - acc: 0.8449\n",
      "Epoch 174/200\n",
      "303/303 [==============================] - 0s 390us/step - loss: 0.3599 - acc: 0.8515\n",
      "Epoch 175/200\n",
      "303/303 [==============================] - 0s 383us/step - loss: 0.3607 - acc: 0.8482\n",
      "Epoch 176/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.3593 - acc: 0.8482\n",
      "Epoch 177/200\n",
      "303/303 [==============================] - 0s 382us/step - loss: 0.3591 - acc: 0.8515\n",
      "Epoch 178/200\n",
      "303/303 [==============================] - 0s 378us/step - loss: 0.3585 - acc: 0.8482\n",
      "Epoch 179/200\n",
      "303/303 [==============================] - 0s 380us/step - loss: 0.3584 - acc: 0.8482\n",
      "Epoch 180/200\n",
      "303/303 [==============================] - 0s 397us/step - loss: 0.3582 - acc: 0.8482\n",
      "Epoch 181/200\n",
      "303/303 [==============================] - 0s 381us/step - loss: 0.3590 - acc: 0.8515\n",
      "Epoch 182/200\n",
      "303/303 [==============================] - 0s 385us/step - loss: 0.3587 - acc: 0.8515\n",
      "Epoch 183/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.3585 - acc: 0.8482\n",
      "Epoch 184/200\n",
      "303/303 [==============================] - 0s 391us/step - loss: 0.3579 - acc: 0.8482\n",
      "Epoch 185/200\n",
      "303/303 [==============================] - 0s 387us/step - loss: 0.3578 - acc: 0.8548\n",
      "Epoch 186/200\n",
      "303/303 [==============================] - 0s 383us/step - loss: 0.3577 - acc: 0.8515\n",
      "Epoch 187/200\n",
      "303/303 [==============================] - 0s 375us/step - loss: 0.3577 - acc: 0.8548\n",
      "Epoch 188/200\n",
      "303/303 [==============================] - 0s 386us/step - loss: 0.3582 - acc: 0.8482\n",
      "Epoch 189/200\n",
      "303/303 [==============================] - 0s 375us/step - loss: 0.3574 - acc: 0.8515\n",
      "Epoch 190/200\n",
      "303/303 [==============================] - 0s 381us/step - loss: 0.3575 - acc: 0.8548\n",
      "Epoch 191/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.3569 - acc: 0.8482\n",
      "Epoch 192/200\n",
      "303/303 [==============================] - 0s 381us/step - loss: 0.3577 - acc: 0.8548\n",
      "Epoch 193/200\n",
      "303/303 [==============================] - 0s 400us/step - loss: 0.3567 - acc: 0.8548\n",
      "Epoch 194/200\n",
      "303/303 [==============================] - 0s 380us/step - loss: 0.3571 - acc: 0.8515\n",
      "Epoch 195/200\n",
      "303/303 [==============================] - 0s 382us/step - loss: 0.3569 - acc: 0.8515\n",
      "Epoch 196/200\n",
      "303/303 [==============================] - 0s 379us/step - loss: 0.3584 - acc: 0.8548\n",
      "Epoch 197/200\n",
      "303/303 [==============================] - 0s 384us/step - loss: 0.3581 - acc: 0.8416\n",
      "Epoch 198/200\n",
      "303/303 [==============================] - 0s 385us/step - loss: 0.3567 - acc: 0.8548\n",
      "Epoch 199/200\n",
      "303/303 [==============================] - 0s 386us/step - loss: 0.3581 - acc: 0.8515\n",
      "Epoch 200/200\n",
      "303/303 [==============================] - 0s 386us/step - loss: 0.3576 - acc: 0.8482\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [5],\n",
    "              'epochs': [50, 100, 200]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.6666666775351704 using {'batch_size': 5, 'epochs': 200}\n"
     ]
    }
   ],
   "source": [
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tune hidden layer architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "303/303 [==============================] - 3s 11ms/step - loss: 0.7140 - acc: 0.4983\n",
      "Epoch 2/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.6839 - acc: 0.5446\n",
      "Epoch 3/200\n",
      "303/303 [==============================] - 0s 441us/step - loss: 0.6793 - acc: 0.5446\n",
      "Epoch 4/200\n",
      "303/303 [==============================] - 0s 433us/step - loss: 0.6702 - acc: 0.6733\n",
      "Epoch 5/200\n",
      "303/303 [==============================] - 0s 429us/step - loss: 0.6571 - acc: 0.6139\n",
      "Epoch 6/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.6433 - acc: 0.6865\n",
      "Epoch 7/200\n",
      "303/303 [==============================] - 0s 421us/step - loss: 0.6239 - acc: 0.7030\n",
      "Epoch 8/200\n",
      "303/303 [==============================] - 0s 422us/step - loss: 0.6060 - acc: 0.8053\n",
      "Epoch 9/200\n",
      "303/303 [==============================] - 0s 425us/step - loss: 0.5781 - acc: 0.8251\n",
      "Epoch 10/200\n",
      "303/303 [==============================] - 0s 429us/step - loss: 0.5528 - acc: 0.8053\n",
      "Epoch 11/200\n",
      "303/303 [==============================] - 0s 419us/step - loss: 0.5243 - acc: 0.8218\n",
      "Epoch 12/200\n",
      "303/303 [==============================] - 0s 426us/step - loss: 0.4981 - acc: 0.8119\n",
      "Epoch 13/200\n",
      "303/303 [==============================] - 0s 422us/step - loss: 0.4764 - acc: 0.8350\n",
      "Epoch 14/200\n",
      "303/303 [==============================] - 0s 409us/step - loss: 0.4555 - acc: 0.8317\n",
      "Epoch 15/200\n",
      "303/303 [==============================] - 0s 428us/step - loss: 0.4400 - acc: 0.8251\n",
      "Epoch 16/200\n",
      "303/303 [==============================] - 0s 418us/step - loss: 0.4299 - acc: 0.8350\n",
      "Epoch 17/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.4192 - acc: 0.8152\n",
      "Epoch 18/200\n",
      "303/303 [==============================] - 0s 418us/step - loss: 0.4109 - acc: 0.8350\n",
      "Epoch 19/200\n",
      "303/303 [==============================] - 0s 424us/step - loss: 0.4043 - acc: 0.8251\n",
      "Epoch 20/200\n",
      "303/303 [==============================] - 0s 418us/step - loss: 0.3981 - acc: 0.8416\n",
      "Epoch 21/200\n",
      "303/303 [==============================] - 0s 427us/step - loss: 0.3988 - acc: 0.8185\n",
      "Epoch 22/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3917 - acc: 0.8284\n",
      "Epoch 23/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3873 - acc: 0.8284\n",
      "Epoch 24/200\n",
      "303/303 [==============================] - 0s 421us/step - loss: 0.3897 - acc: 0.8251\n",
      "Epoch 25/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3846 - acc: 0.8317\n",
      "Epoch 26/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3837 - acc: 0.8251\n",
      "Epoch 27/200\n",
      "303/303 [==============================] - 0s 423us/step - loss: 0.3810 - acc: 0.8350\n",
      "Epoch 28/200\n",
      "303/303 [==============================] - 0s 412us/step - loss: 0.3811 - acc: 0.8251\n",
      "Epoch 29/200\n",
      "303/303 [==============================] - 0s 414us/step - loss: 0.3776 - acc: 0.8449\n",
      "Epoch 30/200\n",
      "303/303 [==============================] - 0s 412us/step - loss: 0.3837 - acc: 0.8251\n",
      "Epoch 31/200\n",
      "303/303 [==============================] - 0s 419us/step - loss: 0.3793 - acc: 0.8350\n",
      "Epoch 32/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3748 - acc: 0.8416\n",
      "Epoch 33/200\n",
      "303/303 [==============================] - 0s 424us/step - loss: 0.3741 - acc: 0.8350\n",
      "Epoch 34/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3743 - acc: 0.8350\n",
      "Epoch 35/200\n",
      "303/303 [==============================] - 0s 422us/step - loss: 0.3809 - acc: 0.8350\n",
      "Epoch 36/200\n",
      "303/303 [==============================] - 0s 419us/step - loss: 0.3756 - acc: 0.8284\n",
      "Epoch 37/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3730 - acc: 0.8383\n",
      "Epoch 38/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3739 - acc: 0.8416\n",
      "Epoch 39/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3729 - acc: 0.8284\n",
      "Epoch 40/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3728 - acc: 0.8449\n",
      "Epoch 41/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3706 - acc: 0.8383\n",
      "Epoch 42/200\n",
      "303/303 [==============================] - 0s 418us/step - loss: 0.3711 - acc: 0.8383\n",
      "Epoch 43/200\n",
      "303/303 [==============================] - 0s 415us/step - loss: 0.3706 - acc: 0.8383\n",
      "Epoch 44/200\n",
      "303/303 [==============================] - 0s 416us/step - loss: 0.3708 - acc: 0.8317\n",
      "Epoch 45/200\n",
      "303/303 [==============================] - 0s 427us/step - loss: 0.3719 - acc: 0.8416\n",
      "Epoch 46/200\n",
      "303/303 [==============================] - 0s 424us/step - loss: 0.3682 - acc: 0.8350\n",
      "Epoch 47/200\n",
      "303/303 [==============================] - 0s 422us/step - loss: 0.3684 - acc: 0.8383\n",
      "Epoch 48/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3699 - acc: 0.8482\n",
      "Epoch 49/200\n",
      "303/303 [==============================] - 0s 418us/step - loss: 0.3695 - acc: 0.8449\n",
      "Epoch 50/200\n",
      "303/303 [==============================] - 0s 418us/step - loss: 0.3671 - acc: 0.8383\n",
      "Epoch 51/200\n",
      "303/303 [==============================] - 0s 422us/step - loss: 0.3694 - acc: 0.8350\n",
      "Epoch 52/200\n",
      "303/303 [==============================] - 0s 418us/step - loss: 0.3678 - acc: 0.8548\n",
      "Epoch 53/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3676 - acc: 0.8515\n",
      "Epoch 54/200\n",
      "303/303 [==============================] - 0s 421us/step - loss: 0.3651 - acc: 0.8548\n",
      "Epoch 55/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3749 - acc: 0.8416\n",
      "Epoch 56/200\n",
      "303/303 [==============================] - 0s 422us/step - loss: 0.3666 - acc: 0.8284\n",
      "Epoch 57/200\n",
      "303/303 [==============================] - 0s 413us/step - loss: 0.3677 - acc: 0.8515\n",
      "Epoch 58/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3671 - acc: 0.8350\n",
      "Epoch 59/200\n",
      "303/303 [==============================] - 0s 421us/step - loss: 0.3691 - acc: 0.8515\n",
      "Epoch 60/200\n",
      "303/303 [==============================] - 0s 418us/step - loss: 0.3682 - acc: 0.8515\n",
      "Epoch 61/200\n",
      "303/303 [==============================] - 0s 426us/step - loss: 0.3661 - acc: 0.8449\n",
      "Epoch 62/200\n",
      "303/303 [==============================] - 0s 421us/step - loss: 0.3667 - acc: 0.8449\n",
      "Epoch 63/200\n",
      "303/303 [==============================] - 0s 413us/step - loss: 0.3663 - acc: 0.8449\n",
      "Epoch 64/200\n",
      "303/303 [==============================] - 0s 412us/step - loss: 0.3672 - acc: 0.8350\n",
      "Epoch 65/200\n",
      "303/303 [==============================] - 0s 418us/step - loss: 0.3651 - acc: 0.8317\n",
      "Epoch 66/200\n",
      "303/303 [==============================] - 0s 419us/step - loss: 0.3641 - acc: 0.8449\n",
      "Epoch 67/200\n",
      "303/303 [==============================] - 0s 416us/step - loss: 0.3654 - acc: 0.8482\n",
      "Epoch 68/200\n",
      "303/303 [==============================] - 0s 411us/step - loss: 0.3712 - acc: 0.8317\n",
      "Epoch 69/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3632 - acc: 0.8515\n",
      "Epoch 70/200\n",
      "303/303 [==============================] - 0s 416us/step - loss: 0.3636 - acc: 0.8449\n",
      "Epoch 71/200\n",
      "303/303 [==============================] - 0s 413us/step - loss: 0.3651 - acc: 0.8482\n",
      "Epoch 72/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3669 - acc: 0.8515\n",
      "Epoch 73/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3630 - acc: 0.8350\n",
      "Epoch 74/200\n",
      "303/303 [==============================] - 0s 424us/step - loss: 0.3641 - acc: 0.8449\n",
      "Epoch 75/200\n",
      "303/303 [==============================] - 0s 421us/step - loss: 0.3688 - acc: 0.8350\n",
      "Epoch 76/200\n",
      "303/303 [==============================] - 0s 415us/step - loss: 0.3628 - acc: 0.8383\n",
      "Epoch 77/200\n",
      "303/303 [==============================] - 0s 421us/step - loss: 0.3629 - acc: 0.8350\n",
      "Epoch 78/200\n",
      "303/303 [==============================] - 0s 418us/step - loss: 0.3631 - acc: 0.8515\n",
      "Epoch 79/200\n",
      "303/303 [==============================] - 0s 425us/step - loss: 0.3616 - acc: 0.8515\n",
      "Epoch 80/200\n",
      "303/303 [==============================] - 0s 413us/step - loss: 0.3625 - acc: 0.8416\n",
      "Epoch 81/200\n",
      "303/303 [==============================] - 0s 418us/step - loss: 0.3629 - acc: 0.8383\n",
      "Epoch 82/200\n",
      "303/303 [==============================] - 0s 419us/step - loss: 0.3606 - acc: 0.8482\n",
      "Epoch 83/200\n",
      "303/303 [==============================] - 0s 418us/step - loss: 0.3650 - acc: 0.8416\n",
      "Epoch 84/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3665 - acc: 0.8515\n",
      "Epoch 85/200\n",
      "303/303 [==============================] - 0s 421us/step - loss: 0.3621 - acc: 0.8350\n",
      "Epoch 86/200\n",
      "303/303 [==============================] - 0s 415us/step - loss: 0.3625 - acc: 0.8449\n",
      "Epoch 87/200\n",
      "303/303 [==============================] - 0s 412us/step - loss: 0.3604 - acc: 0.8416\n",
      "Epoch 88/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3625 - acc: 0.8416\n",
      "Epoch 89/200\n",
      "303/303 [==============================] - 0s 410us/step - loss: 0.3619 - acc: 0.8416\n",
      "Epoch 90/200\n",
      "303/303 [==============================] - 0s 424us/step - loss: 0.3656 - acc: 0.8482\n",
      "Epoch 91/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3645 - acc: 0.8350\n",
      "Epoch 92/200\n",
      "303/303 [==============================] - 0s 418us/step - loss: 0.3600 - acc: 0.8416\n",
      "Epoch 93/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3600 - acc: 0.8416\n",
      "Epoch 94/200\n",
      "303/303 [==============================] - 0s 427us/step - loss: 0.3607 - acc: 0.8416\n",
      "Epoch 95/200\n",
      "303/303 [==============================] - 0s 412us/step - loss: 0.3614 - acc: 0.8416\n",
      "Epoch 96/200\n",
      "303/303 [==============================] - 0s 415us/step - loss: 0.3605 - acc: 0.8350\n",
      "Epoch 97/200\n",
      "303/303 [==============================] - 0s 422us/step - loss: 0.3597 - acc: 0.8515\n",
      "Epoch 98/200\n",
      "303/303 [==============================] - 0s 422us/step - loss: 0.3594 - acc: 0.8482\n",
      "Epoch 99/200\n",
      "303/303 [==============================] - 0s 414us/step - loss: 0.3594 - acc: 0.8416\n",
      "Epoch 100/200\n",
      "303/303 [==============================] - 0s 421us/step - loss: 0.3590 - acc: 0.8416\n",
      "Epoch 101/200\n",
      "303/303 [==============================] - 0s 418us/step - loss: 0.3609 - acc: 0.8416\n",
      "Epoch 102/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3603 - acc: 0.8383\n",
      "Epoch 103/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3592 - acc: 0.8383\n",
      "Epoch 104/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3611 - acc: 0.8548\n",
      "Epoch 105/200\n",
      "303/303 [==============================] - 0s 416us/step - loss: 0.3591 - acc: 0.8449\n",
      "Epoch 106/200\n",
      "303/303 [==============================] - 0s 416us/step - loss: 0.3606 - acc: 0.8416\n",
      "Epoch 107/200\n",
      "303/303 [==============================] - 0s 411us/step - loss: 0.3586 - acc: 0.8449\n",
      "Epoch 108/200\n",
      "303/303 [==============================] - 0s 413us/step - loss: 0.3593 - acc: 0.8416\n",
      "Epoch 109/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3584 - acc: 0.8449\n",
      "Epoch 110/200\n",
      "303/303 [==============================] - 0s 415us/step - loss: 0.3612 - acc: 0.8449\n",
      "Epoch 111/200\n",
      "303/303 [==============================] - 0s 408us/step - loss: 0.3575 - acc: 0.8383\n",
      "Epoch 112/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3593 - acc: 0.8383\n",
      "Epoch 113/200\n",
      "303/303 [==============================] - 0s 407us/step - loss: 0.3601 - acc: 0.8350\n",
      "Epoch 114/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3577 - acc: 0.8482 0s - loss: 0.3553 - acc: 0.84\n",
      "Epoch 115/200\n",
      "303/303 [==============================] - 0s 411us/step - loss: 0.3584 - acc: 0.8449\n",
      "Epoch 116/200\n",
      "303/303 [==============================] - 0s 415us/step - loss: 0.3600 - acc: 0.8482\n",
      "Epoch 117/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3603 - acc: 0.8416\n",
      "Epoch 118/200\n",
      "303/303 [==============================] - 0s 598us/step - loss: 0.3594 - acc: 0.8515\n",
      "Epoch 119/200\n",
      "303/303 [==============================] - 0s 447us/step - loss: 0.3577 - acc: 0.8482\n",
      "Epoch 120/200\n",
      "303/303 [==============================] - 0s 406us/step - loss: 0.3595 - acc: 0.8515\n",
      "Epoch 121/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3570 - acc: 0.8548\n",
      "Epoch 122/200\n",
      "303/303 [==============================] - 0s 412us/step - loss: 0.3641 - acc: 0.8482\n",
      "Epoch 123/200\n",
      "303/303 [==============================] - 0s 413us/step - loss: 0.3573 - acc: 0.8449\n",
      "Epoch 124/200\n",
      "303/303 [==============================] - 0s 419us/step - loss: 0.3564 - acc: 0.8350\n",
      "Epoch 125/200\n",
      "303/303 [==============================] - 0s 424us/step - loss: 0.3578 - acc: 0.8482\n",
      "Epoch 126/200\n",
      "303/303 [==============================] - 0s 414us/step - loss: 0.3581 - acc: 0.8449\n",
      "Epoch 127/200\n",
      "303/303 [==============================] - 0s 422us/step - loss: 0.3554 - acc: 0.8515\n",
      "Epoch 128/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3597 - acc: 0.8482\n",
      "Epoch 129/200\n",
      "303/303 [==============================] - 0s 413us/step - loss: 0.3575 - acc: 0.8548\n",
      "Epoch 130/200\n",
      "303/303 [==============================] - 0s 411us/step - loss: 0.3572 - acc: 0.8449\n",
      "Epoch 131/200\n",
      "303/303 [==============================] - 0s 411us/step - loss: 0.3575 - acc: 0.8449\n",
      "Epoch 132/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3567 - acc: 0.8515\n",
      "Epoch 133/200\n",
      "303/303 [==============================] - 0s 414us/step - loss: 0.3583 - acc: 0.8548\n",
      "Epoch 134/200\n",
      "303/303 [==============================] - 0s 406us/step - loss: 0.3564 - acc: 0.8482\n",
      "Epoch 135/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3547 - acc: 0.8482\n",
      "Epoch 136/200\n",
      "303/303 [==============================] - 0s 415us/step - loss: 0.3601 - acc: 0.8449\n",
      "Epoch 137/200\n",
      "303/303 [==============================] - 0s 416us/step - loss: 0.3568 - acc: 0.8449\n",
      "Epoch 138/200\n",
      "303/303 [==============================] - 0s 421us/step - loss: 0.3556 - acc: 0.8449\n",
      "Epoch 139/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3586 - acc: 0.8515\n",
      "Epoch 140/200\n",
      "303/303 [==============================] - 0s 419us/step - loss: 0.3569 - acc: 0.8482\n",
      "Epoch 141/200\n",
      "303/303 [==============================] - 0s 421us/step - loss: 0.3570 - acc: 0.8482\n",
      "Epoch 142/200\n",
      "303/303 [==============================] - 0s 423us/step - loss: 0.3540 - acc: 0.8482\n",
      "Epoch 143/200\n",
      "303/303 [==============================] - 0s 427us/step - loss: 0.3535 - acc: 0.8482\n",
      "Epoch 144/200\n",
      "303/303 [==============================] - 0s 412us/step - loss: 0.3553 - acc: 0.8482\n",
      "Epoch 145/200\n",
      "303/303 [==============================] - 0s 413us/step - loss: 0.3542 - acc: 0.8515\n",
      "Epoch 146/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3556 - acc: 0.8416\n",
      "Epoch 147/200\n",
      "303/303 [==============================] - 0s 406us/step - loss: 0.3581 - acc: 0.8383\n",
      "Epoch 148/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.3540 - acc: 0.8482\n",
      "Epoch 149/200\n",
      "303/303 [==============================] - 0s 425us/step - loss: 0.3543 - acc: 0.8383\n",
      "Epoch 150/200\n",
      "303/303 [==============================] - 0s 423us/step - loss: 0.3553 - acc: 0.8449\n",
      "Epoch 151/200\n",
      "303/303 [==============================] - 0s 407us/step - loss: 0.3585 - acc: 0.8548\n",
      "Epoch 152/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3560 - acc: 0.8482\n",
      "Epoch 153/200\n",
      "303/303 [==============================] - 0s 416us/step - loss: 0.3527 - acc: 0.8515\n",
      "Epoch 154/200\n",
      "303/303 [==============================] - 0s 406us/step - loss: 0.3532 - acc: 0.8482\n",
      "Epoch 155/200\n",
      "303/303 [==============================] - 0s 415us/step - loss: 0.3579 - acc: 0.8449\n",
      "Epoch 156/200\n",
      "303/303 [==============================] - 0s 418us/step - loss: 0.3544 - acc: 0.8482\n",
      "Epoch 157/200\n",
      "303/303 [==============================] - 0s 419us/step - loss: 0.3526 - acc: 0.8482\n",
      "Epoch 158/200\n",
      "303/303 [==============================] - 0s 422us/step - loss: 0.3551 - acc: 0.8548\n",
      "Epoch 159/200\n",
      "303/303 [==============================] - 0s 411us/step - loss: 0.3527 - acc: 0.8581\n",
      "Epoch 160/200\n",
      "303/303 [==============================] - 0s 421us/step - loss: 0.3533 - acc: 0.8581\n",
      "Epoch 161/200\n",
      "303/303 [==============================] - 0s 425us/step - loss: 0.3518 - acc: 0.8515\n",
      "Epoch 162/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3533 - acc: 0.8548\n",
      "Epoch 163/200\n",
      "303/303 [==============================] - 0s 419us/step - loss: 0.3530 - acc: 0.8482\n",
      "Epoch 164/200\n",
      "303/303 [==============================] - 0s 419us/step - loss: 0.3533 - acc: 0.8515\n",
      "Epoch 165/200\n",
      "303/303 [==============================] - 0s 425us/step - loss: 0.3503 - acc: 0.8581\n",
      "Epoch 166/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3577 - acc: 0.8383\n",
      "Epoch 167/200\n",
      "303/303 [==============================] - 0s 422us/step - loss: 0.3566 - acc: 0.8482\n",
      "Epoch 168/200\n",
      "303/303 [==============================] - 0s 421us/step - loss: 0.3518 - acc: 0.8515\n",
      "Epoch 169/200\n",
      "303/303 [==============================] - 0s 426us/step - loss: 0.3526 - acc: 0.8581\n",
      "Epoch 170/200\n",
      "303/303 [==============================] - 0s 417us/step - loss: 0.3544 - acc: 0.8515\n",
      "Epoch 171/200\n",
      "303/303 [==============================] - 0s 412us/step - loss: 0.3510 - acc: 0.8548\n",
      "Epoch 172/200\n",
      "303/303 [==============================] - 0s 424us/step - loss: 0.3531 - acc: 0.8515\n",
      "Epoch 173/200\n",
      "303/303 [==============================] - 0s 412us/step - loss: 0.3539 - acc: 0.8581\n",
      "Epoch 174/200\n",
      "303/303 [==============================] - 0s 412us/step - loss: 0.3575 - acc: 0.8449\n",
      "Epoch 175/200\n",
      "303/303 [==============================] - 0s 422us/step - loss: 0.3553 - acc: 0.8449\n",
      "Epoch 176/200\n",
      "303/303 [==============================] - 0s 416us/step - loss: 0.3521 - acc: 0.8515\n",
      "Epoch 177/200\n",
      "303/303 [==============================] - 0s 425us/step - loss: 0.3542 - acc: 0.8548\n",
      "Epoch 178/200\n",
      "303/303 [==============================] - 0s 415us/step - loss: 0.3523 - acc: 0.8482\n",
      "Epoch 179/200\n",
      "303/303 [==============================] - 0s 413us/step - loss: 0.3519 - acc: 0.8515\n",
      "Epoch 180/200\n",
      "303/303 [==============================] - 0s 422us/step - loss: 0.3519 - acc: 0.8449\n",
      "Epoch 181/200\n",
      "303/303 [==============================] - 0s 408us/step - loss: 0.3553 - acc: 0.8416\n",
      "Epoch 182/200\n",
      "303/303 [==============================] - 0s 414us/step - loss: 0.3498 - acc: 0.8482\n",
      "Epoch 183/200\n",
      "303/303 [==============================] - 0s 419us/step - loss: 0.3503 - acc: 0.8548\n",
      "Epoch 184/200\n",
      "303/303 [==============================] - 0s 412us/step - loss: 0.3523 - acc: 0.8581\n",
      "Epoch 185/200\n",
      "303/303 [==============================] - 0s 419us/step - loss: 0.3520 - acc: 0.8449\n",
      "Epoch 186/200\n",
      "303/303 [==============================] - 0s 415us/step - loss: 0.3525 - acc: 0.8548\n",
      "Epoch 187/200\n",
      "303/303 [==============================] - 0s 413us/step - loss: 0.3526 - acc: 0.8482\n",
      "Epoch 188/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3503 - acc: 0.8383\n",
      "Epoch 189/200\n",
      "303/303 [==============================] - 0s 414us/step - loss: 0.3520 - acc: 0.8548\n",
      "Epoch 190/200\n",
      "303/303 [==============================] - 0s 424us/step - loss: 0.3508 - acc: 0.8449\n",
      "Epoch 191/200\n",
      "303/303 [==============================] - 0s 424us/step - loss: 0.3496 - acc: 0.8548\n",
      "Epoch 192/200\n",
      "303/303 [==============================] - 0s 416us/step - loss: 0.3498 - acc: 0.8548\n",
      "Epoch 193/200\n",
      "303/303 [==============================] - 0s 410us/step - loss: 0.3485 - acc: 0.8548\n",
      "Epoch 194/200\n",
      "303/303 [==============================] - 0s 421us/step - loss: 0.3478 - acc: 0.8581\n",
      "Epoch 195/200\n",
      "303/303 [==============================] - 0s 415us/step - loss: 0.3490 - acc: 0.8548\n",
      "Epoch 196/200\n",
      "303/303 [==============================] - 0s 418us/step - loss: 0.3492 - acc: 0.8515\n",
      "Epoch 197/200\n",
      "303/303 [==============================] - 0s 416us/step - loss: 0.3536 - acc: 0.8548\n",
      "Epoch 198/200\n",
      "303/303 [==============================] - 0s 413us/step - loss: 0.3514 - acc: 0.8515\n",
      "Epoch 199/200\n",
      "303/303 [==============================] - 0s 419us/step - loss: 0.3507 - acc: 0.8449\n",
      "Epoch 200/200\n",
      "303/303 [==============================] - 0s 420us/step - loss: 0.3504 - acc: 0.8548\n"
     ]
    }
   ],
   "source": [
    "# Add hidden layer with 30 nodes\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=13, activation='sigmoid'))\n",
    "    model.add(Dense(30, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Make output verbose for grading\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "param_grid = {'batch_size': [5],\n",
    "              'epochs': [200]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.6765676677817165 using {'batch_size': 5, 'epochs': 200}\n"
     ]
    }
   ],
   "source": [
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "303/303 [==============================] - 4s 12ms/step - loss: 0.7409 - acc: 0.4554\n",
      "Epoch 2/200\n",
      "303/303 [==============================] - 0s 435us/step - loss: 0.6888 - acc: 0.5446\n",
      "Epoch 3/200\n",
      "303/303 [==============================] - 0s 444us/step - loss: 0.6825 - acc: 0.5446\n",
      "Epoch 4/200\n",
      "303/303 [==============================] - 0s 442us/step - loss: 0.6776 - acc: 0.5743\n",
      "Epoch 5/200\n",
      "303/303 [==============================] - 0s 441us/step - loss: 0.6694 - acc: 0.5446\n",
      "Epoch 6/200\n",
      "303/303 [==============================] - 0s 442us/step - loss: 0.6596 - acc: 0.7426\n",
      "Epoch 7/200\n",
      "303/303 [==============================] - 0s 441us/step - loss: 0.6432 - acc: 0.5908\n",
      "Epoch 8/200\n",
      "303/303 [==============================] - 0s 437us/step - loss: 0.6268 - acc: 0.7624\n",
      "Epoch 9/200\n",
      "303/303 [==============================] - 0s 437us/step - loss: 0.6060 - acc: 0.7855\n",
      "Epoch 10/200\n",
      "303/303 [==============================] - 0s 430us/step - loss: 0.5821 - acc: 0.7954\n",
      "Epoch 11/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.5572 - acc: 0.8119\n",
      "Epoch 12/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.5306 - acc: 0.8119\n",
      "Epoch 13/200\n",
      "303/303 [==============================] - 0s 437us/step - loss: 0.5094 - acc: 0.8053\n",
      "Epoch 14/200\n",
      "303/303 [==============================] - 0s 441us/step - loss: 0.4848 - acc: 0.8119\n",
      "Epoch 15/200\n",
      "303/303 [==============================] - 0s 442us/step - loss: 0.4673 - acc: 0.8218\n",
      "Epoch 16/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.4514 - acc: 0.8251\n",
      "Epoch 17/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.4375 - acc: 0.8185\n",
      "Epoch 18/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.4257 - acc: 0.8284\n",
      "Epoch 19/200\n",
      "303/303 [==============================] - 0s 429us/step - loss: 0.4175 - acc: 0.8317\n",
      "Epoch 20/200\n",
      "303/303 [==============================] - 0s 435us/step - loss: 0.4122 - acc: 0.8218\n",
      "Epoch 21/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.4063 - acc: 0.8218\n",
      "Epoch 22/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.4035 - acc: 0.8383\n",
      "Epoch 23/200\n",
      "303/303 [==============================] - 0s 441us/step - loss: 0.4004 - acc: 0.8284\n",
      "Epoch 24/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.3935 - acc: 0.8317\n",
      "Epoch 25/200\n",
      "303/303 [==============================] - 0s 445us/step - loss: 0.3930 - acc: 0.8218\n",
      "Epoch 26/200\n",
      "303/303 [==============================] - 0s 439us/step - loss: 0.3896 - acc: 0.8251\n",
      "Epoch 27/200\n",
      "303/303 [==============================] - 0s 434us/step - loss: 0.3883 - acc: 0.8383\n",
      "Epoch 28/200\n",
      "303/303 [==============================] - 0s 434us/step - loss: 0.3862 - acc: 0.8251\n",
      "Epoch 29/200\n",
      "303/303 [==============================] - 0s 434us/step - loss: 0.3863 - acc: 0.8350\n",
      "Epoch 30/200\n",
      "303/303 [==============================] - 0s 434us/step - loss: 0.3840 - acc: 0.8350\n",
      "Epoch 31/200\n",
      "303/303 [==============================] - 0s 431us/step - loss: 0.3841 - acc: 0.8383\n",
      "Epoch 32/200\n",
      "303/303 [==============================] - 0s 437us/step - loss: 0.3812 - acc: 0.8350\n",
      "Epoch 33/200\n",
      "303/303 [==============================] - 0s 440us/step - loss: 0.3790 - acc: 0.8449\n",
      "Epoch 34/200\n",
      "303/303 [==============================] - 0s 433us/step - loss: 0.3777 - acc: 0.8449\n",
      "Epoch 35/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3785 - acc: 0.8482\n",
      "Epoch 36/200\n",
      "303/303 [==============================] - 0s 441us/step - loss: 0.3808 - acc: 0.8284\n",
      "Epoch 37/200\n",
      "303/303 [==============================] - 0s 434us/step - loss: 0.3820 - acc: 0.8284\n",
      "Epoch 38/200\n",
      "303/303 [==============================] - 0s 423us/step - loss: 0.3773 - acc: 0.8383\n",
      "Epoch 39/200\n",
      "303/303 [==============================] - 0s 423us/step - loss: 0.3751 - acc: 0.8185\n",
      "Epoch 40/200\n",
      "303/303 [==============================] - 0s 434us/step - loss: 0.3746 - acc: 0.8383\n",
      "Epoch 41/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.3753 - acc: 0.8416\n",
      "Epoch 42/200\n",
      "303/303 [==============================] - 0s 440us/step - loss: 0.3739 - acc: 0.8449\n",
      "Epoch 43/200\n",
      "303/303 [==============================] - 0s 433us/step - loss: 0.3720 - acc: 0.8350\n",
      "Epoch 44/200\n",
      "303/303 [==============================] - 0s 424us/step - loss: 0.3726 - acc: 0.8284\n",
      "Epoch 45/200\n",
      "303/303 [==============================] - 0s 429us/step - loss: 0.3724 - acc: 0.8383\n",
      "Epoch 46/200\n",
      "303/303 [==============================] - 0s 433us/step - loss: 0.3708 - acc: 0.8449\n",
      "Epoch 47/200\n",
      "303/303 [==============================] - 0s 439us/step - loss: 0.3718 - acc: 0.8449\n",
      "Epoch 48/200\n",
      "303/303 [==============================] - 0s 436us/step - loss: 0.3717 - acc: 0.8383\n",
      "Epoch 49/200\n",
      "303/303 [==============================] - 0s 424us/step - loss: 0.3750 - acc: 0.8350\n",
      "Epoch 50/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.3703 - acc: 0.8416\n",
      "Epoch 51/200\n",
      "303/303 [==============================] - 0s 427us/step - loss: 0.3722 - acc: 0.8482\n",
      "Epoch 52/200\n",
      "303/303 [==============================] - 0s 433us/step - loss: 0.3719 - acc: 0.8383\n",
      "Epoch 53/200\n",
      "303/303 [==============================] - 0s 425us/step - loss: 0.3692 - acc: 0.8449\n",
      "Epoch 54/200\n",
      "303/303 [==============================] - 0s 435us/step - loss: 0.3788 - acc: 0.8317\n",
      "Epoch 55/200\n",
      "303/303 [==============================] - 0s 441us/step - loss: 0.3701 - acc: 0.8416\n",
      "Epoch 56/200\n",
      "303/303 [==============================] - 0s 435us/step - loss: 0.3698 - acc: 0.8482\n",
      "Epoch 57/200\n",
      "303/303 [==============================] - 0s 437us/step - loss: 0.3706 - acc: 0.8449\n",
      "Epoch 58/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3695 - acc: 0.8449\n",
      "Epoch 59/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.3728 - acc: 0.8482\n",
      "Epoch 60/200\n",
      "303/303 [==============================] - 0s 431us/step - loss: 0.3696 - acc: 0.8383\n",
      "Epoch 61/200\n",
      "303/303 [==============================] - 0s 431us/step - loss: 0.3679 - acc: 0.8482\n",
      "Epoch 62/200\n",
      "303/303 [==============================] - 0s 442us/step - loss: 0.3676 - acc: 0.8449\n",
      "Epoch 63/200\n",
      "303/303 [==============================] - 0s 434us/step - loss: 0.3720 - acc: 0.8383\n",
      "Epoch 64/200\n",
      "303/303 [==============================] - 0s 439us/step - loss: 0.3680 - acc: 0.8515\n",
      "Epoch 65/200\n",
      "303/303 [==============================] - 0s 427us/step - loss: 0.3663 - acc: 0.8515\n",
      "Epoch 66/200\n",
      "303/303 [==============================] - 0s 435us/step - loss: 0.3680 - acc: 0.8482\n",
      "Epoch 67/200\n",
      "303/303 [==============================] - 0s 426us/step - loss: 0.3699 - acc: 0.8515\n",
      "Epoch 68/200\n",
      "303/303 [==============================] - 0s 426us/step - loss: 0.3674 - acc: 0.8482\n",
      "Epoch 69/200\n",
      "303/303 [==============================] - 0s 424us/step - loss: 0.3682 - acc: 0.8482\n",
      "Epoch 70/200\n",
      "303/303 [==============================] - 0s 425us/step - loss: 0.3674 - acc: 0.8449\n",
      "Epoch 71/200\n",
      "303/303 [==============================] - 0s 434us/step - loss: 0.3687 - acc: 0.8416\n",
      "Epoch 72/200\n",
      "303/303 [==============================] - 0s 443us/step - loss: 0.3671 - acc: 0.8449\n",
      "Epoch 73/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.3675 - acc: 0.8515\n",
      "Epoch 74/200\n",
      "303/303 [==============================] - 0s 433us/step - loss: 0.3683 - acc: 0.8350\n",
      "Epoch 75/200\n",
      "303/303 [==============================] - 0s 422us/step - loss: 0.3656 - acc: 0.8515\n",
      "Epoch 76/200\n",
      "303/303 [==============================] - 0s 426us/step - loss: 0.3666 - acc: 0.8350\n",
      "Epoch 77/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3661 - acc: 0.8548\n",
      "Epoch 78/200\n",
      "303/303 [==============================] - 0s 421us/step - loss: 0.3688 - acc: 0.8449\n",
      "Epoch 79/200\n",
      "303/303 [==============================] - 0s 431us/step - loss: 0.3695 - acc: 0.8416\n",
      "Epoch 80/200\n",
      "303/303 [==============================] - 0s 428us/step - loss: 0.3679 - acc: 0.8416\n",
      "Epoch 81/200\n",
      "303/303 [==============================] - 0s 441us/step - loss: 0.3659 - acc: 0.8515\n",
      "Epoch 82/200\n",
      "303/303 [==============================] - 0s 447us/step - loss: 0.3651 - acc: 0.8482\n",
      "Epoch 83/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.3657 - acc: 0.8548\n",
      "Epoch 84/200\n",
      "303/303 [==============================] - 0s 428us/step - loss: 0.3672 - acc: 0.8482\n",
      "Epoch 85/200\n",
      "303/303 [==============================] - 0s 434us/step - loss: 0.3648 - acc: 0.8416\n",
      "Epoch 86/200\n",
      "303/303 [==============================] - 0s 429us/step - loss: 0.3648 - acc: 0.8416\n",
      "Epoch 87/200\n",
      "303/303 [==============================] - 0s 435us/step - loss: 0.3634 - acc: 0.8581\n",
      "Epoch 88/200\n",
      "303/303 [==============================] - 0s 437us/step - loss: 0.3641 - acc: 0.8416\n",
      "Epoch 89/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.3643 - acc: 0.8581\n",
      "Epoch 90/200\n",
      "303/303 [==============================] - 0s 431us/step - loss: 0.3635 - acc: 0.8482\n",
      "Epoch 91/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3697 - acc: 0.8383\n",
      "Epoch 92/200\n",
      "303/303 [==============================] - 0s 437us/step - loss: 0.3658 - acc: 0.8449\n",
      "Epoch 93/200\n",
      "303/303 [==============================] - 0s 444us/step - loss: 0.3646 - acc: 0.8482\n",
      "Epoch 94/200\n",
      "303/303 [==============================] - 0s 433us/step - loss: 0.3629 - acc: 0.8416\n",
      "Epoch 95/200\n",
      "303/303 [==============================] - 0s 434us/step - loss: 0.3629 - acc: 0.8482\n",
      "Epoch 96/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3646 - acc: 0.8449\n",
      "Epoch 97/200\n",
      "303/303 [==============================] - 0s 433us/step - loss: 0.3650 - acc: 0.8449\n",
      "Epoch 98/200\n",
      "303/303 [==============================] - 0s 428us/step - loss: 0.3641 - acc: 0.8482\n",
      "Epoch 99/200\n",
      "303/303 [==============================] - 0s 428us/step - loss: 0.3625 - acc: 0.8515\n",
      "Epoch 100/200\n",
      "303/303 [==============================] - 0s 434us/step - loss: 0.3632 - acc: 0.8449\n",
      "Epoch 101/200\n",
      "303/303 [==============================] - 0s 429us/step - loss: 0.3630 - acc: 0.8416\n",
      "Epoch 102/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3624 - acc: 0.8482\n",
      "Epoch 103/200\n",
      "303/303 [==============================] - 0s 439us/step - loss: 0.3672 - acc: 0.8482\n",
      "Epoch 104/200\n",
      "303/303 [==============================] - 0s 453us/step - loss: 0.3629 - acc: 0.8482\n",
      "Epoch 105/200\n",
      "303/303 [==============================] - 0s 424us/step - loss: 0.3611 - acc: 0.8515\n",
      "Epoch 106/200\n",
      "303/303 [==============================] - 0s 421us/step - loss: 0.3637 - acc: 0.8482\n",
      "Epoch 107/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3609 - acc: 0.8515\n",
      "Epoch 108/200\n",
      "303/303 [==============================] - 0s 423us/step - loss: 0.3630 - acc: 0.8350\n",
      "Epoch 109/200\n",
      "303/303 [==============================] - 0s 434us/step - loss: 0.3621 - acc: 0.8449\n",
      "Epoch 110/200\n",
      "303/303 [==============================] - 0s 437us/step - loss: 0.3618 - acc: 0.8449\n",
      "Epoch 111/200\n",
      "303/303 [==============================] - 0s 434us/step - loss: 0.3632 - acc: 0.8581\n",
      "Epoch 112/200\n",
      "303/303 [==============================] - 0s 436us/step - loss: 0.3615 - acc: 0.8482\n",
      "Epoch 113/200\n",
      "303/303 [==============================] - 0s 436us/step - loss: 0.3611 - acc: 0.8482\n",
      "Epoch 114/200\n",
      "303/303 [==============================] - 0s 434us/step - loss: 0.3629 - acc: 0.8350\n",
      "Epoch 115/200\n",
      "303/303 [==============================] - 0s 436us/step - loss: 0.3608 - acc: 0.8449\n",
      "Epoch 116/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3595 - acc: 0.8482\n",
      "Epoch 117/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3615 - acc: 0.8383\n",
      "Epoch 118/200\n",
      "303/303 [==============================] - 0s 429us/step - loss: 0.3613 - acc: 0.8515\n",
      "Epoch 119/200\n",
      "303/303 [==============================] - 0s 426us/step - loss: 0.3621 - acc: 0.8548\n",
      "Epoch 120/200\n",
      "303/303 [==============================] - 0s 428us/step - loss: 0.3646 - acc: 0.8416\n",
      "Epoch 121/200\n",
      "303/303 [==============================] - 0s 436us/step - loss: 0.3651 - acc: 0.8449\n",
      "Epoch 122/200\n",
      "303/303 [==============================] - 0s 446us/step - loss: 0.3618 - acc: 0.8449\n",
      "Epoch 123/200\n",
      "303/303 [==============================] - 0s 422us/step - loss: 0.3625 - acc: 0.8548\n",
      "Epoch 124/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3608 - acc: 0.8482\n",
      "Epoch 125/200\n",
      "303/303 [==============================] - 0s 429us/step - loss: 0.3595 - acc: 0.8515\n",
      "Epoch 126/200\n",
      "303/303 [==============================] - 0s 424us/step - loss: 0.3618 - acc: 0.8482\n",
      "Epoch 127/200\n",
      "303/303 [==============================] - 0s 430us/step - loss: 0.3592 - acc: 0.8482\n",
      "Epoch 128/200\n",
      "303/303 [==============================] - 0s 439us/step - loss: 0.3598 - acc: 0.8515\n",
      "Epoch 129/200\n",
      "303/303 [==============================] - 0s 429us/step - loss: 0.3600 - acc: 0.8515\n",
      "Epoch 130/200\n",
      "303/303 [==============================] - 0s 435us/step - loss: 0.3593 - acc: 0.8449\n",
      "Epoch 131/200\n",
      "303/303 [==============================] - 0s 424us/step - loss: 0.3613 - acc: 0.8416\n",
      "Epoch 132/200\n",
      "303/303 [==============================] - 0s 429us/step - loss: 0.3597 - acc: 0.8515\n",
      "Epoch 133/200\n",
      "303/303 [==============================] - 0s 435us/step - loss: 0.3596 - acc: 0.8515\n",
      "Epoch 134/200\n",
      "303/303 [==============================] - 0s 431us/step - loss: 0.3606 - acc: 0.8548\n",
      "Epoch 135/200\n",
      "303/303 [==============================] - 0s 427us/step - loss: 0.3586 - acc: 0.8449\n",
      "Epoch 136/200\n",
      "303/303 [==============================] - 0s 430us/step - loss: 0.3609 - acc: 0.8482\n",
      "Epoch 137/200\n",
      "303/303 [==============================] - 0s 430us/step - loss: 0.3593 - acc: 0.8449\n",
      "Epoch 138/200\n",
      "303/303 [==============================] - 0s 430us/step - loss: 0.3579 - acc: 0.8515\n",
      "Epoch 139/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.3597 - acc: 0.8416\n",
      "Epoch 140/200\n",
      "303/303 [==============================] - 0s 426us/step - loss: 0.3566 - acc: 0.8482\n",
      "Epoch 141/200\n",
      "303/303 [==============================] - 0s 423us/step - loss: 0.3596 - acc: 0.8515\n",
      "Epoch 142/200\n",
      "303/303 [==============================] - 0s 431us/step - loss: 0.3580 - acc: 0.8548\n",
      "Epoch 143/200\n",
      "303/303 [==============================] - 0s 426us/step - loss: 0.3578 - acc: 0.8515\n",
      "Epoch 144/200\n",
      "303/303 [==============================] - 0s 431us/step - loss: 0.3578 - acc: 0.8548\n",
      "Epoch 145/200\n",
      "303/303 [==============================] - 0s 427us/step - loss: 0.3590 - acc: 0.8548\n",
      "Epoch 146/200\n",
      "303/303 [==============================] - 0s 430us/step - loss: 0.3625 - acc: 0.8449\n",
      "Epoch 147/200\n",
      "303/303 [==============================] - 0s 431us/step - loss: 0.3573 - acc: 0.8482\n",
      "Epoch 148/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3576 - acc: 0.8515\n",
      "Epoch 149/200\n",
      "303/303 [==============================] - 0s 428us/step - loss: 0.3579 - acc: 0.8449\n",
      "Epoch 150/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3594 - acc: 0.8482\n",
      "Epoch 151/200\n",
      "303/303 [==============================] - 0s 430us/step - loss: 0.3605 - acc: 0.8383\n",
      "Epoch 152/200\n",
      "303/303 [==============================] - 0s 435us/step - loss: 0.3567 - acc: 0.8548\n",
      "Epoch 153/200\n",
      "303/303 [==============================] - 0s 439us/step - loss: 0.3564 - acc: 0.8581\n",
      "Epoch 154/200\n",
      "303/303 [==============================] - 0s 434us/step - loss: 0.3563 - acc: 0.8548\n",
      "Epoch 155/200\n",
      "303/303 [==============================] - 0s 443us/step - loss: 0.3586 - acc: 0.8482\n",
      "Epoch 156/200\n",
      "303/303 [==============================] - 0s 440us/step - loss: 0.3560 - acc: 0.8515\n",
      "Epoch 157/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3565 - acc: 0.8548\n",
      "Epoch 158/200\n",
      "303/303 [==============================] - 0s 431us/step - loss: 0.3563 - acc: 0.8581\n",
      "Epoch 159/200\n",
      "303/303 [==============================] - 0s 431us/step - loss: 0.3572 - acc: 0.8449\n",
      "Epoch 160/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.3582 - acc: 0.8482\n",
      "Epoch 161/200\n",
      "303/303 [==============================] - 0s 436us/step - loss: 0.3556 - acc: 0.8449\n",
      "Epoch 162/200\n",
      "303/303 [==============================] - 0s 429us/step - loss: 0.3571 - acc: 0.8482\n",
      "Epoch 163/200\n",
      "303/303 [==============================] - 0s 435us/step - loss: 0.3569 - acc: 0.8515\n",
      "Epoch 164/200\n",
      "303/303 [==============================] - 0s 440us/step - loss: 0.3573 - acc: 0.8548\n",
      "Epoch 165/200\n",
      "303/303 [==============================] - 0s 433us/step - loss: 0.3570 - acc: 0.8515\n",
      "Epoch 166/200\n",
      "303/303 [==============================] - 0s 437us/step - loss: 0.3554 - acc: 0.8515\n",
      "Epoch 167/200\n",
      "303/303 [==============================] - 0s 427us/step - loss: 0.3546 - acc: 0.8548\n",
      "Epoch 168/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3564 - acc: 0.8482\n",
      "Epoch 169/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3543 - acc: 0.8515\n",
      "Epoch 170/200\n",
      "303/303 [==============================] - 0s 436us/step - loss: 0.3542 - acc: 0.8515\n",
      "Epoch 171/200\n",
      "303/303 [==============================] - 0s 431us/step - loss: 0.3543 - acc: 0.8515\n",
      "Epoch 172/200\n",
      "303/303 [==============================] - 0s 431us/step - loss: 0.3543 - acc: 0.8515\n",
      "Epoch 173/200\n",
      "303/303 [==============================] - 0s 434us/step - loss: 0.3580 - acc: 0.8482\n",
      "Epoch 174/200\n",
      "303/303 [==============================] - 0s 429us/step - loss: 0.3550 - acc: 0.8548\n",
      "Epoch 175/200\n",
      "303/303 [==============================] - 0s 430us/step - loss: 0.3547 - acc: 0.8515\n",
      "Epoch 176/200\n",
      "303/303 [==============================] - 0s 430us/step - loss: 0.3545 - acc: 0.8515\n",
      "Epoch 177/200\n",
      "303/303 [==============================] - 0s 435us/step - loss: 0.3533 - acc: 0.8482\n",
      "Epoch 178/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.3531 - acc: 0.8548\n",
      "Epoch 179/200\n",
      "303/303 [==============================] - 0s 441us/step - loss: 0.3528 - acc: 0.8581\n",
      "Epoch 180/200\n",
      "303/303 [==============================] - 0s 443us/step - loss: 0.3548 - acc: 0.8647\n",
      "Epoch 181/200\n",
      "303/303 [==============================] - 0s 435us/step - loss: 0.3569 - acc: 0.8581\n",
      "Epoch 182/200\n",
      "303/303 [==============================] - 0s 428us/step - loss: 0.3523 - acc: 0.8581\n",
      "Epoch 183/200\n",
      "303/303 [==============================] - 0s 441us/step - loss: 0.3556 - acc: 0.8482\n",
      "Epoch 184/200\n",
      "303/303 [==============================] - 0s 427us/step - loss: 0.3536 - acc: 0.8548\n",
      "Epoch 185/200\n",
      "303/303 [==============================] - 0s 431us/step - loss: 0.3557 - acc: 0.8416\n",
      "Epoch 186/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3528 - acc: 0.8548\n",
      "Epoch 187/200\n",
      "303/303 [==============================] - 0s 430us/step - loss: 0.3519 - acc: 0.8515\n",
      "Epoch 188/200\n",
      "303/303 [==============================] - 0s 437us/step - loss: 0.3543 - acc: 0.8548\n",
      "Epoch 189/200\n",
      "303/303 [==============================] - 0s 426us/step - loss: 0.3520 - acc: 0.8548\n",
      "Epoch 190/200\n",
      "303/303 [==============================] - 0s 425us/step - loss: 0.3531 - acc: 0.8614\n",
      "Epoch 191/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3533 - acc: 0.8482\n",
      "Epoch 192/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3529 - acc: 0.8548\n",
      "Epoch 193/200\n",
      "303/303 [==============================] - 0s 429us/step - loss: 0.3525 - acc: 0.8449\n",
      "Epoch 194/200\n",
      "303/303 [==============================] - 0s 437us/step - loss: 0.3521 - acc: 0.8581\n",
      "Epoch 195/200\n",
      "303/303 [==============================] - 0s 437us/step - loss: 0.3521 - acc: 0.8581\n",
      "Epoch 196/200\n",
      "303/303 [==============================] - 0s 432us/step - loss: 0.3557 - acc: 0.8548\n",
      "Epoch 197/200\n",
      "303/303 [==============================] - 0s 435us/step - loss: 0.3535 - acc: 0.8515\n",
      "Epoch 198/200\n",
      "303/303 [==============================] - 0s 451us/step - loss: 0.3520 - acc: 0.8548\n",
      "Epoch 199/200\n",
      "303/303 [==============================] - 0s 436us/step - loss: 0.3519 - acc: 0.8449\n",
      "Epoch 200/200\n",
      "303/303 [==============================] - 0s 428us/step - loss: 0.3498 - acc: 0.8548\n"
     ]
    }
   ],
   "source": [
    "# Change \n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=13, activation='sigmoid'))\n",
    "    model.add(Dense(20, activation='sigmoid'))\n",
    "    model.add(Dense())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Make output verbose for grading\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "param_grid = {'batch_size': [5],\n",
    "              'epochs': [200]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.6699670076173524 using {'batch_size': 5, 'epochs': 200}\n"
     ]
    }
   ],
   "source": [
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "303/303 [==============================] - 3s 11ms/step - loss: 0.7055 - acc: 0.5446\n",
      "Epoch 2/200\n",
      "303/303 [==============================] - 0s 460us/step - loss: 0.6894 - acc: 0.5446\n",
      "Epoch 3/200\n",
      "303/303 [==============================] - 0s 471us/step - loss: 0.6878 - acc: 0.5446\n",
      "Epoch 4/200\n",
      "303/303 [==============================] - 0s 447us/step - loss: 0.6856 - acc: 0.5446\n",
      "Epoch 5/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.6838 - acc: 0.5446\n",
      "Epoch 6/200\n",
      "303/303 [==============================] - 0s 458us/step - loss: 0.6799 - acc: 0.5446\n",
      "Epoch 7/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.6746 - acc: 0.5446\n",
      "Epoch 8/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.6676 - acc: 0.5545\n",
      "Epoch 9/200\n",
      "303/303 [==============================] - 0s 460us/step - loss: 0.6559 - acc: 0.5578\n",
      "Epoch 10/200\n",
      "303/303 [==============================] - 0s 451us/step - loss: 0.6387 - acc: 0.7657\n",
      "Epoch 11/200\n",
      "303/303 [==============================] - 0s 461us/step - loss: 0.6158 - acc: 0.7096\n",
      "Epoch 12/200\n",
      "303/303 [==============================] - 0s 455us/step - loss: 0.5848 - acc: 0.7822\n",
      "Epoch 13/200\n",
      "303/303 [==============================] - 0s 451us/step - loss: 0.5546 - acc: 0.8185\n",
      "Epoch 14/200\n",
      "303/303 [==============================] - 0s 453us/step - loss: 0.5285 - acc: 0.7888\n",
      "Epoch 15/200\n",
      "303/303 [==============================] - 0s 452us/step - loss: 0.4976 - acc: 0.8152\n",
      "Epoch 16/200\n",
      "303/303 [==============================] - 0s 454us/step - loss: 0.4765 - acc: 0.8086\n",
      "Epoch 17/200\n",
      "303/303 [==============================] - 0s 447us/step - loss: 0.4589 - acc: 0.8152\n",
      "Epoch 18/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.4479 - acc: 0.8185\n",
      "Epoch 19/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.4339 - acc: 0.8218\n",
      "Epoch 20/200\n",
      "303/303 [==============================] - 0s 447us/step - loss: 0.4259 - acc: 0.8251\n",
      "Epoch 21/200\n",
      "303/303 [==============================] - 0s 439us/step - loss: 0.4189 - acc: 0.8218\n",
      "Epoch 22/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.4161 - acc: 0.8284\n",
      "Epoch 23/200\n",
      "303/303 [==============================] - 0s 447us/step - loss: 0.4116 - acc: 0.8284\n",
      "Epoch 24/200\n",
      "303/303 [==============================] - 0s 439us/step - loss: 0.4051 - acc: 0.8350\n",
      "Epoch 25/200\n",
      "303/303 [==============================] - 0s 447us/step - loss: 0.3995 - acc: 0.8350\n",
      "Epoch 26/200\n",
      "303/303 [==============================] - 0s 446us/step - loss: 0.3974 - acc: 0.8383\n",
      "Epoch 27/200\n",
      "303/303 [==============================] - 0s 446us/step - loss: 0.3959 - acc: 0.8317\n",
      "Epoch 28/200\n",
      "303/303 [==============================] - 0s 459us/step - loss: 0.3928 - acc: 0.8218\n",
      "Epoch 29/200\n",
      "303/303 [==============================] - 0s 454us/step - loss: 0.3912 - acc: 0.8284\n",
      "Epoch 30/200\n",
      "303/303 [==============================] - 0s 465us/step - loss: 0.3885 - acc: 0.8383\n",
      "Epoch 31/200\n",
      "303/303 [==============================] - 0s 462us/step - loss: 0.3865 - acc: 0.8416\n",
      "Epoch 32/200\n",
      "303/303 [==============================] - 0s 473us/step - loss: 0.3862 - acc: 0.8284\n",
      "Epoch 33/200\n",
      "303/303 [==============================] - 0s 457us/step - loss: 0.3864 - acc: 0.8251\n",
      "Epoch 34/200\n",
      "303/303 [==============================] - 0s 452us/step - loss: 0.3846 - acc: 0.8383\n",
      "Epoch 35/200\n",
      "303/303 [==============================] - 0s 455us/step - loss: 0.3852 - acc: 0.8350\n",
      "Epoch 36/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.3854 - acc: 0.8383\n",
      "Epoch 37/200\n",
      "303/303 [==============================] - 0s 444us/step - loss: 0.3810 - acc: 0.8350\n",
      "Epoch 38/200\n",
      "303/303 [==============================] - 0s 453us/step - loss: 0.3805 - acc: 0.8317\n",
      "Epoch 39/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3802 - acc: 0.8317\n",
      "Epoch 40/200\n",
      "303/303 [==============================] - 0s 462us/step - loss: 0.3806 - acc: 0.8383\n",
      "Epoch 41/200\n",
      "303/303 [==============================] - 0s 468us/step - loss: 0.3814 - acc: 0.8284\n",
      "Epoch 42/200\n",
      "303/303 [==============================] - 0s 456us/step - loss: 0.3794 - acc: 0.8350\n",
      "Epoch 43/200\n",
      "303/303 [==============================] - 0s 446us/step - loss: 0.3825 - acc: 0.8416\n",
      "Epoch 44/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3797 - acc: 0.8350\n",
      "Epoch 45/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3764 - acc: 0.8383\n",
      "Epoch 46/200\n",
      "303/303 [==============================] - 0s 451us/step - loss: 0.3779 - acc: 0.8383\n",
      "Epoch 47/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3796 - acc: 0.8383\n",
      "Epoch 48/200\n",
      "303/303 [==============================] - 0s 458us/step - loss: 0.3807 - acc: 0.8383\n",
      "Epoch 49/200\n",
      "303/303 [==============================] - 0s 445us/step - loss: 0.3782 - acc: 0.8383\n",
      "Epoch 50/200\n",
      "303/303 [==============================] - 0s 441us/step - loss: 0.3771 - acc: 0.8317\n",
      "Epoch 51/200\n",
      "303/303 [==============================] - 0s 454us/step - loss: 0.3786 - acc: 0.8350\n",
      "Epoch 52/200\n",
      "303/303 [==============================] - 0s 475us/step - loss: 0.3750 - acc: 0.8317\n",
      "Epoch 53/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3787 - acc: 0.8284\n",
      "Epoch 54/200\n",
      "303/303 [==============================] - 0s 445us/step - loss: 0.3740 - acc: 0.8383\n",
      "Epoch 55/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3743 - acc: 0.8383\n",
      "Epoch 56/200\n",
      "303/303 [==============================] - 0s 452us/step - loss: 0.3746 - acc: 0.8416\n",
      "Epoch 57/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3740 - acc: 0.8350\n",
      "Epoch 58/200\n",
      "303/303 [==============================] - 0s 453us/step - loss: 0.3753 - acc: 0.8284\n",
      "Epoch 59/200\n",
      "303/303 [==============================] - 0s 445us/step - loss: 0.3739 - acc: 0.8350\n",
      "Epoch 60/200\n",
      "303/303 [==============================] - 0s 441us/step - loss: 0.3729 - acc: 0.8416\n",
      "Epoch 61/200\n",
      "303/303 [==============================] - 0s 445us/step - loss: 0.3723 - acc: 0.8449\n",
      "Epoch 62/200\n",
      "303/303 [==============================] - 0s 443us/step - loss: 0.3731 - acc: 0.8449\n",
      "Epoch 63/200\n",
      "303/303 [==============================] - 0s 474us/step - loss: 0.3726 - acc: 0.8449\n",
      "Epoch 64/200\n",
      "303/303 [==============================] - 0s 455us/step - loss: 0.3733 - acc: 0.8350\n",
      "Epoch 65/200\n",
      "303/303 [==============================] - 0s 452us/step - loss: 0.3708 - acc: 0.8581\n",
      "Epoch 66/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3759 - acc: 0.8416\n",
      "Epoch 67/200\n",
      "303/303 [==============================] - 0s 444us/step - loss: 0.3735 - acc: 0.8416\n",
      "Epoch 68/200\n",
      "303/303 [==============================] - 0s 447us/step - loss: 0.3733 - acc: 0.8416\n",
      "Epoch 69/200\n",
      "303/303 [==============================] - 0s 443us/step - loss: 0.3728 - acc: 0.8383\n",
      "Epoch 70/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3713 - acc: 0.8416\n",
      "Epoch 71/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.3708 - acc: 0.8416\n",
      "Epoch 72/200\n",
      "303/303 [==============================] - 0s 446us/step - loss: 0.3720 - acc: 0.8515\n",
      "Epoch 73/200\n",
      "303/303 [==============================] - 0s 455us/step - loss: 0.3698 - acc: 0.8449\n",
      "Epoch 74/200\n",
      "303/303 [==============================] - 0s 447us/step - loss: 0.3703 - acc: 0.8515\n",
      "Epoch 75/200\n",
      "303/303 [==============================] - 0s 453us/step - loss: 0.3698 - acc: 0.8383\n",
      "Epoch 76/200\n",
      "303/303 [==============================] - 0s 443us/step - loss: 0.3701 - acc: 0.8449\n",
      "Epoch 77/200\n",
      "303/303 [==============================] - 0s 445us/step - loss: 0.3694 - acc: 0.8482\n",
      "Epoch 78/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3706 - acc: 0.8482\n",
      "Epoch 79/200\n",
      "303/303 [==============================] - 0s 445us/step - loss: 0.3718 - acc: 0.8383\n",
      "Epoch 80/200\n",
      "303/303 [==============================] - 0s 466us/step - loss: 0.3696 - acc: 0.8416\n",
      "Epoch 81/200\n",
      "303/303 [==============================] - 0s 458us/step - loss: 0.3707 - acc: 0.8548\n",
      "Epoch 82/200\n",
      "303/303 [==============================] - 0s 440us/step - loss: 0.3709 - acc: 0.8449\n",
      "Epoch 83/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3712 - acc: 0.8449\n",
      "Epoch 84/200\n",
      "303/303 [==============================] - 0s 442us/step - loss: 0.3697 - acc: 0.8383\n",
      "Epoch 85/200\n",
      "303/303 [==============================] - 0s 442us/step - loss: 0.3693 - acc: 0.8416\n",
      "Epoch 86/200\n",
      "303/303 [==============================] - 0s 446us/step - loss: 0.3700 - acc: 0.8383\n",
      "Epoch 87/200\n",
      "303/303 [==============================] - 0s 442us/step - loss: 0.3693 - acc: 0.8449\n",
      "Epoch 88/200\n",
      "303/303 [==============================] - 0s 444us/step - loss: 0.3674 - acc: 0.8515\n",
      "Epoch 89/200\n",
      "303/303 [==============================] - 0s 445us/step - loss: 0.3685 - acc: 0.8482\n",
      "Epoch 90/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3676 - acc: 0.8482\n",
      "Epoch 91/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3674 - acc: 0.8449\n",
      "Epoch 92/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3682 - acc: 0.8482\n",
      "Epoch 93/200\n",
      "303/303 [==============================] - 0s 445us/step - loss: 0.3688 - acc: 0.8449\n",
      "Epoch 94/200\n",
      "303/303 [==============================] - 0s 446us/step - loss: 0.3668 - acc: 0.8449\n",
      "Epoch 95/200\n",
      "303/303 [==============================] - 0s 444us/step - loss: 0.3680 - acc: 0.8383\n",
      "Epoch 96/200\n",
      "303/303 [==============================] - 0s 457us/step - loss: 0.3695 - acc: 0.8449\n",
      "Epoch 97/200\n",
      "303/303 [==============================] - 0s 444us/step - loss: 0.3700 - acc: 0.8482\n",
      "Epoch 98/200\n",
      "303/303 [==============================] - 0s 447us/step - loss: 0.3697 - acc: 0.8449\n",
      "Epoch 99/200\n",
      "303/303 [==============================] - 0s 464us/step - loss: 0.3648 - acc: 0.8482\n",
      "Epoch 100/200\n",
      "303/303 [==============================] - 0s 457us/step - loss: 0.3668 - acc: 0.8515\n",
      "Epoch 101/200\n",
      "303/303 [==============================] - 0s 445us/step - loss: 0.3683 - acc: 0.8515\n",
      "Epoch 102/200\n",
      "303/303 [==============================] - 0s 445us/step - loss: 0.3684 - acc: 0.8350\n",
      "Epoch 103/200\n",
      "303/303 [==============================] - 0s 444us/step - loss: 0.3679 - acc: 0.8416\n",
      "Epoch 104/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3667 - acc: 0.8449\n",
      "Epoch 105/200\n",
      "303/303 [==============================] - 0s 440us/step - loss: 0.3681 - acc: 0.8548\n",
      "Epoch 106/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3681 - acc: 0.8383\n",
      "Epoch 107/200\n",
      "303/303 [==============================] - 0s 441us/step - loss: 0.3651 - acc: 0.8548\n",
      "Epoch 108/200\n",
      "303/303 [==============================] - 0s 447us/step - loss: 0.3645 - acc: 0.8383\n",
      "Epoch 109/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.3756 - acc: 0.8449\n",
      "Epoch 110/200\n",
      "303/303 [==============================] - 0s 460us/step - loss: 0.3669 - acc: 0.8548\n",
      "Epoch 111/200\n",
      "303/303 [==============================] - 0s 458us/step - loss: 0.3674 - acc: 0.8449\n",
      "Epoch 112/200\n",
      "303/303 [==============================] - 0s 453us/step - loss: 0.3651 - acc: 0.8350\n",
      "Epoch 113/200\n",
      "303/303 [==============================] - 0s 444us/step - loss: 0.3679 - acc: 0.8548\n",
      "Epoch 114/200\n",
      "303/303 [==============================] - 0s 439us/step - loss: 0.3673 - acc: 0.8317\n",
      "Epoch 115/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3673 - acc: 0.8482\n",
      "Epoch 116/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3666 - acc: 0.8317\n",
      "Epoch 117/200\n",
      "303/303 [==============================] - 0s 456us/step - loss: 0.3635 - acc: 0.8416\n",
      "Epoch 118/200\n",
      "303/303 [==============================] - 0s 447us/step - loss: 0.3691 - acc: 0.8416\n",
      "Epoch 119/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.3645 - acc: 0.8482\n",
      "Epoch 120/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.3632 - acc: 0.8416\n",
      "Epoch 121/200\n",
      "303/303 [==============================] - 0s 446us/step - loss: 0.3628 - acc: 0.8416\n",
      "Epoch 122/200\n",
      "303/303 [==============================] - 0s 446us/step - loss: 0.3641 - acc: 0.8449\n",
      "Epoch 123/200\n",
      "303/303 [==============================] - 0s 467us/step - loss: 0.3640 - acc: 0.8383\n",
      "Epoch 124/200\n",
      "303/303 [==============================] - 0s 456us/step - loss: 0.3645 - acc: 0.8317\n",
      "Epoch 125/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3628 - acc: 0.8383\n",
      "Epoch 126/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.3627 - acc: 0.8416\n",
      "Epoch 127/200\n",
      "303/303 [==============================] - 0s 446us/step - loss: 0.3633 - acc: 0.8482\n",
      "Epoch 128/200\n",
      "303/303 [==============================] - 0s 443us/step - loss: 0.3642 - acc: 0.8350\n",
      "Epoch 129/200\n",
      "303/303 [==============================] - 0s 452us/step - loss: 0.3677 - acc: 0.8614\n",
      "Epoch 130/200\n",
      "303/303 [==============================] - 0s 442us/step - loss: 0.3621 - acc: 0.8482\n",
      "Epoch 131/200\n",
      "303/303 [==============================] - 0s 459us/step - loss: 0.3642 - acc: 0.8350\n",
      "Epoch 132/200\n",
      "303/303 [==============================] - 0s 441us/step - loss: 0.3638 - acc: 0.8515\n",
      "Epoch 133/200\n",
      "303/303 [==============================] - 0s 447us/step - loss: 0.3630 - acc: 0.8449\n",
      "Epoch 134/200\n",
      "303/303 [==============================] - 0s 452us/step - loss: 0.3617 - acc: 0.8350\n",
      "Epoch 135/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3625 - acc: 0.8383\n",
      "Epoch 136/200\n",
      "303/303 [==============================] - 0s 445us/step - loss: 0.3614 - acc: 0.8416\n",
      "Epoch 137/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3616 - acc: 0.8383\n",
      "Epoch 138/200\n",
      "303/303 [==============================] - 0s 439us/step - loss: 0.3624 - acc: 0.8416\n",
      "Epoch 139/200\n",
      "303/303 [==============================] - 0s 453us/step - loss: 0.3642 - acc: 0.8449\n",
      "Epoch 140/200\n",
      "303/303 [==============================] - 0s 451us/step - loss: 0.3602 - acc: 0.8482\n",
      "Epoch 141/200\n",
      "303/303 [==============================] - 0s 442us/step - loss: 0.3628 - acc: 0.8416\n",
      "Epoch 142/200\n",
      "303/303 [==============================] - 0s 437us/step - loss: 0.3604 - acc: 0.8449\n",
      "Epoch 143/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.3593 - acc: 0.8449\n",
      "Epoch 144/200\n",
      "303/303 [==============================] - 0s 462us/step - loss: 0.3617 - acc: 0.8581\n",
      "Epoch 145/200\n",
      "303/303 [==============================] - 0s 469us/step - loss: 0.3607 - acc: 0.8383\n",
      "Epoch 146/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3635 - acc: 0.8581\n",
      "Epoch 147/200\n",
      "303/303 [==============================] - 0s 446us/step - loss: 0.3595 - acc: 0.8548\n",
      "Epoch 148/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.3594 - acc: 0.8416\n",
      "Epoch 149/200\n",
      "303/303 [==============================] - 0s 444us/step - loss: 0.3590 - acc: 0.8515\n",
      "Epoch 150/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.3594 - acc: 0.8350\n",
      "Epoch 151/200\n",
      "303/303 [==============================] - 0s 451us/step - loss: 0.3620 - acc: 0.8515\n",
      "Epoch 152/200\n",
      "303/303 [==============================] - 0s 442us/step - loss: 0.3621 - acc: 0.8416\n",
      "Epoch 153/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3611 - acc: 0.8482\n",
      "Epoch 154/200\n",
      "303/303 [==============================] - 0s 457us/step - loss: 0.3625 - acc: 0.8383\n",
      "Epoch 155/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.3624 - acc: 0.8482\n",
      "Epoch 156/200\n",
      "303/303 [==============================] - 0s 452us/step - loss: 0.3648 - acc: 0.8482\n",
      "Epoch 157/200\n",
      "303/303 [==============================] - 0s 438us/step - loss: 0.3600 - acc: 0.8416\n",
      "Epoch 158/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3574 - acc: 0.8515\n",
      "Epoch 159/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3606 - acc: 0.8383\n",
      "Epoch 160/200\n",
      "303/303 [==============================] - 0s 451us/step - loss: 0.3592 - acc: 0.8416\n",
      "Epoch 161/200\n",
      "303/303 [==============================] - 0s 464us/step - loss: 0.3592 - acc: 0.8515\n",
      "Epoch 162/200\n",
      "303/303 [==============================] - 0s 463us/step - loss: 0.3584 - acc: 0.8548\n",
      "Epoch 163/200\n",
      "303/303 [==============================] - 0s 454us/step - loss: 0.3613 - acc: 0.8350\n",
      "Epoch 164/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3571 - acc: 0.8515\n",
      "Epoch 165/200\n",
      "303/303 [==============================] - 0s 458us/step - loss: 0.3604 - acc: 0.8515\n",
      "Epoch 166/200\n",
      "303/303 [==============================] - 0s 459us/step - loss: 0.3600 - acc: 0.8416\n",
      "Epoch 167/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3585 - acc: 0.8416\n",
      "Epoch 168/200\n",
      "303/303 [==============================] - 0s 444us/step - loss: 0.3572 - acc: 0.8482\n",
      "Epoch 169/200\n",
      "303/303 [==============================] - 0s 452us/step - loss: 0.3581 - acc: 0.8581\n",
      "Epoch 170/200\n",
      "303/303 [==============================] - 0s 463us/step - loss: 0.3594 - acc: 0.8515\n",
      "Epoch 171/200\n",
      "303/303 [==============================] - 0s 474us/step - loss: 0.3619 - acc: 0.8581\n",
      "Epoch 172/200\n",
      "303/303 [==============================] - 0s 465us/step - loss: 0.3574 - acc: 0.8482\n",
      "Epoch 173/200\n",
      "303/303 [==============================] - 0s 446us/step - loss: 0.3659 - acc: 0.8416\n",
      "Epoch 174/200\n",
      "303/303 [==============================] - 0s 445us/step - loss: 0.3579 - acc: 0.8449\n",
      "Epoch 175/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3582 - acc: 0.8449\n",
      "Epoch 176/200\n",
      "303/303 [==============================] - 0s 446us/step - loss: 0.3588 - acc: 0.8482\n",
      "Epoch 177/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3571 - acc: 0.8515\n",
      "Epoch 178/200\n",
      "303/303 [==============================] - 0s 440us/step - loss: 0.3600 - acc: 0.8350\n",
      "Epoch 179/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.3613 - acc: 0.8383\n",
      "Epoch 180/200\n",
      "303/303 [==============================] - 0s 459us/step - loss: 0.3574 - acc: 0.8449\n",
      "Epoch 181/200\n",
      "303/303 [==============================] - 0s 483us/step - loss: 0.3566 - acc: 0.8515\n",
      "Epoch 182/200\n",
      "303/303 [==============================] - 0s 458us/step - loss: 0.3640 - acc: 0.8449\n",
      "Epoch 183/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3583 - acc: 0.8449\n",
      "Epoch 184/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.3569 - acc: 0.8482\n",
      "Epoch 185/200\n",
      "303/303 [==============================] - 0s 464us/step - loss: 0.3569 - acc: 0.8350\n",
      "Epoch 186/200\n",
      "303/303 [==============================] - 0s 452us/step - loss: 0.3569 - acc: 0.8482\n",
      "Epoch 187/200\n",
      "303/303 [==============================] - 0s 454us/step - loss: 0.3542 - acc: 0.8515\n",
      "Epoch 188/200\n",
      "303/303 [==============================] - 0s 453us/step - loss: 0.3549 - acc: 0.8548\n",
      "Epoch 189/200\n",
      "303/303 [==============================] - 0s 450us/step - loss: 0.3551 - acc: 0.8614\n",
      "Epoch 190/200\n",
      "303/303 [==============================] - 0s 445us/step - loss: 0.3568 - acc: 0.8515\n",
      "Epoch 191/200\n",
      "303/303 [==============================] - 0s 442us/step - loss: 0.3545 - acc: 0.8416\n",
      "Epoch 192/200\n",
      "303/303 [==============================] - 0s 448us/step - loss: 0.3565 - acc: 0.8482\n",
      "Epoch 193/200\n",
      "303/303 [==============================] - 0s 453us/step - loss: 0.3538 - acc: 0.8416\n",
      "Epoch 194/200\n",
      "303/303 [==============================] - 0s 445us/step - loss: 0.3559 - acc: 0.8614\n",
      "Epoch 195/200\n",
      "303/303 [==============================] - 0s 451us/step - loss: 0.3563 - acc: 0.8548\n",
      "Epoch 196/200\n",
      "303/303 [==============================] - 0s 455us/step - loss: 0.3566 - acc: 0.8482\n",
      "Epoch 197/200\n",
      "303/303 [==============================] - 0s 449us/step - loss: 0.3539 - acc: 0.8515\n",
      "Epoch 198/200\n",
      "303/303 [==============================] - 0s 446us/step - loss: 0.3597 - acc: 0.8449\n",
      "Epoch 199/200\n",
      "303/303 [==============================] - 0s 469us/step - loss: 0.3541 - acc: 0.8383\n",
      "Epoch 200/200\n",
      "303/303 [==============================] - 0s 467us/step - loss: 0.3553 - acc: 0.8416\n"
     ]
    }
   ],
   "source": [
    "# Change hidden layer #1 to 20 nodes, add second hidden layer\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=13, activation='sigmoid'))\n",
    "    model.add(Dense(20, activation='sigmoid'))\n",
    "    model.add(Dense(10, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Make output verbose for grading\n",
    "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "param_grid = {'batch_size': [5],\n",
    "              'epochs': [200]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "grid_result = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.6864686584708715 using {'batch_size': 5, 'epochs': 200}\n"
     ]
    }
   ],
   "source": [
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
